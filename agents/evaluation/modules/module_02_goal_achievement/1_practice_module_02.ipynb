{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b383f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f92fa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Client initialized with model: gpt-4o-mini, temperature: 0.0\n"
     ]
    }
   ],
   "source": [
    "# ai-performance-management-system/ëª¨ë“ˆ2_êµ¬í˜„_í…ŒìŠ¤íŠ¸.ipynb\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (í•„ìš”ì‹œ)\n",
    "# ì´ë¯¸ ì„¤ì¹˜í–ˆë‹¤ë©´ ì´ ì…€ì€ ê±´ë„ˆë›°ì„¸ìš”.\n",
    "# !pip install langchain langchain-openai langgraph sqlalchemy pymysql python-dotenv\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../..')))  # ë£¨íŠ¸ ê²½ë¡œë¡œ ì´ë™\n",
    "\n",
    "from config.settings import DatabaseConfig\n",
    "from agents.evaluation.modules.module_02_goal_achievement import db_utils\n",
    "\n",
    "# 2. .env íŒŒì¼ ë¡œë“œ (DB ì ‘ì† ì •ë³´ ì„¤ì • ì‹œ í•„ìš”)\n",
    "# ì‹¤ì œ DB ì—°ê²°ì„ ìœ„í•´ DB_USERNAME, DB_PASSWORD ë“±ì„ .env íŒŒì¼ì— ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 3. LangSmith ì¶”ì  ì„¤ì • (ì„ íƒ ì‚¬í•­ - ë””ë²„ê¹…ì— ë§¤ìš° ìœ ìš©)\n",
    "# from langchain_teddynote import logging\n",
    "# logging.langsmith(\"CH21-Module2-Local-Test\")\n",
    "\n",
    "# 4. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from typing import Annotated, List, Literal, TypedDict, Dict, Any, Optional\n",
    "from langchain_core.messages import HumanMessage # LangChain ë©”ì‹œì§€ íƒ€ì…\n",
    "import operator # operator.add ì‚¬ìš©\n",
    "from langgraph.graph import StateGraph, START, END # LangGraph ê·¸ë˜í”„ êµ¬ì„±\n",
    "import uuid # ê³ ìœ  ID ìƒì„±ì„ ìœ„í•´ (thread_id ë“±)\n",
    "import random # Mocking í•¨ìˆ˜ì—ì„œ ëœë¤ ê°’ ìƒì„±ì„ ìœ„í•´\n",
    "\n",
    "# SQLAlchemy ê´€ë ¨ ì„í¬íŠ¸ (DB ì—°ë™ ì‹œ í•„ìš”)\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Connection, Row\n",
    "\n",
    "# config.settings (DB ì ‘ì† ì •ë³´ëŠ” ì—¬ê¸°ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤)\n",
    "# ì‹¤ì œ íŒŒì¼ ê²½ë¡œì— ë”°ë¼ ì„í¬íŠ¸ ë°©ì‹ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# ë§Œì•½ ì£¼í”¼í„° ë…¸íŠ¸ë¶ íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆë‹¤ë©´:\n",
    "from config.settings import DatabaseConfig \n",
    "from agents.evaluation.modules.module_02_goal_achievement.db_utils import *\n",
    "# ë§Œì•½ ë‹¤ë¥¸ ê²½ë¡œì— ìˆë‹¤ë©´ sys.path.append() í›„ ì„í¬íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # ì˜ˆì‹œ: í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ë¶€ëª¨ë¥¼ ì¶”ê°€\n",
    "# from config.settings import DatabaseConfig\n",
    "\n",
    "\n",
    "# 5. DB ì„¤ì • ë° ì—”ì§„ ìƒì„± (ì‹¤ì œ DB ì—°ê²°)\n",
    "db_config = DatabaseConfig()\n",
    "DATABASE_URL = db_config.DATABASE_URL\n",
    "engine = create_engine(DATABASE_URL, pool_pre_ping=True)\n",
    "\n",
    "# --- Module2AgentState ì •ì˜ ---\n",
    "class Module2AgentState(TypedDict):\n",
    "   \"\"\"\n",
    "   ëª¨ë“ˆ 2 (ëª©í‘œë‹¬ì„±ë„ ë¶„ì„ ëª¨ë“ˆ)ì˜ ë‚´ë¶€ ìƒíƒœë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "   ì´ ìƒíƒœëŠ” ëª¨ë“ˆ 2 ë‚´ì˜ ëª¨ë“  ì„œë¸Œëª¨ë“ˆì´ ê³µìœ í•˜ê³  ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "   \"\"\"\n",
    "   messages: Annotated[List[HumanMessage], operator.add] \n",
    "\n",
    "   report_type: Literal[\"quarterly\", \"annual\"] \n",
    "   team_id: int \n",
    "   period_id: int \n",
    "   \n",
    "   target_task_ids: List[int] \n",
    "   target_team_kpi_ids: List[int] \n",
    "\n",
    "   updated_task_ids: List[int]\n",
    "   updated_team_kpi_ids: List[int]\n",
    "   \n",
    "   kpi_individual_relative_contributions: List[Dict] = [] \n",
    "\n",
    "   feedback_report_id: int = None \n",
    "   team_evaluation_id: int = None \n",
    "   final_evaluation_report_id: int = None \n",
    "   updated_temp_evaluation_ids_list: List[int] = [] \n",
    "\n",
    "\n",
    "\n",
    "# ai-performance-management-system/shared/tools/py\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Connection, Row\n",
    "from typing import Optional, List, Dict, Any\n",
    "from config.settings import DatabaseConfig\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import random \n",
    "import json \n",
    "import re \n",
    "\n",
    "# LangChain LLM ê´€ë ¨ ì„í¬íŠ¸\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "# --- LLM í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ (ì „ì—­ ì„¤ì •) ---\n",
    "llm_client = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) \n",
    "print(f\"LLM Client initialized with model: {llm_client.model_name}, temperature: {llm_client.temperature}\")\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë¡œë“œ\n",
    "db_config = DatabaseConfig()\n",
    "DATABASE_URL = db_config.DATABASE_URL\n",
    "\n",
    "# SQLAlchemy Engine ìƒì„±\n",
    "engine = create_engine(DATABASE_URL, pool_pre_ping=True)\n",
    "\n",
    "# --- ë„ìš°ë¯¸ í•¨ìˆ˜: SQLAlchemy Row ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ ---\n",
    "def row_to_dict(row: Row) -> Dict[str, Any]:\n",
    "   \"\"\"SQLAlchemy Row ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "   if row is None:\n",
    "       return {}\n",
    "   return row._asdict() # ._asdict() ì‚¬ìš©\n",
    "\n",
    "\n",
    "# --- LLM ì‘ë‹µì—ì„œ JSON ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ ë„ìš°ë¯¸ í•¨ìˆ˜ ---\n",
    "def _extract_json_from_llm_response(text: str) -> str:\n",
    "   \"\"\"LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ```json ... ``` ë¸”ë¡ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\"\"\"\n",
    "   match = re.search(r\"```(?:json)?\\s*(.*?)\\s*```\", text, re.DOTALL)\n",
    "   if match:\n",
    "       return match.group(1).strip() # JSON ë‚´ìš©ë§Œ ë°˜í™˜í•˜ê³  ì–‘ìª½ ê³µë°± ì œê±°\n",
    "   return text.strip()\n",
    "\n",
    "\n",
    "# --- ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜ (`SELECT` ì¿¼ë¦¬ êµ¬í˜„) ---\n",
    "def fetch_task_summary_by_id(task_summary_id: int) -> Optional[Dict]:\n",
    "   \"\"\"\n",
    "   `task_summary_Id`ë¡œ `task_summaries` ë° ê´€ë ¨ `tasks`, `employees` í…Œì´ë¸”ì—ì„œ ìƒì„¸ Task Summary ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "   \"\"\"\n",
    "   with engine.connect() as connection:\n",
    "       query = text(f\"\"\"\n",
    "           SELECT ts.*, t.task_name, t.target_level, t.emp_no, t.team_kpi_id, t.weight, e.emp_name,\n",
    "                  t.ai_contribution_score, t.ai_achievement_rate, t.ai_assessed_grade, t.ai_analysis_comment_task\n",
    "           FROM task_summaries ts\n",
    "           JOIN tasks t ON ts.task_id = t.task_id\n",
    "           JOIN employees e ON t.emp_no = e.emp_no \n",
    "           WHERE ts.task_summary_Id = :task_summary_id\n",
    "       \"\"\")\n",
    "       result = connection.execute(query, {\"task_summary_id\": task_summary_id}).fetchone()\n",
    "       return row_to_dict(result) if result else None\n",
    "\n",
    "def fetch_task_summaries_by_task_and_period(task_id: int, period_id: int) -> List[Dict]:\n",
    "    \"\"\"íŠ¹ì • Taskì˜ í•´ë‹¹ ë¶„ê¸°ê¹Œì§€ ëª¨ë“  Task Summary ì¡°íšŒ\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT ts.*, t.task_name, t.target_level, t.weight, t.emp_no, t.team_kpi_id, e.emp_name\n",
    "            FROM task_summaries ts\n",
    "            JOIN tasks t ON ts.task_id = t.task_id\n",
    "            JOIN employees e ON t.emp_no = e.emp_no \n",
    "            WHERE ts.task_id = :task_id AND ts.period_id <= :period_id\n",
    "            ORDER BY ts.period_id\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"task_id\": task_id, \"period_id\": period_id}).fetchall()\n",
    "        return [row_to_dict(row) for row in results]\n",
    "\n",
    "def fetch_kpi_data_by_id(team_kpi_id: int) -> Optional[Dict]:\n",
    "   \"\"\"\n",
    "   `team_kpi_id`ë¡œ `team_kpis` í…Œì´ë¸”ì—ì„œ ìƒì„¸ KPI ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "   \"\"\"\n",
    "   with engine.connect() as connection:\n",
    "       query = text(\"SELECT * FROM team_kpis WHERE team_kpi_id = :team_kpi_id\")\n",
    "       result = connection.execute(query, {\"team_kpi_id\": team_kpi_id}).fetchone()\n",
    "       return row_to_dict(result) if result else None\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "def fetch_tasks_for_kpi(team_kpi_id: int, period_id: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    íŠ¹ì • KPIì— ì†í•œ Taskë“¤ì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT t.task_id, t.task_name, t.target_level, t.weight, t.emp_no, \n",
    "                   ts.task_summary, ts.task_performance, ts.task_summary_Id, \n",
    "                   ts.period_id,  -- ğŸ”§ ì¶”ê°€: period_idë¥¼ SELECTì— í¬í•¨\n",
    "                   e.emp_name, ts.ai_contribution_score, ts.ai_achievement_rate,\n",
    "                   ts.ai_assessed_grade, ts.ai_analysis_comment_task\n",
    "            FROM tasks t\n",
    "            JOIN task_summaries ts ON t.task_id = ts.task_id\n",
    "            JOIN employees e ON t.emp_no = e.emp_no\n",
    "            WHERE t.team_kpi_id = :team_kpi_id AND ts.period_id <= :period_id\n",
    "        \"\"\")\n",
    "        \n",
    "        results = connection.execute(query, {\"team_kpi_id\": team_kpi_id, \"period_id\": period_id}).fetchall()\n",
    "        return [row_to_dict(row) for row in results]\n",
    "\n",
    "def fetch_cumulative_task_data_for_comment(task_id: int, period_id: int) -> Dict:\n",
    "    \"\"\"\n",
    "    task_idì˜ ëª¨ë“  ë¶„ê¸° ì •ë³´ë¥¼ ëˆ„ì í•´ì„œ ë°˜í™˜ (ì½”ë©˜íŠ¸ ìƒì„±ìš©)\n",
    "    \"\"\"\n",
    "    # ëª¨ë“  ë¶„ê¸° ë°ì´í„° ì¡°íšŒ\n",
    "    task_summaries = fetch_task_summaries_by_task_and_period(task_id, period_id)\n",
    "    if not task_summaries:\n",
    "        return {}\n",
    "    \n",
    "    # ìµœì‹  ê¸°ë³¸ ì •ë³´ + ëˆ„ì  ìš”ì•½\n",
    "    latest_data = task_summaries[-1]\n",
    "    combined_summary = \"\\n\".join([f\"Q{ts['period_id']}: {ts['task_summary']}\" for ts in task_summaries])\n",
    "    \n",
    "    return {\n",
    "        **latest_data,  # ê¸°ë³¸ ì •ë³´ëŠ” ìµœì‹  ê²ƒ ì‚¬ìš©\n",
    "        \"cumulative_task_summary\": combined_summary,  # ëˆ„ì  ìš”ì•½ ì¶”ê°€\n",
    "        \"cumulative_task_performance\": latest_data.get('task_performance', '')\n",
    "    }\n",
    "\n",
    "def fetch_grade_definitions_from_db() -> Dict:\n",
    "   \"\"\"\n",
    "   `grades` í…Œì´ë¸”ì—ì„œ LLMì´ ì°¸ê³ í•  ë“±ê¸‰ ì •ì˜ (`grade_s`, `grade_a` ë“± ì»¬ëŸ¼ì˜ í…ìŠ¤íŠ¸)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "   \"\"\"\n",
    "   with engine.connect() as connection:\n",
    "       query = text(\"SELECT grade_id, grade_s, grade_a, grade_b, grade_c, grade_d, grade_rule FROM grades\")\n",
    "       results = connection.execute(query).fetchall()\n",
    "       \n",
    "       if results:\n",
    "           first_row = row_to_dict(results[0])\n",
    "           return {\n",
    "               \"S\": first_row.get(\"grade_s\", \"ëª©í‘œë¥¼ ì´ˆê³¼ ë‹¬ì„±\"),\n",
    "               \"A\": first_row.get(\"grade_a\", \"ëª©í‘œë¥¼ ì™„ë²½í•˜ê²Œ ë‹¬ì„±í•˜ë©° ë†’ì€ í’ˆì§ˆì˜ ê²°ê³¼ë¬¼ ì œê³µ\"),\n",
    "               \"B\": first_row.get(\"grade_b\", \"ëª©í‘œ ìˆ˜ì¤€ì„ ì •í™•íˆ ë‹¬ì„±\"),\n",
    "               \"C\": first_row.get(\"grade_c\", \"ëª©í‘œì— ë¯¸ë‹¬í–ˆìœ¼ë‚˜ ì¼ë¶€ ì„±ê³¼ ë‹¬ì„±\"),\n",
    "               \"D\": first_row.get(\"grade_d\", \"ëª©í‘œ ë‹¬ì„± ë¯¸í¡\")\n",
    "           }\n",
    "       return {}\n",
    "\n",
    "\n",
    "def fetch_team_evaluation_id_by_team_and_period(team_id: int, period_id: int) -> Optional[int]:\n",
    "   \"\"\"\n",
    "   `team_evaluations` í…Œì´ë¸”ì—ì„œ `team_id`ì™€ `period_id`ë¡œ `team_evaluation_id`ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "   Springì—ì„œ ì´ ë ˆì½”ë“œë¥¼ ë¯¸ë¦¬ ìƒì„±í•˜ê³  IDë¥¼ ê´€ë¦¬í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "   \"\"\"\n",
    "   with engine.connect() as connection:\n",
    "       query = text(\"SELECT team_evaluation_id FROM team_evaluations WHERE team_id = :team_id AND period_id = :period_id\")\n",
    "       result = connection.execute(query, {\"team_id\": team_id, \"period_id\": period_id}).scalar_one_or_none()\n",
    "       return result\n",
    "\n",
    "\n",
    "\n",
    "def fetch_employees_by_team_id(team_id: int) -> List[Dict]:\n",
    "   \"\"\"\n",
    "   íŠ¹ì • íŒ€ì— ì†í•œ ëª¨ë“  ì§ì›ì˜ emp_no, emp_name, roleì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "   \"\"\"\n",
    "   with engine.connect() as connection:\n",
    "       query = text(\"SELECT emp_no, emp_name, role FROM employees WHERE team_id = :team_id\")\n",
    "       results = connection.execute(query, {\"team_id\": team_id}).fetchall()\n",
    "       return [row_to_dict(row) for row in results]\n",
    "\n",
    "# --- ë°ì´í„° ì—…ë°ì´íŠ¸/ì¶”ê°€ í•¨ìˆ˜ (`UPDATE` / `INSERT` ì¿¼ë¦¬ êµ¬í˜„) ---\n",
    "\n",
    "def update_task_summary_ai_results_in_db(task_summary_id: int, update_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    `task_summary_Id`ì— í•´ë‹¹í•˜ëŠ” `task_summaries` í…Œì´ë¸” ë ˆì½”ë“œì˜ AI ì»¬ëŸ¼ë“¤ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        set_clauses = [f\"`{k}` = :{k}\" for k in update_data.keys()]\n",
    "        query = text(f\"UPDATE `task_summaries` SET {', '.join(set_clauses)} WHERE `task_summary_Id` = :task_summary_id\")\n",
    "        \n",
    "        params = {**update_data, \"task_summary_id\": task_summary_id}\n",
    "        result = connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        return result.rowcount > 0\n",
    "\n",
    "\n",
    "\n",
    "def update_team_kpi_ai_results_in_db(team_kpi_id: int, update_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    `team_kpi_id`ì— í•´ë‹¹í•˜ëŠ” `team_kpis` í…Œì´ë¸” ë ˆì½”ë“œì˜ AI ì»¬ëŸ¼ë“¤ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        set_clauses = [f\"`{k}` = :{k}\" for k in update_data.keys()]\n",
    "        query = text(f\"UPDATE `team_kpis` SET {', '.join(set_clauses)} WHERE `team_kpi_id` = :team_kpi_id\")\n",
    "        \n",
    "        params = {**update_data, \"team_kpi_id\": team_kpi_id}\n",
    "        result = connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        return result.rowcount > 0\n",
    "\n",
    "def save_feedback_report_module2_results_to_db(emp_no: str, team_evaluation_id: int, results: Dict) -> int: \n",
    "    \"\"\"\n",
    "    `feedback_reports` í…Œì´ë¸”ì— ëª¨ë“ˆ 2 ê´€ë ¨ AI ê²°ê³¼ë¥¼ ì‚½ì…í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        cols_for_insert = [\"emp_no\", \"team_evaluation_id\"] + list(results.keys())\n",
    "        values_placeholder = \", \".join([f\":{col}\" for col in cols_for_insert])\n",
    "        cols_str = \", \".join([f\"`{col}`\" for col in cols_for_insert])\n",
    "\n",
    "        on_duplicate_set_clauses = [f\"`{k}` = VALUES(`{k}`)\" for k in results.keys()]\n",
    "        \n",
    "        query = text(f\"\"\"\n",
    "            INSERT INTO `feedback_reports` ({cols_str}) VALUES ({values_placeholder})\n",
    "            ON DUPLICATE KEY UPDATE {\", \".join(on_duplicate_set_clauses)}\n",
    "        \"\"\")\n",
    "        \n",
    "        params = {\"emp_no\": emp_no, \"team_evaluation_id\": team_evaluation_id, **results} \n",
    "        \n",
    "        connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        \n",
    "        inserted_or_updated_id_query = text(\"\"\"\n",
    "            SELECT feedback_report_id FROM `feedback_reports`\n",
    "            WHERE `emp_no` = :emp_no AND `team_evaluation_id` = :team_evaluation_id\n",
    "        \"\"\")\n",
    "        ret_id = connection.execute(inserted_or_updated_id_query, {\"emp_no\": emp_no, \"team_evaluation_id\": team_evaluation_id}).scalar_one()\n",
    "        \n",
    "        print(f\"DB: feedback_reports[{ret_id}] for emp_no={emp_no}, team_evaluation_id={team_evaluation_id} inserted/updated.\")\n",
    "        return ret_id\n",
    "    \n",
    "\n",
    "def update_team_evaluations_module2_results_in_db(team_evaluation_id: int, update_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    `team_evaluations` í…Œì´ë¸”ì— ëª¨ë“ˆ 2 ê´€ë ¨ AI ê²°ê³¼ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        set_clauses = [f\"`{k}` = :{k}\" for k in update_data.keys()]\n",
    "        query = text(f\"UPDATE `team_evaluations` SET {', '.join(set_clauses)} WHERE `team_evaluation_id` = :team_evaluation_id\")\n",
    "        \n",
    "        params = {**update_data, \"team_evaluation_id\": team_evaluation_id}\n",
    "        result = connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        return result.rowcount > 0\n",
    "\n",
    "def save_final_evaluation_report_module2_results_to_db(emp_no: str, team_evaluation_id: int, results: Dict) -> int:\n",
    "    \"\"\"\n",
    "    `final_evaluation_reports` í…Œì´ë¸”ì— ëª¨ë“ˆ 2 ê´€ë ¨ AI ê²°ê³¼ë¥¼ ì‚½ì…í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        cols_for_insert = [\"emp_no\", \"team_evaluation_id\"] + list(results.keys())\n",
    "        values_placeholder = \", \".join([f\":{col}\" for col in cols_for_insert])\n",
    "        cols_str = \", \".join([f\"`{col}`\" for col in cols_for_insert])\n",
    "        \n",
    "        on_duplicate_set_clauses = [f\"`{k}` = VALUES(`{k}`)\" for k in results.keys()]\n",
    "        \n",
    "        query = text(f\"\"\"\n",
    "            INSERT INTO `final_evaluation_reports` ({cols_str}) VALUES ({values_placeholder})\n",
    "            ON DUPLICATE KEY UPDATE {\", \".join(on_duplicate_set_clauses)}\n",
    "        \"\"\")\n",
    "        \n",
    "        params = {\"emp_no\": emp_no, \"team_evaluation_id\": team_evaluation_id, **results}\n",
    "        \n",
    "        connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        \n",
    "        inserted_or_updated_id_query = text(\"\"\"\n",
    "            SELECT final_evaluation_report_id FROM `final_evaluation_reports`\n",
    "            WHERE `emp_no` = :emp_no AND `team_evaluation_id` = :team_evaluation_id\n",
    "        \"\"\")\n",
    "        ret_id = connection.execute(inserted_or_updated_id_query, {\"emp_no\": emp_no, \"team_evaluation_id\": team_evaluation_id}).scalar_one()\n",
    "        \n",
    "        print(f\"DB: final_evaluation_reports[{ret_id}] created/updated for emp_no={emp_no}.\")\n",
    "        return ret_id\n",
    "\n",
    "\n",
    "\n",
    "# --- LLM í˜¸ì¶œ í•¨ìˆ˜ë“¤ ---\n",
    "\n",
    "\n",
    "\n",
    "def call_llm_for_task_achievement(target_level_text: str, task_performance_text: str, grade_definitions: Dict) -> Dict:\n",
    "   \n",
    "   system_prompt = \"\"\"\n",
    "   ë‹¹ì‹ ì€ SK ì¡°ì§ì˜ ì„±ê³¼ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "   ì•„ë˜ Task ëª©í‘œì™€ ì‹¤ì œ ì„±ê³¼ë¥¼ ë¹„êµí•˜ì—¬, Taskì˜ ë‹¬ì„±ë¥ (0-100ì  ì´ìƒ)ê³¼ ì ì ˆí•œ ë“±ê¸‰(S, A, B, C, D)ì„ íŒë‹¨í•˜ê³ ,\n",
    "   ìƒì„¸ ë¶„ì„ ì½”ë©˜íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "   í‰ê°€ ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "   - ë‹¬ì„±ë¥ ì€ 0ì ë¶€í„° ì‹œì‘í•˜ë©°, 100ì ì„ ì´ˆê³¼í•˜ì—¬ ëª©í‘œ ì´ˆê³¼ ë‹¬ì„±ì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: 100.1% ì´ìƒ)\n",
    "   - ë“±ê¸‰ì€ S, A, B, C, D ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "   <ë“±ê¸‰ ì •ì˜ (LLM ì°¸ê³ ìš©)>\n",
    "   \"\"\"\n",
    "   for grade, desc in grade_definitions.items():\n",
    "       system_prompt += f\"- {grade} ë“±ê¸‰: {desc}\\n\"\n",
    "   system_prompt += \"</ë“±ê¸‰ ì •ì˜>\\n\"\n",
    "   system_prompt += \"ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì„œë¬¸ì´ë‚˜ ì¶”ê°€ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "   human_prompt = f\"\"\"\n",
    "   <Task ëª©í‘œ>\n",
    "   {target_level_text}\n",
    "   </Task ëª©í‘œ>\n",
    "\n",
    "   <ì‹¤ì œ ì„±ê³¼>\n",
    "   {task_performance_text}\n",
    "   </ì‹¤ì œ ì„±ê³¼>\n",
    "\n",
    "   JSON ì‘ë‹µ:\n",
    "   {{\n",
    "     \"ë‹¬ì„±ë¥ \": [ë‹¬ì„±ë¥  (0-100ì  ì´ìƒ)],\n",
    "     \"ë“±ê¸‰\": \"[S, A, B, C, D ì¤‘ í•˜ë‚˜]\",\n",
    "     \"ìƒì„¸ ë¶„ì„ ì½”ë©˜íŠ¸\": \"[Taskì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ì½”ë©˜íŠ¸]\"\n",
    "   }}\n",
    "   \"\"\"\n",
    "   \n",
    "   prompt = ChatPromptTemplate.from_messages([\n",
    "       SystemMessage(content=system_prompt),\n",
    "       HumanMessage(content=human_prompt)\n",
    "   ])\n",
    "   \n",
    "   chain = prompt | llm_client\n",
    "\n",
    "   try:\n",
    "       response: AIMessage = chain.invoke({\"target_level_text\": target_level_text, \"task_performance_text\": task_performance_text, \"grade_definitions\": grade_definitions})\n",
    "       json_output_raw = response.content\n",
    "       \n",
    "       json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "       \n",
    "       llm_parsed_data = json.loads(json_output)\n",
    "       \n",
    "       rate = llm_parsed_data.get(\"ë‹¬ì„±ë¥ \") \n",
    "       grade = llm_parsed_data.get(\"ë“±ê¸‰\") \n",
    "       analysis = llm_parsed_data.get(\"ìƒì„¸ ë¶„ì„ ì½”ë©˜íŠ¸\") \n",
    "\n",
    "       # ìˆ˜ì •ëœ ë¶€ë¶„: ë‹¬ì„±ë¥  ìœ íš¨ì„± ê²€ì‚¬ ìƒí•œ ì œê±°\n",
    "       if not isinstance(rate, (int, float)) or not (0 <= rate): \n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ë‹¬ì„±ë¥  {rate}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤).\")\n",
    "       if grade not in [\"S\", \"A\", \"B\", \"C\", \"D\"]:\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ë“±ê¸‰ {grade}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "       if not isinstance(analysis, str) or not analysis:\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ë¶„ì„ ì½”ë©˜íŠ¸ {analysis}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "       return {\"grade\": grade, \"rate\": round(float(rate), 2), \"analysis\": analysis}\n",
    "\n",
    "   except json.JSONDecodeError as e:\n",
    "       print(f\"LLM ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\"grade\": \"D\", \"rate\": 0.0, \"analysis\": f\"AI ë¶„ì„ ì‹¤íŒ¨: JSON íŒŒì‹± ì˜¤ë¥˜ - {json_output_raw[:100]}...\"}\n",
    "   except ValueError as e:\n",
    "       print(f\"LLM ì‘ë‹µ ë°ì´í„° ìœ íš¨ì„± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\"grade\": \"D\", \"rate\": 0.0, \"analysis\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ìœ íš¨ì„± ì˜¤ë¥˜ - {json_output_raw[:100]}...\"}\n",
    "   except Exception as e:\n",
    "       print(f\"LLM í˜¸ì¶œ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'\")\n",
    "       return {\"grade\": \"D\", \"rate\": 0.0, \"analysis\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ - {str(e)[:100]}...\"}\n",
    "\n",
    "\n",
    "def call_llm_for_overall_contribution_summary(all_individual_task_results: List[Dict], emp_name: str, emp_no: str) -> Dict: \n",
    "   print(f\"LLM Call (Overall Contribution Summary): '{emp_name} ({emp_no})' Task {len(all_individual_task_results)}ê°œ ê¸°ë°˜ ìš”ì•½ ìš”ì²­.\") \n",
    "\n",
    "   task_details_str = \"\"\n",
    "   for task in all_individual_task_results:\n",
    "       task_details_str += f\"- Task: {task.get('task_name')} (ID: {task.get('task_id')})\\n\"\n",
    "       task_details_str += f\"  Summary: {task.get('task_summary', task.get('task_performance', ''))}\\n\"\n",
    "       if task.get('ai_contribution_score') is not None:\n",
    "           task_details_str += f\"  AI ê¸°ì—¬ë„: {task.get('ai_contribution_score')}ì \\n\"\n",
    "       if task.get('ai_achievement_rate') is not None:\n",
    "           task_details_str += f\"  AI ë‹¬ì„±ë¥ : {task.get('ai_achievement_rate')}%\\n\"\n",
    "       if task.get('ai_assessed_grade'):\n",
    "           task_details_str += f\"  AI ë“±ê¸‰: {task.get('ai_assessed_grade')}\\n\"\n",
    "       task_details_str += \"\\n\"\n",
    "\n",
    "   system_prompt = \"\"\"\n",
    "   ë‹¹ì‹ ì€ SK ì¡°ì§ì˜ HR ì„±ê³¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "   ì•„ë˜ ì œê³µëœ ê°œì¸ì˜ ëª¨ë“  Task ì •ë³´, Task Summary, ê·¸ë¦¬ê³  AIê°€ ë¶„ì„í•œ ê°œë³„ Task ê¸°ì—¬ë„/ë‹¬ì„±ë¥  ì ìˆ˜ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬,\n",
    "   ì´ ê°œì¸ì˜ ì´ì²´ì ì¸ ê¸°ì—¬ë„ ì ìˆ˜ (íŒ€ ë‚´ ìƒëŒ€ ë¹„ìœ¨, 0-100%)ë¥¼ ì¶”ì •í•˜ê³ ,\n",
    "   ì´ë¦„ê³¼ ì‚¬ë²ˆì„ ëª…ì‹œí•˜ë©° ê°œì¸ì˜ ì „ì²´ì ì¸ ì„±ê³¼ì™€ ê¸°ì—¬ì— ëŒ€í•œ ê°„ëµí•œ ì¢…í•© ì½”ë©˜íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "   ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì„œë¬¸ì´ë‚˜ ì¶”ê°€ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "   ì§ì› ì´ë¦„ì„ ì–¸ê¸‰í•  ë•ŒëŠ” ë°˜ë“œì‹œ \"ì´ë¦„(ì‚¬ë²ˆ)ë‹˜\" í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "   \"\"\"\n",
    "\n",
    "   human_prompt = f\"\"\"\n",
    "   <ê°œì¸ Task ì¢…í•© ì •ë³´>\n",
    "   {task_details_str}\n",
    "   </ê°œì¸ Task ì¢…í•© ì •ë³´>\n",
    "   <í‰ê°€ ëŒ€ìƒ ê°œì¸ ì •ë³´>\n",
    "   ì´ë¦„: {emp_name}\n",
    "   ì‚¬ë²ˆ: {emp_no}\n",
    "   </í‰ê°€ ëŒ€ìƒ ê°œì¸ ì •ë³´>\n",
    "\n",
    "   JSON ì‘ë‹µ:\n",
    "   {{\n",
    "     \"total_contribution\": [ê°œì¸ì˜ ì´ì²´ì ì¸ ê¸°ì—¬ë„ ì ìˆ˜ (0-100ì )],\n",
    "     \"comment\": \"[{emp_name}({emp_no})ë‹˜ì˜ ì „ì²´ ì„±ê³¼ì™€ ê¸°ì—¬ì— ëŒ€í•œ ì¢…í•© ì½”ë©˜íŠ¸]\",\n",
    "     \"average_rate\": [Task ë‹¬ì„±ë¥ ë“¤ì˜ í‰ê·  ë˜ëŠ” ì¢…í•©ì ì¸ ë‹¬ì„±ë¥  ì¶”ì • (0-100ì  ì´ìƒ)]\n",
    "   }}\n",
    "   \"\"\"\n",
    "\n",
    "\n",
    "   \n",
    "   prompt = ChatPromptTemplate.from_messages([\n",
    "       SystemMessage(content=system_prompt),\n",
    "       HumanMessage(content=human_prompt)\n",
    "   ])\n",
    "   \n",
    "   chain = prompt | llm_client\n",
    "\n",
    "   try:\n",
    "       response: AIMessage = chain.invoke({\"all_individual_task_results\": all_individual_task_results, \"emp_name\": emp_name, \"emp_no\": emp_no})\n",
    "       json_output_raw = response.content\n",
    "       \n",
    "       json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "       \n",
    "       llm_parsed_data = json.loads(json_output)\n",
    "       \n",
    "       total_contribution = llm_parsed_data.get(\"total_contribution\")\n",
    "       comment = llm_parsed_data.get(\"comment\")\n",
    "       average_rate = llm_parsed_data.get(\"average_rate\")\n",
    "\n",
    "       if not isinstance(total_contribution, (int, float)) or not (0 <= total_contribution <= 100):\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ì´ ê¸°ì—¬ë„ {total_contribution}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "       if not isinstance(comment, str) or not comment:\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ì½”ë©˜íŠ¸ {comment}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "       if not isinstance(average_rate, (int, float)) or not (0 <= average_rate): # 0-120ì  -> 0ì  ì´ìƒìœ¼ë¡œ ìˆ˜ì •\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ í‰ê·  ë‹¬ì„±ë¥  {average_rate}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤).\")\n",
    "\n",
    "       return {\"total_contribution\": round(float(total_contribution), 2), \"comment\": comment, \"average_rate\": round(float(average_rate), 2)}\n",
    "\n",
    "   except json.JSONDecodeError as e:\n",
    "       print(f\"LLM ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\"total_contribution\": 0.0, \"comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: JSON íŒŒì‹± ì˜¤ë¥˜ - {json_output_raw[:100]}...\", \"average_rate\": 0.0}\n",
    "   except ValueError as e:\n",
    "       print(f\"LLM ì‘ë‹µ ë°ì´í„° ìœ íš¨ì„± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\"total_contribution\": 0.0, \"comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ìœ íš¨ì„± ì˜¤ë¥˜ - {json_output_raw[:100]}...\", \"average_rate\": 0.0}\n",
    "   except Exception as e:\n",
    "       print(f\"LLM í˜¸ì¶œ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'\")\n",
    "       return {\"total_contribution\": 0.0, \"comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ - {str(e)[:100]}...\", \"average_rate\": 0.0}\n",
    "\n",
    "\n",
    "def call_llm_for_cumulative_task_contribution(\n",
    "   task_id: int,\n",
    "   combined_summary: str, \n",
    "   cumulative_performance: str,\n",
    "   target_level: str,\n",
    "   emp_name: str\n",
    ") -> Dict:\n",
    "   \n",
    "   print(f\"LLM Call (Cumulative Task Contribution): Task {task_id} for {emp_name}\")\n",
    "\n",
    "   system_prompt = \"\"\"\n",
    "   ë‹¹ì‹ ì€ SK ì¡°ì§ì˜ ì„±ê³¼ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "   ì•„ë˜ëŠ” íŠ¹ì • Taskì— ëŒ€í•œ ë¶„ê¸°ë³„ ì—…ë¬´ ì§„í–‰ ê³¼ì •ê³¼ ëˆ„ì  ì„±ê³¼ì…ë‹ˆë‹¤.\n",
    "   \n",
    "   ë¶„ê¸°ë³„ ì—…ë¬´ ì§„í–‰ ê³¼ì •ê³¼ ëˆ„ì  ì„±ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ í•´ë‹¹ Taskì˜ ì „ì²´ì ì¸ ê¸°ì—¬ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "   \n",
    "   í‰ê°€ ì‹œ ë‹¤ìŒì„ ê³ ë ¤í•©ë‹ˆë‹¤:\n",
    "   - ë¶„ê¸°ë³„ ì—…ë¬´ ì§„í–‰ì˜ ì—°ì†ì„±ê³¼ ë°œì „ì„±\n",
    "   - ëˆ„ì  ì„±ê³¼ì˜ í’ˆì§ˆê³¼ ì™„ì„±ë„\n",
    "   - ëª©í‘œ ëŒ€ë¹„ í˜„ì¬ê¹Œì§€ì˜ ë‹¬ì„± ìˆ˜ì¤€\n",
    "   - Taskì˜ ë³µì¡ì„±ê³¼ ì¤‘ìš”ë„\n",
    "   - ë‹¤ë¥¸ ì—…ë¬´ë‚˜ íŒ€ì›ì—ê²Œ ë¯¸ì¹œ ê¸ì •ì  ì˜í–¥\n",
    "   \n",
    "   ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì„œë¬¸ì´ë‚˜ ì¶”ê°€ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "   \"\"\"\n",
    "   \n",
    "   human_prompt = f\"\"\"\n",
    "   <Task ê¸°ë³¸ ì •ë³´>\n",
    "   Task ID: {task_id}\n",
    "   ë‹´ë‹¹ì: {emp_name}ë‹˜\n",
    "   ëª©í‘œ: {target_level}\n",
    "   </Task ê¸°ë³¸ ì •ë³´>\n",
    "   \n",
    "   <ë¶„ê¸°ë³„ ì—…ë¬´ ì§„í–‰ ê³¼ì •>\n",
    "   {combined_summary}\n",
    "   </ë¶„ê¸°ë³„ ì—…ë¬´ ì§„í–‰ ê³¼ì •>\n",
    "   \n",
    "   <ëˆ„ì  ì„±ê³¼>\n",
    "   {cumulative_performance}\n",
    "   </ëˆ„ì  ì„±ê³¼>\n",
    "   \n",
    "   JSON ì‘ë‹µ:\n",
    "   {{\n",
    "     \"score\": [ëˆ„ì  ê¸°ì—¬ë„ ì ìˆ˜ (0-100ì , ì†Œìˆ˜ì  ì²«ì§¸ ìë¦¬ê¹Œì§€)],\n",
    "     \"comment\": \"[ë¶„ê¸°ë³„ ì§„í–‰ê³¼ì •ê³¼ ëˆ„ì  ì„±ê³¼ë¥¼ ì¢…í•©í•œ ìƒì„¸ ë¶„ì„ ì½”ë©˜íŠ¸]\"\n",
    "   }}\n",
    "   \"\"\"\n",
    "   \n",
    "   prompt = ChatPromptTemplate.from_messages([\n",
    "       SystemMessage(content=system_prompt),\n",
    "       HumanMessage(content=human_prompt)\n",
    "   ])\n",
    "   \n",
    "   chain = prompt | llm_client\n",
    "\n",
    "   try:\n",
    "       response: AIMessage = chain.invoke({\n",
    "           \"task_id\": task_id,\n",
    "           \"combined_summary\": combined_summary,\n",
    "           \"cumulative_performance\": cumulative_performance,\n",
    "           \"target_level\": target_level,\n",
    "           \"emp_name\": emp_name\n",
    "       })\n",
    "       json_output_raw = response.content\n",
    "\n",
    "       json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "\n",
    "       llm_parsed_data = json.loads(json_output)\n",
    "\n",
    "       score = llm_parsed_data.get(\"score\") \n",
    "       comment = llm_parsed_data.get(\"comment\") \n",
    "\n",
    "       if not isinstance(score, (int, float)) or not (0 <= score <= 100):\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ì ìˆ˜ {score}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "       if not isinstance(comment, str) or not comment:\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ì½”ë©˜íŠ¸ {comment}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "       return {\"score\": round(float(score), 2), \"comment\": comment}\n",
    "       \n",
    "   except json.JSONDecodeError as e:\n",
    "       print(f\"LLM ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\"score\": 0.0, \"comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: JSON íŒŒì‹± ì˜¤ë¥˜ - {json_output_raw[:100]}...\"}\n",
    "   except ValueError as e:\n",
    "       print(f\"LLM ì‘ë‹µ ë°ì´í„° ìœ íš¨ì„± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\"score\": 0.0, \"comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ìœ íš¨ì„± ì˜¤ë¥˜ - {json_output_raw[:100]}...\"}\n",
    "   except Exception as e:\n",
    "       print(f\"LLM í˜¸ì¶œ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'\")\n",
    "       return {\"score\": 0.0, \"comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ - {str(e)[:100]}...\"}\n",
    "\n",
    "def call_llm_for_team_overall_analysis(all_team_kpis_results: List[Dict]) -> Dict:\n",
    "   print(f\"LLM Call (Team Overall Analysis): KPI {len(all_team_kpis_results)}ê°œ ê¸°ë°˜ ë¶„ì„ ìš”ì²­.\")\n",
    "\n",
    "   kpi_details_str = \"\"\n",
    "   for kpi in all_team_kpis_results:\n",
    "       kpi_details_str += f\"- KPI: {kpi.get('kpi_name')} (ID: {kpi.get('team_kpi_id')})\\n\"\n",
    "       kpi_details_str += f\"  Description: {kpi.get('kpi_description')}\\n\"\n",
    "       if kpi.get('ai_kpi_overall_progress_rate') is not None:\n",
    "           kpi_details_str += f\"  AI ì§„í–‰ë¥ : {kpi.get('ai_kpi_overall_progress_rate')}%\\n\"\n",
    "       if kpi.get('ai_kpi_analysis_comment'):\n",
    "           kpi_details_str += f\"  AI ì½”ë©˜íŠ¸: {kpi.get('ai_kpi_analysis_comment')}\\n\"\n",
    "       kpi_details_str += \"\\n\"\n",
    "\n",
    "   system_prompt = \"\"\"\n",
    "   ë‹¹ì‹ ì€ SK ì¡°ì§ì˜ ê³ ìœ„ ê²½ì˜ì§„ì„ ìœ„í•œ íŒ€ ì„±ê³¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "   ì•„ë˜ ì œê³µëœ íŒ€ì˜ KPI ì •ë³´, ì„¤ëª…, ê·¸ë¦¬ê³  AIê°€ ë¶„ì„í•œ ê° KPIì˜ ì§„í–‰ë¥  ë° ì½”ë©˜íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ì—¬,\n",
    "   ì´ íŒ€ì˜ ì „ë°˜ì ì¸ ëª©í‘œ ë‹¬ì„±ë¥ ì„ ì¶”ì •í•˜ê³ , íŒ€ ì„±ê³¼ì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ê°œì„ ì ì— ëŒ€í•œ ë¶„ì„ ì½”ë©˜íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "   ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì„œë¬¸ì´ë‚˜ ì¶”ê°€ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "   \"\"\"\n",
    "\n",
    "   human_prompt = f\"\"\"\n",
    "   <íŒ€ KPI ì¢…í•© ì •ë³´>\n",
    "   {kpi_details_str}\n",
    "   </íŒ€ KPI ì¢…í•© ì •ë³´>\n",
    "\n",
    "   JSON ì‘ë‹µ:\n",
    "   {{\n",
    "     \"overall_rate\": [íŒ€ ì „ì²´ì˜ ëª©í‘œ ë‹¬ì„±ë¥  ì¶”ì • (0-100ì )],\n",
    "     \"comment\": \"[íŒ€ ì„±ê³¼ì— ëŒ€í•œ ì „ë°˜ì ì¸ ë¶„ì„ ì½”ë©˜íŠ¸]\"\n",
    "   }}\n",
    "   \"\"\"\n",
    "   \n",
    "   prompt = ChatPromptTemplate.from_messages([\n",
    "       SystemMessage(content=system_prompt),\n",
    "       HumanMessage(content=human_prompt)\n",
    "   ])\n",
    "   \n",
    "   chain = prompt | llm_client\n",
    "\n",
    "   try:\n",
    "       response: AIMessage = chain.invoke({\"all_team_kpis_results\": all_team_kpis_results})\n",
    "       json_output_raw = response.content\n",
    "       \n",
    "       json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "       \n",
    "       llm_parsed_data = json.loads(json_output)\n",
    "       \n",
    "       overall_rate = llm_parsed_data.get(\"overall_rate\")\n",
    "       comment = llm_parsed_data.get(\"comment\")\n",
    "\n",
    "       if not isinstance(overall_rate, (int, float)) or not (0 <= overall_rate <= 100):\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ì „ì²´ ë‹¬ì„±ë¥  {overall_rate}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "       if not isinstance(comment, str) or not comment:\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ì½”ë©˜íŠ¸ {comment}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "       return {\"overall_rate\": round(float(overall_rate), 2), \"comment\": comment}\n",
    "\n",
    "   except json.JSONDecodeError as e:\n",
    "       print(f\"LLM ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\"overall_rate\": 0.0, \"comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: JSON íŒŒì‹± ì˜¤ë¥˜ - {json_output_raw[:100]}...\"}\n",
    "   except ValueError as e:\n",
    "       print(f\"LLM ì‘ë‹µ ë°ì´í„° ìœ íš¨ì„± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\"overall_rate\": 0.0, \"comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ìœ íš¨ì„± ì˜¤ë¥˜ - {json_output_raw[:100]}...\"}\n",
    "   except Exception as e:\n",
    "       print(f\"LLM í˜¸ì¶œ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'\")\n",
    "       return {\"overall_rate\": 0.0, \"comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ - {str(e)[:100]}...\"}\n",
    "\n",
    "\n",
    "def call_llm_for_kpi_relative_contribution(kpi_analysis_input: Dict) -> Dict:\n",
    "   kpi_goal = kpi_analysis_input.get(\"kpi_goal\", \"ì•Œ ìˆ˜ ì—†ëŠ” ëª©í‘œ\")\n",
    "   kpi_description = kpi_analysis_input.get(\"kpi_description\", \"\")\n",
    "   team_tasks = kpi_analysis_input.get(\"team_members_tasks\", [])\n",
    "   \n",
    "   print(f\"LLM Call (KPI Relative Contribution): '{kpi_goal[:30]}...' KPI ë‚´ ê°œì¸ë³„ ìƒëŒ€ ê¸°ì—¬ë„ ë¶„ì„ ìš”ì²­.\")\n",
    "   \n",
    "   actual_emp_nos_in_kpi = sorted(list(set(task.get('emp_no') for task in team_tasks if task.get('emp_no'))))\n",
    "\n",
    "   system_prompt = \"\"\"\n",
    "   ë‹¹ì‹ ì€ íŒ€ KPI ì„±ê³¼ì— ëŒ€í•œ ê°œì¸ë³„ ê¸°ì—¬ë„ë¥¼ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "   ì•„ë˜ëŠ” íŠ¹ì • íŒ€ KPIì˜ ëª©í‘œ, ì„¤ëª…, ê·¸ë¦¬ê³  ì´ KPIì— ê¸°ì—¬í•œ íŒ€ì›ë“¤ì˜ Task ìƒì„¸ ë‚´ìš© ë° AIê°€ ë¶„ì„í•œ ê°œë³„ Task ê¸°ì—¬ë„ ì ìˆ˜ì…ë‹ˆë‹¤.\n",
    "   \n",
    "   ì´ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "   1. ì´ KPIì— ëŒ€í•œ ê° ê°œì¸ì˜ **ìƒëŒ€ì ì¸ ê¸°ì—¬ë„ ì ìˆ˜ (ì´í•© 100%)**ë¥¼ íŒë‹¨í•˜ì„¸ìš”.\n",
    "      - ë°˜í™˜í•˜ëŠ” JSONì˜ `individual_relative_contributions_in_kpi` ë”•ì…”ë„ˆë¦¬ì—ëŠ” ì•„ë˜ <ì‹¤ì œ íŒ€ì› ì‚¬ë²ˆ ëª©ë¡>ì— ìˆëŠ” ëª¨ë“  ì‚¬ë²ˆì— ëŒ€í•´ ê¸°ì—¬ë„ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "      - ê° ê°œì¸ì˜ ê¸°ì—¬ë„ ì ìˆ˜(0-100ì )ëŠ” ì†Œìˆ˜ì  ë‘ ìë¦¬ê¹Œì§€ í—ˆìš©í•©ë‹ˆë‹¤.\n",
    "      - ì–´ë–¤ íŒ€ì›ì˜ ê¸°ì—¬ë„ê°€ 0%ì´ë”ë¼ë„ í•´ë‹¹ ì‚¬ë²ˆê³¼ 0ì ì„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "      - ëª¨ë“  íŒ€ì›ì˜ ê¸°ì—¬ë„ í•©ê³„ê°€ 100%ê°€ ë˜ë„ë¡ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "   2. KPI ì „ì²´ì˜ ì§„í–‰ ìƒí™©ì— ëŒ€í•œ ê°„ëµí•œ ë¶„ì„ ì½”ë©˜íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "   í‰ê°€ ì‹œ ë‹¤ìŒì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "   - ê° Taskì˜ ë‚´ìš©ì´ KPI ëª©í‘œ ë‹¬ì„±ì— ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œê°€?\n",
    "   - ê° Taskì˜ AI ê¸°ì—¬ë„ ì ìˆ˜ëŠ” ì–´ë–¤ ì˜ë¯¸ì¸ê°€? (ê°œë³„ Taskì˜ í’ˆì§ˆ ë° ì¤‘ìš”ë„)\n",
    "   - íŒ€ì› ê°„ Taskì˜ ìƒí˜¸ ì˜ì¡´ì„±, ì„ í–‰/í›„í–‰ ê´€ê³„, í˜‘ì—… ê¸°ì—¬ë„\n",
    "   - íŠ¹ì • íŒ€ì›ì´ ì—¬ëŸ¬ Taskë¥¼ ìˆ˜í–‰í–ˆê±°ë‚˜, ë” ì¤‘ìš”í•œ Taskë¥¼ ìˆ˜í–‰í–ˆëŠ”ê°€?\n",
    "   - ê²°ê³¼ë¬¼ JSONì— ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "   - ì§ì› ì´ë¦„ì„ ì–¸ê¸‰í•  ë•ŒëŠ” ë°˜ë“œì‹œ \"ì´ë¦„(ì‚¬ë²ˆ)ë‹˜\" í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "\n",
    "   ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:\n",
    "   \"\"\"\n",
    "\n",
    "   team_tasks_str = \"\"\n",
    "   for task in team_tasks:\n",
    "       emp_name = task.get('emp_name', 'ì´ë¦„ì—†ìŒ') \n",
    "       emp_no = task.get('emp_no', 'ì‚¬ë²ˆì—†ìŒ')\n",
    "       team_tasks_str += f\"- íŒ€ì›: {emp_name}({emp_no})ë‹˜, Task: {task.get('task_name')}\\n\" \n",
    "       team_tasks_str += f\"  ìš”ì•½: {task.get('task_summary')}\\n\"\n",
    "       if task.get('ai_contribution_score_from_individual_analysis') is not None:\n",
    "           team_tasks_str += f\"  ê°œë³„ AI ê¸°ì—¬ë„ ì ìˆ˜ (ì°¸ê³ ìš©): {task.get('ai_contribution_score_from_individual_analysis')}ì \\n\"\n",
    "       team_tasks_str += \"\\n\"\n",
    "\n",
    "\n",
    "   individual_contributions_json_example = \",\\n\".join([f'\"{emp_no}\": [ìƒëŒ€ ê¸°ì—¬ë„ (0-100ì )]' for emp_no in actual_emp_nos_in_kpi])\n",
    "   if not individual_contributions_json_example:\n",
    "       individual_contributions_json_example = '\"EMP_NO_X\": [ìƒëŒ€ ê¸°ì—¬ë„ (0-100ì )]'\n",
    "\n",
    "   human_prompt = f\"\"\"\n",
    "   <íŒ€ KPI ëª©í‘œ>\n",
    "   {kpi_goal}\n",
    "   </íŒ€ KPI ëª©í‘œ>\n",
    "   <íŒ€ KPI ì„¤ëª…>\n",
    "   {kpi_description}\n",
    "   </íŒ€ KPI ì„¤ëª…>\n",
    "   <íŒ€ì› Task ì •ë³´>\n",
    "   {team_tasks_str}\n",
    "   </íŒ€ì› Task ì •ë³´>\n",
    "   <ì‹¤ì œ íŒ€ì› ì‚¬ë²ˆ ëª©ë¡>\n",
    "   {', '.join(actual_emp_nos_in_kpi) if actual_emp_nos_in_kpi else 'ì—†ìŒ'}\n",
    "   </ì‹¤ì œ íŒ€ì› ì‚¬ë²ˆ ëª©ë¡>\n",
    "\n",
    "   JSON ì‘ë‹µ:\n",
    "   {{\n",
    "     \"kpi_overall_rate\": [KPI ì „ì²´ì˜ ì§„í–‰ ìƒí™©ì— ëŒ€í•œ ì ìˆ˜ (0-100ì )],\n",
    "     \"kpi_analysis_comment\": \"[KPI ì „ì²´ ì§„í–‰ ìƒí™©ì— ëŒ€í•œ ë¶„ì„ ì½”ë©˜íŠ¸]\",\n",
    "     \"individual_relative_contributions_in_kpi\": {{\n",
    "       {individual_contributions_json_example}\n",
    "     }}\n",
    "   }}\n",
    "   \"\"\"\n",
    "   \n",
    "   prompt = ChatPromptTemplate.from_messages([\n",
    "       SystemMessage(content=system_prompt),\n",
    "       HumanMessage(content=human_prompt)\n",
    "   ])\n",
    "   \n",
    "   chain = prompt | llm_client\n",
    "\n",
    "   try:\n",
    "       response: AIMessage = chain.invoke({\"kpi_analysis_input\": kpi_analysis_input})\n",
    "       json_output_raw = response.content\n",
    "       json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "       \n",
    "       llm_parsed_data = json.loads(json_output)\n",
    "       \n",
    "       kpi_overall_rate = llm_parsed_data.get(\"kpi_overall_rate\")\n",
    "       kpi_analysis_comment = llm_parsed_data.get(\"kpi_analysis_comment\")\n",
    "       individual_relative_contributions_raw_from_llm = llm_parsed_data.get(\"individual_relative_contributions_in_kpi\")\n",
    "\n",
    "       if not isinstance(kpi_overall_rate, (int, float)) or not (0 <= kpi_overall_rate <= 100):\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ KPI ì „ì²´ ì§„í–‰ë¥  {kpi_overall_rate}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "       if not isinstance(kpi_analysis_comment, str) or not kpi_analysis_comment:\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ KPI ë¶„ì„ ì½”ë©˜íŠ¸ {kpi_analysis_comment}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "       if not isinstance(individual_relative_contributions_raw_from_llm, dict):\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ê°œì¸ ìƒëŒ€ ê¸°ì—¬ë„ í˜•ì‹ {individual_relative_contributions_raw_from_llm}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "       \n",
    "       # --- íŒŒì‹± ë¡œì§ ë³´ê°•: LLMì´ ë°˜í™˜í•œ ì‚¬ë²ˆ ì™¸ì˜ ì‚¬ë²ˆ ì²˜ë¦¬ ë° í•©ê³„ ê²€ì¦ ---\n",
    "       final_relative_contributions = {}\n",
    "       for emp_no in actual_emp_nos_in_kpi:\n",
    "           final_relative_contributions[emp_no] = 0.0\n",
    "       \n",
    "       for emp_no_from_llm, score in individual_relative_contributions_raw_from_llm.items():\n",
    "           if emp_no_from_llm in final_relative_contributions and isinstance(score, (int, float)):\n",
    "               final_relative_contributions[emp_no_from_llm] = round(float(score), 2)\n",
    "           else:\n",
    "               print(f\"Warning: LLMì´ ì˜ˆìƒì¹˜ ëª»í•œ ì‚¬ë²ˆ '{emp_no_from_llm}'ë¥¼ ë°˜í™˜í–ˆê±°ë‚˜ ì ìˆ˜ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ë¬´ì‹œë©ë‹ˆë‹¤. ì ìˆ˜: {score}\")\n",
    "\n",
    "       total_relative_sum = sum(final_relative_contributions.values())\n",
    "       if total_relative_sum > 0 and not (99.9 <= total_relative_sum <= 100.1):\n",
    "           print(f\"Warning: ê°œì¸ ìƒëŒ€ ê¸°ì—¬ë„ í•©ê³„ê°€ 100%ì™€ ë‹¤ë¦…ë‹ˆë‹¤: {total_relative_sum}%. ì¬ì¡°ì • ì‹œë„.\")\n",
    "           adjustment_factor = 100.0 / total_relative_sum if total_relative_sum > 0 else 1.0\n",
    "           adjusted_contributions = {k: round(v * adjustment_factor, 2) for k, v in final_relative_contributions.items()}\n",
    "           final_relative_contributions = adjusted_contributions\n",
    "           print(f\"ì¬ì¡°ì •ëœ ê¸°ì—¬ë„: {final_relative_contributions}\")\n",
    "           \n",
    "       return {\n",
    "           \"kpi_overall_rate\": round(float(kpi_overall_rate), 2),\n",
    "           \"kpi_analysis_comment\": kpi_analysis_comment,\n",
    "           \"individual_relative_contributions_in_kpi\": final_relative_contributions\n",
    "       }\n",
    "       \n",
    "   except json.JSONDecodeError as e:\n",
    "       print(f\"LLM ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\n",
    "           \"kpi_overall_rate\": 0.0,\n",
    "           \"kpi_analysis_comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: JSON íŒŒì‹± ì˜¤ë¥˜ - {json_output_raw[:100]}...\",\n",
    "           \"individual_relative_contributions_in_kpi\": {}\n",
    "       }\n",
    "   except ValueError as e:\n",
    "       print(f\"LLM ì‘ë‹µ ë°ì´í„° ìœ íš¨ì„± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\n",
    "           \"kpi_overall_rate\": 0.0,\n",
    "           \"kpi_analysis_comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ìœ íš¨ì„± ì˜¤ë¥˜ - {json_output_raw[:100]}...\",\n",
    "           \"individual_relative_contributions_in_kpi\": {}\n",
    "       }\n",
    "   except Exception as e:\n",
    "       print(f\"LLM í˜¸ì¶œ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'\")\n",
    "       return {\n",
    "           \"kpi_overall_rate\": 0.0,\n",
    "           \"kpi_analysis_comment\": f\"AI ë¶„ì„ ì‹¤íŒ¨: ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ - {str(e)[:100]}...\",\n",
    "           \"individual_relative_contributions_in_kpi\": {}\n",
    "       }\n",
    "   \n",
    "\n",
    "\n",
    "def call_llm_for_individual_contribution_reason_comment(\n",
    "   task_info: Dict, \n",
    "   adjusted_contribution_score: float, \n",
    "   kpi_goal: str, \n",
    "   kpi_overall_comment: str) -> Dict:\n",
    "   \n",
    "   emp_name = task_info.get(\"emp_name\", \"ì´ë¦„ ì—†ìŒ\")\n",
    "   emp_no = task_info.get(\"emp_no\", \"ì‚¬ë²ˆ ì—†ìŒ\")\n",
    "   task_name = task_info.get(\"task_name\", \"ì•Œ ìˆ˜ ì—†ëŠ” Task\")\n",
    "   \n",
    "   # --- ìˆ˜ì •: ëˆ„ì  ìš”ì•½ ì •ë³´ ìš°ì„  ì‚¬ìš© ---\n",
    "   task_summary_text = task_info.get(\"cumulative_task_summary\", \n",
    "                                    task_info.get(\"task_summary\", \"ìƒì„¸ ë‚´ìš© ì—†ìŒ\"))\n",
    "\n",
    "   print(f\"LLM Call (Individual Contribution Reason): '{emp_name} ({emp_no})'ì˜ '{task_name[:30]}...' Task ê·¼ê±° ìš”ì²­.\")\n",
    "\n",
    "   system_prompt = \"\"\"\n",
    "   ë‹¹ì‹ ì€ SK ì¡°ì§ì˜ ì„±ê³¼ í‰ê°€ ì „ë¬¸ê°€ì´ì ëª…í™•í•œ ê·¼ê±°ë¥¼ ì œì‹œí•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n",
    "   ì•„ë˜ ì œê³µëœ ê°œì¸ì˜ íŠ¹ì • Task ìƒì„¸ ë‚´ìš©, ì´ Taskê°€ ì†í•œ KPIì˜ ëª©í‘œ, ê·¸ë¦¬ê³  íŒ€ ì „ì²´ì— ëŒ€í•œ KPI ë¶„ì„ ì½”ë©˜íŠ¸ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬,\n",
    "   ì´ Taskì˜ ìµœì¢… ì¡°ì •ëœ ê¸°ì—¬ë„ ì ìˆ˜(KPI ë‚´ ìƒëŒ€ì  ê¸°ì—¬ë„)ê°€ ì™œ ê·¸ë ‡ê²Œ ì‚°ì •ë˜ì—ˆëŠ”ì§€ì— ëŒ€í•œ êµ¬ì²´ì ì´ê³  ë³µí•©ì ì¸ ê·¼ê±° ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "   ì½”ë©˜íŠ¸ëŠ” ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "   - Task ìì²´ì˜ ë‚´ìš©ê³¼ ì¤‘ìš”ë„ (ì „ì²´ ë¶„ê¸°ë³„ í™œë™ ê¸°ë°˜)\n",
    "   - LLMì´ íŒë‹¨í•œ KPI ë‚´ ìƒëŒ€ì  ê¸°ì—¬ë„ ì ìˆ˜ (ì œì‹œëœ ì ìˆ˜ í™œìš©)\n",
    "   - ì´ Taskê°€ íŒ€ KPI ëª©í‘œ ë‹¬ì„±ì— ì–´ë–»ê²Œ ê¸°ì—¬í–ˆëŠ”ì§€ (KPI ëª©í‘œ, ì „ì²´ KPI ì½”ë©˜íŠ¸ ê¸°ë°˜)\n",
    "   - Task ê°„ì˜ ìƒí˜¸ ê´€ê³„ë‚˜ í˜‘ì—… ë“±ì˜ ë§¥ë½ì´ ê¸°ì—¬ë„ì— ë¯¸ì¹œ ì˜í–¥ (ì œê³µëœ ì •ë³´ ë‚´ì—ì„œ ì¶”ë¡ )\n",
    "   - ì§ì› ì´ë¦„ì„ ì–¸ê¸‰í•  ë•ŒëŠ” ë°˜ë“œì‹œ \"ì´ë¦„(ì‚¬ë²ˆ)ë‹˜\" í˜•íƒœë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "   ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì„œë¬¸ì´ë‚˜ ì¶”ê°€ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "   \"\"\"\n",
    "\n",
    "   human_prompt = f\"\"\"\n",
    "   <Task ìƒì„¸ ì •ë³´>\n",
    "   ì´ë¦„: {emp_name}\n",
    "   ì‚¬ë²ˆ: {emp_no}\n",
    "   Task ì´ë¦„: {task_name}\n",
    "   Task ì—°ê°„ ëˆ„ì  í™œë™/ì„±ê³¼: {task_summary_text}\n",
    "   ì¡°ì •ëœ ê¸°ì—¬ë„ ì ìˆ˜: {adjusted_contribution_score}ì \n",
    "   </Task ìƒì„¸ ì •ë³´>\n",
    "\n",
    "   <KPI ì •ë³´>\n",
    "   KPI ëª©í‘œ: {kpi_goal}\n",
    "   KPI ì „ì²´ ë¶„ì„ ì½”ë©˜íŠ¸: {kpi_overall_comment}\n",
    "   </KPI ì •ë³´>\n",
    "\n",
    "   JSON ì‘ë‹µ:\n",
    "   {{\n",
    "     \"comment_reason\": \"[{emp_name}({emp_no})ë‹˜ì˜ í•´ë‹¹ Taskì— ëŒ€í•œ êµ¬ì²´ì  ê·¼ê±° ì½”ë©˜íŠ¸]\"\n",
    "   }}\n",
    "   \"\"\"\n",
    "\n",
    "   prompt = ChatPromptTemplate.from_messages([\n",
    "       SystemMessage(content=system_prompt),\n",
    "       HumanMessage(content=human_prompt)\n",
    "   ])\n",
    "   \n",
    "   chain = prompt | llm_client\n",
    "\n",
    "   try:\n",
    "       response: AIMessage = chain.invoke({\n",
    "           \"task_info\": task_info, \n",
    "           \"adjusted_contribution_score\": adjusted_contribution_score, \n",
    "           \"kpi_goal\": kpi_goal, \n",
    "           \"kpi_overall_comment\": kpi_overall_comment\n",
    "       })\n",
    "       json_output_raw = response.content\n",
    "       json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "       llm_parsed_data = json.loads(json_output)\n",
    "       \n",
    "       comment_reason = llm_parsed_data.get(\"comment_reason\")\n",
    "\n",
    "       if not isinstance(comment_reason, str) or not comment_reason:\n",
    "           raise ValueError(f\"LLM ë°˜í™˜ ê·¼ê±° ì½”ë©˜íŠ¸ {comment_reason}ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "       return {\"comment\": comment_reason}\n",
    "       \n",
    "   except json.JSONDecodeError as e:\n",
    "       print(f\"LLM ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'. íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸: '{json_output[:100]}...'\")\n",
    "       return {\"comment\": f\"AI ê·¼ê±° ìƒì„± ì‹¤íŒ¨: JSON íŒŒì‹± ì˜¤ë¥˜ - {json_output_raw[:100]}...\"}\n",
    "   except ValueError as e:\n",
    "       print(f\"LLM ì‘ë‹µ ë°ì´í„° ìœ íš¨ì„± ì˜¤ë¥˜: {e}. ì‘ë‹µ: {json_output}\")\n",
    "       return {\"comment\": f\"AI ê·¼ê±° ìƒì„± ì‹¤íŒ¨: ìœ íš¨ì„± ì˜¤ë¥˜ - {json_output[:100]}...\"}\n",
    "   except Exception as e:\n",
    "        print(f\"LLM í˜¸ì¶œ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}. ì›ë³¸ ì‘ë‹µ: '{json_output_raw}'\")\n",
    "        return {\"comment\": f\"AI ê·¼ê±° ìƒì„± ì‹¤íŒ¨: ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ - {str(e)[:100]}...\"}\n",
    "\n",
    "\n",
    "# --- ì„œë¸Œëª¨ë“ˆ í•¨ìˆ˜ ì •ì˜ ---\n",
    "\n",
    "# 1. ë°ì´í„° ìˆ˜ì§‘ ì„œë¸Œëª¨ë“ˆ\n",
    "def data_collection_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "   messages = state.get(\"messages\", []) + [HumanMessage(content=\"ëª¨ë“ˆ 2: ë°ì´í„° ìˆ˜ì§‘ ID ì´ˆê¸°í™” ì™„ë£Œ\")] \n",
    "   return {\"messages\": messages}\n",
    "\n",
    "\n",
    "# 2. ê°œì¸ ê¸°ì—¬ë„ ê³„ì‚° ì„œë¸Œëª¨ë“ˆ\n",
    "def calculate_individual_contribution_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "    report_type = state[\"report_type\"] \n",
    "    target_task_ids = state[\"target_task_ids\"]\n",
    "    period_id = state[\"period_id\"]\n",
    "    \n",
    "    updated_task_summary_ids_list = []\n",
    "\n",
    "    for task_id in target_task_ids:\n",
    "        task_summaries = fetch_task_summaries_by_task_and_period(task_id, period_id)\n",
    "        \n",
    "        if not task_summaries:\n",
    "            print(f\"Warning: No task summaries found for task_id {task_id}.\")\n",
    "            continue\n",
    "        \n",
    "        # ğŸ”§ Taskë‹¹ 1ë²ˆë§Œ LLM í˜¸ì¶œ (ì „ì²´ ëˆ„ì  ë°ì´í„° ê¸°ë°˜)\n",
    "        latest_task_data = task_summaries[-1]  # ê°€ì¥ ìµœì‹  ë°ì´í„°\n",
    "        combined_summary = \"\\n\".join([f\"Q{summary['period_id']}: {summary['task_summary']}\" for summary in task_summaries])\n",
    "        cumulative_performance = latest_task_data.get('task_performance', '')\n",
    "        target_level = latest_task_data.get('target_level', '')\n",
    "        emp_name = latest_task_data.get('emp_name', '')\n",
    "        \n",
    "        # ğŸ”§ 1ë²ˆë§Œ í˜¸ì¶œ (ì „ì²´ ë¶„ê¸° ë°ì´í„° ê¸°ë°˜)\n",
    "        if report_type == \"quarterly\":\n",
    "            llm_results = call_llm_for_cumulative_task_contribution(\n",
    "                task_id, combined_summary, cumulative_performance, target_level, emp_name\n",
    "            )\n",
    "            base_update_data = {\n",
    "                \"ai_contribution_score\": llm_results.get(\"score\"), \n",
    "                \"ai_analysis_comment_task\": llm_results.get(\"comment\") \n",
    "            }\n",
    "        \n",
    "        elif report_type == \"annual\":\n",
    "            contribution_results = call_llm_for_cumulative_task_contribution(\n",
    "                task_id, combined_summary, cumulative_performance, target_level, emp_name\n",
    "            )\n",
    "            \n",
    "            if target_level and cumulative_performance:\n",
    "                grade_definitions = fetch_grade_definitions_from_db()\n",
    "                achievement_results = call_llm_for_task_achievement(\n",
    "                    target_level, cumulative_performance, grade_definitions\n",
    "                )\n",
    "                \n",
    "                base_update_data = {\n",
    "                    \"ai_contribution_score\": contribution_results.get(\"score\"), \n",
    "                    \"ai_achievement_rate\": achievement_results.get(\"rate\"), \n",
    "                    \"ai_assessed_grade\": achievement_results.get(\"grade\"), \n",
    "                    \"ai_analysis_comment_task\": achievement_results.get(\"analysis\") \n",
    "                }\n",
    "            else:\n",
    "                base_update_data = {\n",
    "                    \"ai_contribution_score\": contribution_results.get(\"score\"), \n",
    "                    \"ai_analysis_comment_task\": contribution_results.get(\"comment\") \n",
    "                }\n",
    "\n",
    "        # ğŸ”§ ê° ë¶„ê¸°ë³„ë¡œ ë¹„ë¡€ ë°°ë¶„í•˜ì—¬ ì €ì¥\n",
    "        for task_summary in task_summaries:\n",
    "            task_summary_id = task_summary.get('task_summary_Id')\n",
    "            current_period = task_summary.get('period_id')\n",
    "            \n",
    "            # ë¶„ê¸°ë³„ ë¹„ë¡€ ë°°ë¶„\n",
    "            period_weight = current_period / period_id\n",
    "            \n",
    "            update_data = base_update_data.copy()\n",
    "            if \"ai_contribution_score\" in update_data:\n",
    "                update_data[\"ai_contribution_score\"] = round(base_update_data[\"ai_contribution_score\"] * period_weight, 2)\n",
    "            \n",
    "            if update_task_summary_ai_results_in_db(task_summary_id, update_data):\n",
    "                updated_task_summary_ids_list.append(task_summary_id)\n",
    "\n",
    "    messages = state.get(\"messages\", []) + [HumanMessage(content=f\"ëª¨ë“ˆ 2: ê°œì¸ ê¸°ì—¬ë„ ê³„ì‚° ì™„ë£Œ ({len(updated_task_summary_ids_list)}ê±´)\")]\n",
    "    return {\"messages\": messages, \"updated_task_ids\": updated_task_summary_ids_list}\n",
    "\n",
    "\n",
    "# 3. íŒ€ ëª©í‘œ ë¶„ì„ ì„œë¸Œëª¨ë“ˆ (ìˆ˜ì •: KPI ë‚´ ê°œì¸ ìƒëŒ€ ê¸°ì—¬ë„ ê³„ì‚° ë° LLM ìš”ì²­ í›„ tasks ì—…ë°ì´íŠ¸)\n",
    "def analyze_team_goals_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "    report_type = state[\"report_type\"] \n",
    "    target_team_kpi_ids = state[\"target_team_kpi_ids\"] \n",
    "    period_id = state[\"period_id\"] \n",
    "\n",
    "    updated_team_kpi_ids_list = [] \n",
    "    kpi_individual_relative_contributions_for_state = [] \n",
    "\n",
    "    for team_kpi_id in target_team_kpi_ids: \n",
    "        kpi_data = fetch_kpi_data_by_id(team_kpi_id) \n",
    "        if not kpi_data: \n",
    "            print(f\"Warning: Team KPI data not found for team_kpi_id {team_kpi_id}.\") \n",
    "            continue \n",
    "\n",
    "        tasks_in_this_kpi = fetch_tasks_for_kpi(team_kpi_id, period_id) \n",
    "        \n",
    "        # ğŸ”§ ìµœì‹  ë¶„ê¸° ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ì œê±°\n",
    "        latest_period_tasks = [\n",
    "            task for task in tasks_in_this_kpi \n",
    "            if task.get(\"period_id\") == period_id\n",
    "        ]\n",
    "        \n",
    "        llm_input_for_kpi_analysis = {\n",
    "            \"kpi_goal\": kpi_data.get(\"kpi_name\"), \n",
    "            \"kpi_description\": kpi_data.get(\"kpi_description\"), \n",
    "            \"team_members_tasks\": [\n",
    "                {\n",
    "                    \"emp_no\": task.get(\"emp_no\"), \n",
    "                    \"task_id\": task.get(\"task_id\"), \n",
    "                    \"task_name\": task.get(\"task_name\"), \n",
    "                    \"task_summary\": task.get(\"task_summary\"), \n",
    "                    \"ai_contribution_score_from_individual_analysis\": task.get(\"ai_contribution_score\") \n",
    "                } for task in latest_period_tasks  # ğŸ”§ ìµœì‹  ë¶„ê¸°ë§Œ ì‚¬ìš©\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        llm_kpi_analysis_results = call_llm_for_kpi_relative_contribution(llm_input_for_kpi_analysis) \n",
    "\n",
    "        update_data_kpi = { \n",
    "            \"ai_kpi_progress_rate\": llm_kpi_analysis_results.get(\"kpi_overall_rate\"),\n",
    "            \"ai_kpi_analysis_comment\": llm_kpi_analysis_results.get(\"kpi_analysis_comment\") \n",
    "        }\n",
    "\n",
    "        if update_team_kpi_ai_results_in_db(team_kpi_id, update_data_kpi): \n",
    "            updated_team_kpi_ids_list.append(team_kpi_id) \n",
    "            \n",
    "            if \"individual_relative_contributions_in_kpi\" in llm_kpi_analysis_results: \n",
    "                relative_contributions_by_emp = llm_kpi_analysis_results[\"individual_relative_contributions_in_kpi\"]\n",
    "                kpi_individual_relative_contributions_for_state.append({ \n",
    "                    \"team_kpi_id\": team_kpi_id,\n",
    "                    \"relative_contributions\": relative_contributions_by_emp\n",
    "                }) \n",
    "\n",
    "                # ğŸ”§ ìµœì‹  ë¶„ê¸° ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ê³ ìœ í•œ task_id ëª©ë¡ ì¶”ì¶œ\n",
    "                unique_task_ids = list(set(task.get(\"task_id\") for task in latest_period_tasks))\n",
    "\n",
    "                for task_id in unique_task_ids:\n",
    "                    emp_no_for_this_task = None\n",
    "                    \n",
    "                    # í•´ë‹¹ task_idì˜ ëª¨ë“  ë¶„ê¸° ë°ì´í„° ìˆ˜ì§‘ (ì „ì²´ tasks_in_this_kpiì—ì„œ)\n",
    "                    task_summaries_for_this_task = []\n",
    "                    for task in tasks_in_this_kpi:\n",
    "                        if task.get(\"task_id\") == task_id:\n",
    "                            emp_no_for_this_task = task.get(\"emp_no\")\n",
    "                            task_summaries_for_this_task.append(task)\n",
    "                    \n",
    "                    if emp_no_for_this_task in relative_contributions_by_emp:\n",
    "                        new_contribution_score = relative_contributions_by_emp[emp_no_for_this_task]\n",
    "                        \n",
    "                        # ğŸ”§ Taskë‹¹ 1ë²ˆë§Œ ê·¼ê±° ìƒì„± (ì „ì²´ ë¶„ê¸° ë°ì´í„° ê¸°ë°˜)\n",
    "                        cumulative_data = fetch_cumulative_task_data_for_comment(task_id, period_id)\n",
    "                        \n",
    "                        if cumulative_data:\n",
    "                            # ğŸ”§ 1ë²ˆë§Œ LLM í˜¸ì¶œ (ì „ì²´ ì—°ê°„ í™œë™ ê¸°ë°˜)\n",
    "                            reason_llm_results = call_llm_for_individual_contribution_reason_comment(\n",
    "                                cumulative_data,\n",
    "                                float(new_contribution_score),\n",
    "                                kpi_data.get('kpi_name', ''),\n",
    "                                llm_kpi_analysis_results.get('kpi_analysis_comment', '')\n",
    "                            )\n",
    "                            adjusted_comment = reason_llm_results.get(\"comment\", f\"AI ê·¼ê±° ìƒì„± ì‹¤íŒ¨: {emp_no_for_this_task}ì˜ Task {task_id}ì— ëŒ€í•œ ê·¼ê±°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                            \n",
    "                            # ğŸ”§ ëª¨ë“  ë¶„ê¸°ì— ë™ì¼í•œ ê·¼ê±° ì €ì¥í•˜ë˜ ê¸°ì—¬ë„ëŠ” ë¶„ê¸°ë³„ ë¹„ë¡€ ë°°ë¶„\n",
    "                            for task_summary in task_summaries_for_this_task:\n",
    "                                task_summary_id = task_summary.get(\"task_summary_Id\")\n",
    "                                current_period = task_summary.get(\"period_id\")\n",
    "                                \n",
    "                                if current_period is None:\n",
    "                                    print(f\"Warning: current_period is None for task_summary_id {task_summary_id}\")\n",
    "                                    continue\n",
    "                                \n",
    "                                # í•´ë‹¹ ë¶„ê¸°ê¹Œì§€ì˜ ê¸°ì—¬ë„ ê³„ì‚° (ìµœì¢…ê°’ì—ì„œ ë¹„ë¡€ ë°°ë¶„)\n",
    "                                period_weight = current_period / period_id\n",
    "                                period_contribution = new_contribution_score * period_weight\n",
    "                                \n",
    "                                update_data_task_summary = {\n",
    "                                    \"ai_contribution_score\": round(period_contribution, 2),\n",
    "                                    \"ai_analysis_comment_task\": adjusted_comment\n",
    "                                }\n",
    "                                \n",
    "                                if not update_task_summary_ai_results_in_db(task_summary_id, update_data_task_summary):\n",
    "                                    print(f\"Warning: Failed to update task_summary_Id {task_summary_id} (task_id: {task_id}, period: {current_period})\")\n",
    "                        else:\n",
    "                            print(f\"Warning: No cumulative data found for task_id {task_id}\")\n",
    "                    else:\n",
    "                        print(f\"Warning: Emp_no {emp_no_for_this_task} from task_id {task_id} not found in LLM's relative contributions for KPI {team_kpi_id}.\")\n",
    "\n",
    "        else: \n",
    "            print(f\"Failed to update AI results for team_kpi_id: {team_kpi_id}\") \n",
    "\n",
    "    messages = state.get(\"messages\", []) + [HumanMessage(content=f\"ëª¨ë“ˆ 2: íŒ€ ëª©í‘œ ë¶„ì„ ë° DB ì—…ë°ì´íŠ¸ ì™„ë£Œ ({len(updated_team_kpi_ids_list)}ê±´)\")] \n",
    "    \n",
    "    return {\"messages\": messages, \"updated_team_kpi_ids\": updated_team_kpi_ids_list,\n",
    "            \"kpi_individual_relative_contributions\": kpi_individual_relative_contributions_for_state}\n",
    "\n",
    "\n",
    "# 4. ëª¨ë“ˆ 2 ê´€ë ¨ ë ˆí¬íŠ¸ í…Œì´ë¸” ë°ì´í„° ìƒì„±/ì—…ë°ì´íŠ¸ ì„œë¸Œëª¨ë“ˆ\n",
    "def generate_module2_report_data_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "    report_type = state[\"report_type\"] \n",
    "    team_id = state[\"team_id\"] \n",
    "    period_id = state[\"period_id\"] \n",
    "    \n",
    "    kpi_individual_relative_contributions = state.get(\"kpi_individual_relative_contributions\", []) \n",
    "    \n",
    "    updated_ids_for_state = {} \n",
    "\n",
    "    # ê°œì¸ì˜ íŒ€ ì „ì²´ ê¸°ì—¬ë„ ê³„ì‚° (KPIë³„ ìƒëŒ€ ê¸°ì—¬ë„ ê¸°ë°˜)\n",
    "    emp_overall_relative_contributions = {} \n",
    "    \n",
    "    for kpi_result in kpi_individual_relative_contributions: \n",
    "        for emp_no, relative_score in kpi_result[\"relative_contributions\"].items(): \n",
    "            if emp_no not in emp_overall_relative_contributions: \n",
    "                emp_overall_relative_contributions[emp_no] = 0 \n",
    "            emp_overall_relative_contributions[emp_no] += relative_score \n",
    "\n",
    "    # --- íŒ€ ì „ì²´ ê¸°ì—¬ë„ í•©ê³„ 100%ë¡œ ì •ê·œí™” ---\n",
    "    total_sum_of_relative_contributions = sum(emp_overall_relative_contributions.values())\n",
    "    if total_sum_of_relative_contributions > 0:\n",
    "        adjustment_factor = 100.0 / total_sum_of_relative_contributions\n",
    "        for emp_no, score in emp_overall_relative_contributions.items():\n",
    "            emp_overall_relative_contributions[emp_no] = round(score * adjustment_factor, 2)\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # ëª¨ë“  ê°œì¸ Task ê²°ê³¼ëŠ” ì—¬ì „íˆ í•„ìš” \n",
    "    all_individual_task_results_raw = []\n",
    "    for task_id in state[\"target_task_ids\"]:\n",
    "        task_summaries = fetch_task_summaries_by_task_and_period(task_id, period_id)\n",
    "        all_individual_task_results_raw.extend(task_summaries)\n",
    "\n",
    "    # ê°œì¸ìš© ë¶„ê¸°ë³„ í”¼ë“œë°± ë ˆí¬íŠ¸ (feedback_reports)\n",
    "    if report_type == \"quarterly\": \n",
    "        # 1. í•´ë‹¹ íŒ€ì˜ ëª¨ë“  emp_no ì¡°íšŒ (í”¼ë“œë°± ë ˆí¬íŠ¸ëŠ” íŒ€ì›ìš©)\n",
    "        all_team_members_in_db = fetch_employees_by_team_id(team_id)\n",
    "\n",
    "        for member_info in all_team_members_in_db:\n",
    "            emp_no_current_member = member_info[\"emp_no\"]\n",
    "            emp_name_current_member = member_info[\"emp_name\"]\n",
    "\n",
    "            # íŒ€ì¥(MANAGER) ì—­í• ì€ í”¼ë“œë°± ë ˆí¬íŠ¸ë¥¼ ì§ì ‘ ìƒì„±í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.\n",
    "            if member_info.get(\"role\") == \"MANAGER\": \n",
    "                print(f\"Info: Skipping feedback_reports for manager {emp_no_current_member}.\")\n",
    "                continue\n",
    "\n",
    "            # í•´ë‹¹ íŒ€ì›ì—ê²Œ í•´ë‹¹í•˜ëŠ” Task Summaries í•„í„°ë§\n",
    "            individual_tasks_for_report = [\n",
    "                task for task in all_individual_task_results_raw \n",
    "                if task.get(\"emp_no\") == emp_no_current_member and task.get(\"period_id\") <= period_id \n",
    "            ]\n",
    "\n",
    "            if not individual_tasks_for_report: \n",
    "                print(f\"Warning: No individual tasks found for emp_no {emp_no_current_member} in period {period_id}. Skipping feedback_reports save for this member.\") \n",
    "                continue \n",
    "\n",
    "            # LLM í˜¸ì¶œ ì‹œ emp_name, emp_no ì „ë‹¬\n",
    "            individual_overall_results = call_llm_for_overall_contribution_summary(\n",
    "                individual_tasks_for_report, emp_name_current_member, emp_no_current_member\n",
    "            ) \n",
    "            calculated_individual_quarterly_contribution = emp_overall_relative_contributions.get(emp_no_current_member, 0) \n",
    "\n",
    "            team_evaluation_id_for_report = state.get(\"team_evaluation_id\") \n",
    "            if team_evaluation_id_for_report is None: \n",
    "                print(f\"Warning: team_evaluation_id for team_id={team_id}, period_id={period_id} is missing in state. Cannot save feedback_reports for {emp_no_current_member}. (ì•ë‹¨ Agentì—ì„œ ìƒì„± í•„ìš”)\") \n",
    "            else: \n",
    "                actual_team_eval_id_in_db = fetch_team_evaluation_id_by_team_and_period(team_id, period_id) \n",
    "                if actual_team_eval_id_in_db != team_evaluation_id_for_report: \n",
    "                     print(f\"Warning: team_evaluation_id {team_evaluation_id_for_report} from state does not match existing ID in DB for team={team_id}, period={period_id}. Skipping feedback_reports save for {emp_no_current_member}.\") \n",
    "                else: \n",
    "                    # --- INSERT ë˜ëŠ” UPDATE ë¡œì§ (ON DUPLICATE KEY UPDATE ì‚¬ìš©) ---\n",
    "                    feedback_report_id = save_feedback_report_module2_results_to_db(\n",
    "                        emp_no_current_member, team_evaluation_id_for_report, \n",
    "                        {\n",
    "                            \"contribution_rate\": int(calculated_individual_quarterly_contribution),  # ğŸ”§ ì»¬ëŸ¼ëª… ë³€ê²½ ë° int ë³€í™˜\n",
    "                            \"ai_overall_contribution_summary_comment\": individual_overall_results.get(\"comment\"),\n",
    "                            \"ai_peer_talk_summary\": \"ëª¨ë“ˆ 2ì—ì„œëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ\"  # ğŸ”§ ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ (ë¹ˆ ê°’)\n",
    "                        }\n",
    "                    )\n",
    "                    updated_ids_for_state[\"feedback_report_id\"] = feedback_report_id \n",
    "                    messages = state.get(\"messages\", []) + [HumanMessage(content=f\"ëª¨ë“ˆ 2: ê°œì¸ {emp_no_current_member} ë¶„ê¸°ë³„ ë ˆí¬íŠ¸ ë‚´ìš© ìƒì„±/ì—…ë°ì´íŠ¸ ë° feedback_reports ì €ì¥ ì™„ë£Œ (ID: {feedback_report_id})\")] \n",
    "\n",
    "    # íŒ€ì¥ìš© ë¶„ê¸°ë³„/ì—°ë§ íŒ€ ì „ì²´ í‰ê°€ ë ˆí¬íŠ¸ (team_evaluations)\n",
    "    team_evaluation_id = state.get(\"team_evaluation_id\") \n",
    "    if team_evaluation_id is None: \n",
    "        print(f\"Warning: team_evaluation_id for team_id={team_id}, period_id={period_id} is missing in state. Cannot update team_evaluations. (ì•ë‹¨ Agentì—ì„œ ìƒì„± í•„ìš”)\") \n",
    "    else: \n",
    "        actual_team_eval_id_in_db = fetch_team_evaluation_id_by_team_and_period(team_id, period_id) \n",
    "        if actual_team_eval_id_in_db != team_evaluation_id: \n",
    "             print(f\"Warning: team_evaluation_id {team_evaluation_id} from state does not match existing ID in DB for team={team_id}, period={period_id}. Skipping team_evaluations update.\") \n",
    "        else: \n",
    "            all_team_kpis_results = [fetch_kpi_data_by_id(kpi_id) for kpi_id in state[\"target_team_kpi_ids\"] if fetch_kpi_data_by_id(kpi_id)] \n",
    "            team_overall_results = call_llm_for_team_overall_analysis(all_team_kpis_results) \n",
    "            \n",
    "            update_data = {\n",
    "                \"average_achievement_rate\": int(team_overall_results.get(\"overall_rate\")),  # ğŸ”§ ì»¬ëŸ¼ëª… ë³€ê²½ ë° int ë³€í™˜\n",
    "                \"ai_team_overall_analysis_comment\": team_overall_results.get(\"comment\") \n",
    "            }\n",
    "            update_team_evaluations_module2_results_in_db(team_evaluation_id, update_data) \n",
    "            updated_ids_for_state[\"team_evaluation_id\"] = team_evaluation_id \n",
    "            messages = state.get(\"messages\", []) + [HumanMessage(content=f\"ëª¨ë“ˆ 2: íŒ€ ì „ì²´ ë¶„ì„ ì½”ë©˜íŠ¸ ìƒì„± ë° team_evaluations ì—…ë°ì´íŠ¸ ì™„ë£Œ (ID: {team_evaluation_id})\")] \n",
    "\n",
    "    # ê°œì¸ìš© ì—°ë§ ìµœì¢… í‰ê°€ ë ˆí¬íŠ¸ (final_evaluation_reports)\n",
    "    if report_type == \"annual\": \n",
    "        all_team_members_in_db = fetch_employees_by_team_id(team_id)\n",
    "\n",
    "        for member_info in all_team_members_in_db:\n",
    "            emp_no_current_member = member_info[\"emp_no\"]\n",
    "            emp_name_current_member = member_info[\"emp_name\"]\n",
    "\n",
    "            # íŒ€ì¥(MANAGER) ì—­í• ì€ ìµœì¢… í‰ê°€ ë ˆí¬íŠ¸ì˜ ì§ì ‘ ëŒ€ìƒì´ ì•„ë‹ˆë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.\n",
    "            if member_info.get(\"role\") == \"MANAGER\": \n",
    "                print(f\"Info: Skipping final_evaluation_reports for manager {emp_no_current_member}.\")\n",
    "                continue\n",
    "\n",
    "            # í•´ë‹¹ íŒ€ì›ì—ê²Œ í•´ë‹¹í•˜ëŠ” Task Summaries í•„í„°ë§\n",
    "            individual_tasks_for_annual_report = [\n",
    "                task for task in all_individual_task_results_raw \n",
    "                if task.get(\"emp_no\") == emp_no_current_member and task.get(\"period_id\") <= period_id\n",
    "            ]\n",
    "            if not individual_tasks_for_annual_report: \n",
    "                print(f\"Warning: No individual tasks found for emp_no {emp_no_current_member} in period {period_id}. Skipping final_evaluation_reports save for this member.\") \n",
    "                continue \n",
    "\n",
    "            # LLM í˜¸ì¶œ ì‹œ emp_name, emp_no ì „ë‹¬\n",
    "            annual_individual_summary_results = call_llm_for_overall_contribution_summary(\n",
    "                individual_tasks_for_annual_report, emp_name_current_member, emp_no_current_member\n",
    "            ) \n",
    "            \n",
    "            calculated_annual_individual_total_contribution = emp_overall_relative_contributions.get(emp_no_current_member, 0) \n",
    "            \n",
    "            final_team_evaluation_id_example = state.get(\"team_evaluation_id\") \n",
    "            if final_team_evaluation_id_example is None: \n",
    "                print(f\"Warning: team_evaluation_id for team_id={team_id}, period_id={period_id} is missing in state. Cannot save final_evaluation_reports for {emp_no_current_member}. (ì•ë‹¨ Agentì—ì„œ ìƒì„± í•„ìš”)\") \n",
    "            else: \n",
    "                actual_team_eval_id_in_db = fetch_team_evaluation_id_by_team_and_period(team_id, period_id) \n",
    "                if actual_team_eval_id_in_db != final_team_evaluation_id_example: \n",
    "                     print(f\"Warning: team_evaluation_id {final_team_evaluation_id_example} from state does not match existing ID in DB for team={team_id}, period={period_id}. Skipping final_evaluation_reports save for {emp_no_current_member}.\") \n",
    "                else: \n",
    "                    final_report_id = save_final_evaluation_report_module2_results_to_db(\n",
    "                        emp_no_current_member, final_team_evaluation_id_example, \n",
    "                        {\n",
    "                            \"contribution_rate\": int(calculated_annual_individual_total_contribution),  # ğŸ”§ ì»¬ëŸ¼ëª… ë³€ê²½ ë° int ë³€í™˜\n",
    "                            \"ai_annual_achievement_rate\": int(annual_individual_summary_results.get(\"average_rate\")),  # ğŸ”§ int ë³€í™˜\n",
    "                            \"ai_annual_performance_summary_comment\": annual_individual_summary_results.get(\"comment\"),\n",
    "                            \"ai_annual_peer_talk_summary\": \"ëª¨ë“ˆ 2ì—ì„œëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ\"  # ğŸ”§ ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ (ë¹ˆ ê°’)\n",
    "                        }\n",
    "                    )\n",
    "                    updated_ids_for_state[\"final_report_id\"] = final_report_id \n",
    "                    messages = state.get(\"messages\", []) + [HumanMessage(content=f\"ëª¨ë“ˆ 2: ê°œì¸ {emp_no_current_member} ì—°ë§ ìµœì¢… í‰ê°€ ë ˆí¬íŠ¸ ë‚´ìš© ìƒì„± ë° final_evaluation_reports ì €ì¥ ì™„ë£Œ (ID: {final_report_id})\")] \n",
    "\n",
    "    # ğŸ”§ temp_evaluations ê´€ë ¨ ì½”ë“œ ì „ì²´ ì‚­ì œ (ai_annual_key_performance_contribution_summary ì €ì¥ ì•ˆí•¨)\n",
    "\n",
    "    return {\"messages\": messages, **updated_ids_for_state}\n",
    "\n",
    "# 5. í¬ë§·í„° ì„œë¸Œëª¨ë“ˆ\n",
    "def formatter_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "   messages = state.get(\"messages\", []) + [HumanMessage(content=\"ëª¨ë“ˆ 2: í¬ë§·íŒ… ì™„ë£Œ\")]\n",
    "   return {\"messages\": messages}\n",
    "\n",
    "# --- LangGraph Workflow êµ¬ì„± ë° ì»´íŒŒì¼ ---\n",
    "# ëª¨ë“ˆ 2ì˜ ì›Œí¬í”Œë¡œìš° ì •ì˜\n",
    "module2_workflow = StateGraph(Module2AgentState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€ (ê° ì„œë¸Œëª¨ë“ˆ í•¨ìˆ˜ë¥¼ ë…¸ë“œë¡œ ë“±ë¡)\n",
    "module2_workflow.add_node(\"data_collection\", data_collection_submodule)\n",
    "module2_workflow.add_node(\"calculate_individual_contribution\", calculate_individual_contribution_submodule)\n",
    "module2_workflow.add_node(\"analyze_team_goals\", analyze_team_goals_submodule)\n",
    "module2_workflow.add_node(\"generate_module2_report_data\", generate_module2_report_data_submodule)\n",
    "module2_workflow.add_node(\"formatter\", formatter_submodule)\n",
    "\n",
    "\n",
    "# ì—£ì§€ (ì‹¤í–‰ ìˆœì„œ) ì •ì˜\n",
    "# ì‹œì‘ ë…¸ë“œì—ì„œ 'data_collection' ë…¸ë“œë¡œ ì—°ê²°\n",
    "module2_workflow.add_edge(START, \"data_collection\")\n",
    "# 'data_collection' -> 'calculate_individual_contribution' ìˆœì„œë¡œ ì—°ê²°\n",
    "module2_workflow.add_edge(\"data_collection\", \"calculate_individual_contribution\")\n",
    "# 'calculate_individual_contribution' -> 'analyze_team_goals' ìˆœì„œë¡œ ì—°ê²°\n",
    "module2_workflow.add_edge(\"calculate_individual_contribution\", \"analyze_team_goals\")\n",
    "# 'analyze_team_goals' -> 'generate_module2_report_data' ìˆœì„œë¡œ ì—°ê²°\n",
    "module2_workflow.add_edge(\"analyze_team_goals\", \"generate_module2_report_data\")\n",
    "# 'generate_module2_report_data' -> 'formatter' ìˆœì„œë¡œ ì—°ê²°\n",
    "module2_workflow.add_edge(\"generate_module2_report_data\", \"formatter\")\n",
    "# 'formatter'ì—ì„œ ìµœì¢… ì¢…ë£Œ ì§€ì (END)ìœ¼ë¡œ ì—°ê²°\n",
    "module2_workflow.add_edge(\"formatter\", END)\n",
    "\n",
    "# ëª¨ë“ˆ 2ì˜ Graph ì»´íŒŒì¼\n",
    "module2_graph = module2_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f5edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc9cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107f6609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ëª¨ë“ˆ 2 í…ŒìŠ¤íŠ¸ ì‹œì‘: 2ë¶„ê¸° í‰ê°€\n",
      "============================================================\n",
      "ğŸš€ 2ë¶„ê¸° í‰ê°€ ì‹¤í–‰ ì¤‘...\n",
      "LLM Call (Cumulative Task Contribution): Task 1 for ê¹€ê°œë°œ\n",
      "LLM Call (Cumulative Task Contribution): Task 2 for ì´ì„¤ê³„\n",
      "LLM Call (Cumulative Task Contribution): Task 3 for ë°•DB\n",
      "LLM Call (Cumulative Task Contribution): Task 4 for ê¹€ê°œë°œ\n",
      "LLM Call (Cumulative Task Contribution): Task 5 for ì´ì„¤ê³„\n",
      "LLM Call (Cumulative Task Contribution): Task 6 for ê¹€ê°œë°œ\n",
      "LLM Call (Cumulative Task Contribution): Task 7 for ì´ì„¤ê³„\n",
      "LLM Call (Cumulative Task Contribution): Task 8 for ì´ì„¤ê³„\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 2ë¶„ê¸° í‰ê°€ ì‹¤í–‰\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸš€ 2ë¶„ê¸° í‰ê°€ ì‹¤í–‰ ì¤‘...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m result_q2 = \u001b[43mmodule2_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_q2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… 2ë¶„ê¸° í‰ê°€ ì™„ë£Œ!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mìµœì¢… ë©”ì‹œì§€: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_q2[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m].content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langgraph/pregel/runner.py:161\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    159\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langgraph/utils/runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langgraph/utils/runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 941\u001b[39m, in \u001b[36mcalculate_individual_contribution_submodule\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# ğŸ”§ 1ë²ˆë§Œ í˜¸ì¶œ (ì „ì²´ ë¶„ê¸° ë°ì´í„° ê¸°ë°˜)\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m report_type == \u001b[33m\"\u001b[39m\u001b[33mquarterly\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     llm_results = \u001b[43mcall_llm_for_cumulative_task_contribution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcumulative_performance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memp_name\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m     base_update_data = {\n\u001b[32m    945\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mai_contribution_score\u001b[39m\u001b[33m\"\u001b[39m: llm_results.get(\u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m), \n\u001b[32m    946\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mai_analysis_comment_task\u001b[39m\u001b[33m\"\u001b[39m: llm_results.get(\u001b[33m\"\u001b[39m\u001b[33mcomment\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m    947\u001b[39m     }\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m report_type == \u001b[33m\"\u001b[39m\u001b[33mannual\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 574\u001b[39m, in \u001b[36mcall_llm_for_cumulative_task_contribution\u001b[39m\u001b[34m(task_id, combined_summary, cumulative_performance, target_level, emp_name)\u001b[39m\n\u001b[32m    571\u001b[39m chain = prompt | llm_client\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     response: AIMessage = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtask_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcombined_summary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_summary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcumulative_performance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcumulative_performance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtarget_level\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43memp_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43memp_name\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    581\u001b[39m     json_output_raw = response.content\n\u001b[32m    583\u001b[39m     json_output = _extract_json_from_llm_response(json_output_raw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 input_ = context.run(step.invoke, input_, config)\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:717\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    715\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/openai/_base_client.py:972\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    970\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    978\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/ssl.py:1295\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1292\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1293\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1294\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/ssl.py:1168\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 2ë¶„ê¸° ë° ì—°ë§ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜ˆì‹œ\n",
    "\n",
    "# ê¸°ì¡´ ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ë‘ê³ , ì‹¤í–‰ ë¶€ë¶„ë§Œ ìˆ˜ì •\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ëª¨ë“ˆ 2 í…ŒìŠ¤íŠ¸ ì‹œì‘: 2ë¶„ê¸° í‰ê°€\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# === 2ë¶„ê¸° í‰ê°€ ì‹¤í–‰ ===\n",
    "state_q2 = Module2AgentState(\n",
    "    messages=[HumanMessage(content=\"ëª¨ë“ˆ 2 ë¶„ê¸°ë³„ í‰ê°€ ì‹œì‘\")],\n",
    "    report_type=\"quarterly\",\n",
    "    team_id=1,\n",
    "    period_id=2,  # 2024ë…„ 2ë¶„ê¸° (Q2) í‰ê°€\n",
    "    \n",
    "    # Q1, Q2 Task Summaries (id: 1-18 = Q1 9ê°œ + Q2 9ê°œ)\n",
    "    target_task_ids=[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    target_team_kpi_ids=[1, 2, 3, 4],\n",
    "    \n",
    "    team_evaluation_id=102,  # Q2ì˜ team_evaluation_id\n",
    "    \n",
    "    updated_task_ids=None,\n",
    "    updated_team_kpi_ids=None,\n",
    "    kpi_individual_relative_contributions=None\n",
    ")\n",
    "\n",
    "# 2ë¶„ê¸° í‰ê°€ ì‹¤í–‰\n",
    "print(\"ğŸš€ 2ë¶„ê¸° í‰ê°€ ì‹¤í–‰ ì¤‘...\")\n",
    "result_q2 = module2_graph.invoke(state_q2)\n",
    "\n",
    "print(\"âœ… 2ë¶„ê¸° í‰ê°€ ì™„ë£Œ!\")\n",
    "print(f\"ìµœì¢… ë©”ì‹œì§€: {result_q2['messages'][-1].content}\")\n",
    "print(f\"ì—…ë°ì´íŠ¸ëœ Task ìˆ˜: {len(result_q2.get('updated_task_ids', []))}\")\n",
    "print(f\"ì—…ë°ì´íŠ¸ëœ KPI ìˆ˜: {len(result_q2.get('updated_team_kpi_ids', []))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1986d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53aa3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bfff68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92182de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ëª¨ë“ˆ 2 í…ŒìŠ¤íŠ¸ ì‹œì‘: ì—°ë§ í‰ê°€\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# === ì—°ë§ í‰ê°€ ì‹¤í–‰ ===\n",
    "state_annual = Module2AgentState(\n",
    "    messages=[HumanMessage(content=\"ëª¨ë“ˆ 2 ì—°ë§ í‰ê°€ ì‹œì‘\")],\n",
    "    report_type=\"annual\",\n",
    "    team_id=1,\n",
    "    period_id=4,  # 2024ë…„ ì—°ë§ (Q4) í‰ê°€\n",
    "    \n",
    "    # Q1~Q4 ëª¨ë“  Task Summaries (id: 1-36 = ì „ì²´)\n",
    "    target_task_ids=[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    target_team_kpi_ids=[1, 2, 3, 4],\n",
    "    \n",
    "    team_evaluation_id=104,  # Q4ì˜ team_evaluation_id\n",
    "    \n",
    "    updated_task_ids=None,\n",
    "    updated_team_kpi_ids=None,\n",
    "    kpi_individual_relative_contributions=None\n",
    ")\n",
    "\n",
    "# ì—°ë§ í‰ê°€ ì‹¤í–‰\n",
    "print(\"ğŸš€ ì—°ë§ í‰ê°€ ì‹¤í–‰ ì¤‘...\")\n",
    "result_annual = module2_graph.invoke(state_annual)\n",
    "\n",
    "print(\"âœ… ì—°ë§ í‰ê°€ ì™„ë£Œ!\")\n",
    "print(f\"ìµœì¢… ë©”ì‹œì§€: {result_annual['messages'][-1].content}\")\n",
    "print(f\"ì—…ë°ì´íŠ¸ëœ Task ìˆ˜: {len(result_annual.get('updated_task_ids', []))}\")\n",
    "print(f\"ì—…ë°ì´íŠ¸ëœ KPI ìˆ˜: {len(result_annual.get('updated_team_kpi_ids', []))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ê²°ê³¼ í™•ì¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# === ê²°ê³¼ í™•ì¸ ===\n",
    "def check_results():\n",
    "    \"\"\"ê²°ê³¼ í™•ì¸ í•¨ìˆ˜\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        print(\"ğŸ“Š 2ë¶„ê¸° ê²°ê³¼ í™•ì¸:\")\n",
    "        \n",
    "        # tasks í…Œì´ë¸” í™•ì¸ (2ë¶„ê¸°ëŠ” ê¸°ì—¬ë„ë§Œ)\n",
    "        print(\"\\n1. Tasks í…Œì´ë¸” AI ê²°ê³¼ (2ë¶„ê¸° í›„):\")\n",
    "        query = text(\"\"\"\n",
    "            SELECT task_id, task_name, emp_no, \n",
    "                   ai_contribution_score, ai_achievement_rate, ai_assessed_grade\n",
    "            FROM tasks \n",
    "            ORDER BY task_id LIMIT 5\n",
    "        \"\"\")\n",
    "        results = connection.execute(query).fetchall()\n",
    "        for row in results:\n",
    "            print(f\"  Task {row.task_id}: ê¸°ì—¬ë„={row.ai_contribution_score}, ë‹¬ì„±ë¥ ={row.ai_achievement_rate}, ë“±ê¸‰={row.ai_assessed_grade}\")\n",
    "        \n",
    "        # team_kpis í™•ì¸\n",
    "        print(\"\\n2. Team KPIs ê²°ê³¼:\")\n",
    "        query = text(\"\"\"\n",
    "            SELECT kpi_name, ai_kpi_overall_progress_rate, \n",
    "                   LEFT(ai_kpi_analysis_comment, 50) as comment_preview\n",
    "            FROM team_kpis \n",
    "            ORDER BY team_kpi_id\n",
    "        \"\"\")\n",
    "        results = connection.execute(query).fetchall()\n",
    "        for row in results:\n",
    "            print(f\"  {row.kpi_name}: ë‹¬ì„±ë¥ ={row.ai_kpi_overall_progress_rate}%, ì½”ë©˜íŠ¸={row.comment_preview}...\")\n",
    "        \n",
    "        # feedback_reports í™•ì¸ (2ë¶„ê¸°)\n",
    "        print(\"\\n3. Feedback Reports (2ë¶„ê¸°):\")\n",
    "        query = text(\"\"\"\n",
    "            SELECT emp_no, ai_individual_total_contribution_quarterly,\n",
    "                   LEFT(ai_overall_contribution_summary_comment, 50) as comment_preview\n",
    "            FROM feedback_reports \n",
    "            WHERE team_evaluation_id = 102\n",
    "        \"\"\")\n",
    "        results = connection.execute(query).fetchall()\n",
    "        for row in results:\n",
    "            print(f\"  {row.emp_no}: ê¸°ì—¬ë„={row.ai_individual_total_contribution_quarterly}%, ì½”ë©˜íŠ¸={row.comment_preview}...\")\n",
    "        \n",
    "        print(\"\\nğŸ“Š ì—°ë§ ê²°ê³¼ í™•ì¸:\")\n",
    "        \n",
    "        # final_evaluation_reports í™•ì¸\n",
    "        print(\"\\n4. Final Evaluation Reports (ì—°ë§):\")\n",
    "        query = text(\"\"\"\n",
    "            SELECT emp_no, ai_annual_individual_total_contribution, ai_annual_achievement_rate,\n",
    "                   LEFT(ai_annual_performance_summary_comment, 50) as comment_preview\n",
    "            FROM final_evaluation_reports \n",
    "            WHERE team_evaluation_id = 104\n",
    "        \"\"\")\n",
    "        results = connection.execute(query).fetchall()\n",
    "        for row in results:\n",
    "            print(f\"  {row.emp_no}: ê¸°ì—¬ë„={row.ai_annual_individual_total_contribution}%, ë‹¬ì„±ë¥ ={row.ai_annual_achievement_rate}%, ì½”ë©˜íŠ¸={row.comment_preview}...\")\n",
    "        \n",
    "        # temp_evaluations í™•ì¸\n",
    "        print(\"\\n5. Temp Evaluations (ì¤‘ê°„ í‰ê°€):\")\n",
    "        query = text(\"\"\"\n",
    "            SELECT TempEvaluation_empNo,\n",
    "                   LEFT(ai_annual_key_performance_contribution_summary, 50) as summary_preview\n",
    "            FROM temp_evaluations \n",
    "            WHERE team_evaluation_id = 104\n",
    "        \"\"\")\n",
    "        results = connection.execute(query).fetchall()\n",
    "        for row in results:\n",
    "            print(f\"  {row.TempEvaluation_empNo}: ìš”ì•½={row.summary_preview}...\")\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸ ì‹¤í–‰\n",
    "check_results()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ğŸ‰\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448748de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b69d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c992986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-WTM_qa1c-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
