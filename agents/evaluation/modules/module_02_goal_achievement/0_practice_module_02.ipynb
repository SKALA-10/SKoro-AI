{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1e53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai-performance-management-system/모듈2_구현_테스트.ipynb\n",
    "\n",
    "# 1. 환경 설정 및 라이브러리 설치 (필요시)\n",
    "# 이미 설치했다면 이 셀은 건너뛰세요.\n",
    "# !pip install langchain langchain-openai langgraph sqlalchemy pymysql python-dotenv\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../..')))  # 루트 경로로 이동\n",
    "\n",
    "from config.settings import DatabaseConfig\n",
    "from agents.evaluation.modules.module_02_goal_achievement import db_utils\n",
    "\n",
    "# 2. .env 파일 로드 (DB 접속 정보 설정 시 필요)\n",
    "# 실제 DB 연결을 위해 DB_USERNAME, DB_PASSWORD 등을 .env 파일에 설정해야 합니다.\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 3. LangSmith 추적 설정 (선택 사항 - 디버깅에 매우 유용)\n",
    "# from langchain_teddynote import logging\n",
    "# logging.langsmith(\"CH21-Module2-Local-Test\")\n",
    "\n",
    "# 4. 필수 라이브러리 임포트\n",
    "from typing import Annotated, List, Literal, TypedDict, Dict, Any, Optional\n",
    "from langchain_core.messages import HumanMessage # LangChain 메시지 타입\n",
    "import operator # operator.add 사용\n",
    "from langgraph.graph import StateGraph, START, END # LangGraph 그래프 구성\n",
    "import uuid # 고유 ID 생성을 위해 (thread_id 등)\n",
    "import random # Mocking 함수에서 랜덤 값 생성을 위해\n",
    "\n",
    "# SQLAlchemy 관련 임포트 (DB 연동 시 필요)\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Connection, Row\n",
    "\n",
    "# config.settings (DB 접속 정보는 여기서 가져옵니다)\n",
    "# 실제 파일 경로에 따라 임포트 방식이 달라질 수 있습니다.\n",
    "# 만약 주피터 노트북 파일이 프로젝트 루트에 있다면:\n",
    "from config.settings import DatabaseConfig \n",
    "from agents.evaluation.modules.module_02_goal_achievement.db_utils import *\n",
    "# 만약 다른 경로에 있다면 sys.path.append() 후 임포트해야 합니다.\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # 예시: 현재 디렉토리의 부모를 추가\n",
    "# from config.settings import DatabaseConfig\n",
    "\n",
    "\n",
    "# 5. DB 설정 및 엔진 생성 (실제 DB 연결)\n",
    "db_config = DatabaseConfig()\n",
    "DATABASE_URL = db_config.DATABASE_URL\n",
    "engine = create_engine(DATABASE_URL, pool_pre_ping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04aa8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../..')))  # 루트 경로로 이동\n",
    "\n",
    "from config.settings import DatabaseConfig\n",
    "\n",
    "db_config = DatabaseConfig()\n",
    "DATABASE_URL = db_config.DATABASE_URL\n",
    "engine = create_engine(DATABASE_URL, pool_pre_ping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a80e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Module2AgentState 정의 ---\n",
    "class Module2AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    모듈 2 (목표달성도 분석 모듈)의 내부 상태를 정의합니다.\n",
    "    이 상태는 모듈 2 내의 모든 서브모듈이 공유하고 업데이트합니다.\n",
    "    \"\"\"\n",
    "    messages: Annotated[List[HumanMessage], operator.add] \n",
    "\n",
    "    report_type: Literal[\"quarterly\", \"annual\"] \n",
    "    team_id: int \n",
    "    period_id: int \n",
    "    \n",
    "    target_task_summary_ids: List[int] \n",
    "    target_team_kpi_ids: List[int] \n",
    "\n",
    "    updated_task_ids: List[int]\n",
    "    updated_team_kpi_ids: List[int]\n",
    "    \n",
    "    kpi_individual_relative_contributions: List[Dict] = [] \n",
    "\n",
    "    feedback_report_id: int = None \n",
    "    team_evaluation_id: int = None \n",
    "    final_evaluation_report_id: int = None \n",
    "    updated_temp_evaluation_ids_list: List[int] = [] \n",
    "\n",
    "\n",
    "# 분기 \n",
    "state = Module2AgentState(\n",
    "    messages=[HumanMessage(content=\"모듈 2 분기별 평가 시작\")],\n",
    "    report_type=\"quarterly\",\n",
    "    team_id=1,\n",
    "    period_id=2,  # 2025년 2분기 (Q2) 평가\n",
    "    \n",
    "    # Time Scope Adapter Agent에서 필터링해준다고 가정 (Q1, Q2 Task Summaries)\n",
    "    target_task_summary_ids=[1, 5, 9, 13, 17, 21, 25, 29, 2, 6, 10, 14, 18, 22, 26, 30],  # Q1(1,5,9,13,17,21,25,29), Q2(2,6,10,14,18,22,26,30)의 task_summary_Id\n",
    "    target_team_kpi_ids=[1, 2, 3],  # DML에 삽입된 team_kpi_id\n",
    "    \n",
    "    # team_evaluation_id는 상위 에이전트가 미리 생성/전달했다고 가정\n",
    "    team_evaluation_id=101,  # DML에 삽입된 Q2의 team_evaluation_id\n",
    "    \n",
    "    updated_task_ids=None,\n",
    "    updated_team_kpi_ids=None,\n",
    "    kpi_individual_relative_contributions=None\n",
    ")\n",
    "\n",
    "\n",
    "# # 연말 \n",
    "# state = Module2AgentState(\n",
    "#     messages=[HumanMessage(content=\"모듈 2 연말 평가 시작\")],\n",
    "#     report_type=\"annual\",\n",
    "#     team_id=1,\n",
    "#     period_id=4,  # 2025년 연말 (Q4) 평가\n",
    "    \n",
    "#     # Time Scope Adapter Agent에서 필터링해준다고 가정 (Q1, Q2, Q3, Q4 Task Summaries)\n",
    "#     target_task_summary_ids=[1, 5, 9, 13, 17, 21, 25, 29, 2, 6, 10, 14, 18, 22, 26, 30, 3, 7, 11, 15, 19, 23, 27, 31, 4, 8, 12, 16, 20, 24, 28, 32],  # Q1~Q4 전체 task_summary_Id\n",
    "#     target_team_kpi_ids=[1, 2, 3],  # DML에 삽입된 team_kpi_id\n",
    "    \n",
    "#     # team_evaluation_id는 상위 에이전트가 미리 생성/전달했다고 가정\n",
    "#     team_evaluation_id=102,  # DML에 삽입된 Q4의 team_evaluation_id\n",
    "    \n",
    "#     updated_task_ids=None,\n",
    "#     updated_team_kpi_ids=None,\n",
    "#     kpi_individual_relative_contributions=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665640f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0661dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Client initialized with model: gpt-4o-mini, temperature: 0.0\n"
     ]
    }
   ],
   "source": [
    "# ai-performance-management-system/shared/tools/py\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Connection, Row\n",
    "from typing import Optional, List, Dict, Any\n",
    "from config.settings import DatabaseConfig\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import random \n",
    "import json \n",
    "import re \n",
    "\n",
    "# LangChain LLM 관련 임포트\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "# --- LLM 클라이언트 인스턴스 (전역 설정) ---\n",
    "llm_client = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) \n",
    "print(f\"LLM Client initialized with model: {llm_client.model_name}, temperature: {llm_client.temperature}\")\n",
    "\n",
    "# 데이터베이스 설정 로드\n",
    "db_config = DatabaseConfig()\n",
    "DATABASE_URL = db_config.DATABASE_URL\n",
    "\n",
    "# SQLAlchemy Engine 생성\n",
    "engine = create_engine(DATABASE_URL, pool_pre_ping=True)\n",
    "\n",
    "# --- 도우미 함수: SQLAlchemy Row 객체를 딕셔너리로 변환 ---\n",
    "def row_to_dict(row: Row) -> Dict[str, Any]:\n",
    "    \"\"\"SQLAlchemy Row 객체를 딕셔너리로 변환합니다.\"\"\"\n",
    "    if row is None:\n",
    "        return {}\n",
    "    return row._asdict() # ._asdict() 사용\n",
    "\n",
    "\n",
    "# --- LLM 응답에서 JSON 코드 블록 추출 도우미 함수 ---\n",
    "def _extract_json_from_llm_response(text: str) -> str:\n",
    "    \"\"\"LLM 응답 텍스트에서 ```json ... ``` 블록만 추출합니다.\"\"\"\n",
    "    match = re.search(r\"```(?:json)?\\s*(.*?)\\s*```\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip() # JSON 내용만 반환하고 양쪽 공백 제거\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# --- 데이터 조회 함수 (`SELECT` 쿼리 구현) ---\n",
    "def fetch_task_summary_by_id(task_summary_id: int) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    `task_summary_Id`로 `task_summaries` 및 관련 `tasks`, `employees` 테이블에서 상세 Task Summary 데이터를 조회합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(f\"\"\"\n",
    "            SELECT ts.*, t.task_name, t.target_level, t.task_performance, \n",
    "                   t.emp_no, t.team_kpi_id, e.emp_name, -- 수정: e.emp_name 추가\n",
    "                   t.ai_contribution_score, t.ai_achievement_rate, t.ai_assessed_grade, t.ai_analysis_comment_task\n",
    "            FROM task_summaries ts\n",
    "            JOIN tasks t ON ts.task_id = t.task_id\n",
    "            JOIN employees e ON t.emp_no = e.emp_no \n",
    "            WHERE ts.task_summary_Id = :task_summary_id\n",
    "        \"\"\")\n",
    "        result = connection.execute(query, {\"task_summary_id\": task_summary_id}).fetchone()\n",
    "        return row_to_dict(result) if result else None\n",
    "\n",
    "\n",
    "def fetch_kpi_data_by_id(team_kpi_id: int) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    `team_kpi_id`로 `team_kpis` 테이블에서 상세 KPI 데이터를 조회합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT * FROM team_kpis WHERE team_kpi_id = :team_kpi_id\")\n",
    "        result = connection.execute(query, {\"team_kpi_id\": team_kpi_id}).fetchone()\n",
    "        return row_to_dict(result) if result else None\n",
    "\n",
    "# def fetch_tasks_for_kpi(team_kpi_id: int, period_id: int) -> List[Dict]:\n",
    "#     \"\"\"\n",
    "#     특정 KPI에 속한 Task들을 조회합니다.\n",
    "#     `tasks` 테이블의 AI 관련 컬럼들과 직원 이름도 포함하여 조회합니다.\n",
    "#     \"\"\"\n",
    "#     with engine.connect() as connection:\n",
    "#         query = text(\"\"\"\n",
    "#             SELECT t.*, ts.task_summary, ts.task_summary_Id, e.emp_name\n",
    "#             FROM tasks t\n",
    "#             JOIN task_summaries ts ON t.task_id = ts.task_id\n",
    "#             JOIN employees e ON t.emp_no = e.emp_no\n",
    "#             WHERE t.team_kpi_id = :team_kpi_id AND ts.period_id = :period_id\n",
    "#         \"\"\")\n",
    "#         results = connection.execute(query, {\"team_kpi_id\": team_kpi_id, \"period_id\": period_id}).fetchall()\n",
    "#         return [row_to_dict(row) for row in results]\n",
    "    \n",
    "\n",
    "def fetch_tasks_for_kpi(team_kpi_id: int, period_id: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    특정 KPI에 속한 Task들을 조회합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        # 먼저 디버깅용으로 각 테이블 데이터 확인\n",
    "        \n",
    "        query = text(\"\"\"\n",
    "            SELECT t.task_id, t.task_name, t.emp_no, ts.task_summary, ts.task_summary_Id, \n",
    "                    e.emp_name, t.ai_contribution_score, t.ai_achievement_rate, \n",
    "                    t.ai_assessed_grade, t.ai_analysis_comment_task\n",
    "            FROM tasks t\n",
    "            JOIN task_summaries ts ON t.task_id = ts.task_id\n",
    "            JOIN employees e ON t.emp_no = e.emp_no\n",
    "            WHERE t.team_kpi_id = :team_kpi_id AND ts.period_id = :period_id\n",
    "        \"\"\")\n",
    "        \n",
    "        results = connection.execute(query, {\"team_kpi_id\": team_kpi_id, \"period_id\": period_id}).fetchall()\n",
    "        result_dicts = [row_to_dict(row) for row in results]\n",
    "        \n",
    "        return result_dicts\n",
    "\n",
    "\n",
    "def fetch_grade_definitions_from_db() -> Dict:\n",
    "    \"\"\"\n",
    "    `grades` 테이블에서 LLM이 참고할 등급 정의 (`grade_s`, `grade_a` 등 컬럼의 텍스트)를 조회합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT grade_id, grade_s, grade_a, grade_b, grade_c, grade_d, grade_rule FROM grades\")\n",
    "        results = connection.execute(query).fetchall()\n",
    "        \n",
    "        if results:\n",
    "            first_row = row_to_dict(results[0])\n",
    "            return {\n",
    "                \"S\": first_row.get(\"grade_s\", \"목표를 초과 달성\"),\n",
    "                \"A\": first_row.get(\"grade_a\", \"목표를 완벽하게 달성하며 높은 품질의 결과물 제공\"),\n",
    "                \"B\": first_row.get(\"grade_b\", \"목표 수준을 정확히 달성\"),\n",
    "                \"C\": first_row.get(\"grade_c\", \"목표에 미달했으나 일부 성과 달성\"),\n",
    "                \"D\": first_row.get(\"grade_d\", \"목표 달성 미흡\")\n",
    "            }\n",
    "        return {}\n",
    "\n",
    "\n",
    "def fetch_team_evaluation_id_by_team_and_period(team_id: int, period_id: int) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    `team_evaluations` 테이블에서 `team_id`와 `period_id`로 `team_evaluation_id`를 조회합니다.\n",
    "    Spring에서 이 레코드를 미리 생성하고 ID를 관리한다고 가정합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT team_evaluation_id FROM team_evaluations WHERE team_id = :team_id AND period_id = :period_id\")\n",
    "        result = connection.execute(query, {\"team_id\": team_id, \"period_id\": period_id}).scalar_one_or_none()\n",
    "        return result\n",
    "\n",
    "def fetch_temp_evaluation_id_by_emp_and_period(emp_no: str, period_id: int) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    `temp_evaluations` 테이블에서 `TempEvaluation_empNo`와 `period_id`로 `TempEvaluation_id`를 조회합니다.\n",
    "    (ERD상 `temp_evaluations`에 `period_id`가 직접 없고 `team_evaluation_id`를 통해 간접 연결되므로, Spring의 테이블 구조에 맞춰 쿼리 수정)\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT te.TempEvaluation_id\n",
    "            FROM temp_evaluations te\n",
    "            JOIN team_evaluations t_eval ON te.team_evaluation_id = t_eval.team_evaluation_id\n",
    "            WHERE te.TempEvaluation_empNo = :emp_no AND t_eval.period_id = :period_id\n",
    "        \"\"\")\n",
    "        result = connection.execute(query, {\"emp_no\": emp_no, \"period_id\": period_id}).scalar_one_or_none()\n",
    "        return result\n",
    "\n",
    "def fetch_employees_by_team_id(team_id: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    특정 팀에 속한 모든 직원의 emp_no, emp_name, role을 조회합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT emp_no, emp_name, role FROM employees WHERE team_id = :team_id\")\n",
    "        results = connection.execute(query, {\"team_id\": team_id}).fetchall()\n",
    "        return [row_to_dict(row) for row in results]\n",
    "\n",
    "# --- 데이터 업데이트/추가 함수 (`UPDATE` / `INSERT` 쿼리 구현) ---\n",
    "def update_task_ai_results_in_db(task_id: int, update_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    `task_id`에 해당하는 `tasks` 테이블 레코드의 AI 컬럼들을 업데이트합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        set_clauses = [f\"`{k}` = :{k}\" for k in update_data.keys()]\n",
    "        query = text(f\"UPDATE `tasks` SET {', '.join(set_clauses)} WHERE `task_id` = :task_id\")\n",
    "        \n",
    "        params = {**update_data, \"task_id\": task_id}\n",
    "        result = connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        return result.rowcount > 0\n",
    "\n",
    "def update_team_kpi_ai_results_in_db(team_kpi_id: int, update_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    `team_kpi_id`에 해당하는 `team_kpis` 테이블 레코드의 AI 컬럼들을 업데이트합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        set_clauses = [f\"`{k}` = :{k}\" for k in update_data.keys()]\n",
    "        query = text(f\"UPDATE `team_kpis` SET {', '.join(set_clauses)} WHERE `team_kpi_id` = :team_kpi_id\")\n",
    "        \n",
    "        params = {**update_data, \"team_kpi_id\": team_kpi_id}\n",
    "        result = connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        return result.rowcount > 0\n",
    "    \n",
    "\n",
    "def save_feedback_report_module2_results_to_db(emp_no: str, team_evaluation_id: int, results: Dict) -> int: \n",
    "    \"\"\"\n",
    "    `feedback_reports` 테이블에 모듈 2 관련 AI 결과를 삽입하거나 업데이트합니다.\n",
    "    `emp_no`와 `team_evaluation_id`가 중복되면 업데이트를 수행합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        # INSERT ... ON DUPLICATE KEY UPDATE 사용\n",
    "        # emp_no와 team_evaluation_id는 UNIQUE 키(또는 복합 PK)로 설정되어 있어야 합니다.\n",
    "        cols_for_insert = [\"emp_no\", \"team_evaluation_id\"] + list(results.keys())\n",
    "        values_placeholder = \", \".join([f\":{col}\" for col in cols_for_insert])\n",
    "        cols_str = \", \".join([f\"`{col}`\" for col in cols_for_insert])\n",
    "\n",
    "        # ON DUPLICATE KEY UPDATE 절에 사용할 컬럼들 (AI 결과 컬럼만 업데이트)\n",
    "        on_duplicate_set_clauses = [f\"`{k}` = VALUES(`{k}`)\" for k in results.keys()]\n",
    "        \n",
    "        query = text(f\"\"\"\n",
    "            INSERT INTO `feedback_reports` ({cols_str}) VALUES ({values_placeholder})\n",
    "            ON DUPLICATE KEY UPDATE {\", \".join(on_duplicate_set_clauses)}\n",
    "        \"\"\")\n",
    "        \n",
    "        params = {\"emp_no\": emp_no, \"team_evaluation_id\": team_evaluation_id, **results} \n",
    "        \n",
    "        connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        \n",
    "        # 삽입 또는 업데이트된 레코드의 ID를 다시 조회 (ON DUPLICATE KEY UPDATE의 LAST_INSERT_ID()는 복잡)\n",
    "        inserted_or_updated_id_query = text(\"\"\"\n",
    "            SELECT feedback_report_id FROM `feedback_reports`\n",
    "            WHERE `emp_no` = :emp_no AND `team_evaluation_id` = :team_evaluation_id\n",
    "        \"\"\")\n",
    "        ret_id = connection.execute(inserted_or_updated_id_query, {\"emp_no\": emp_no, \"team_evaluation_id\": team_evaluation_id}).scalar_one()\n",
    "        \n",
    "        print(f\"DB: feedback_reports[{ret_id}] for emp_no={emp_no}, team_evaluation_id={team_evaluation_id} inserted/updated.\")\n",
    "        return ret_id\n",
    "    \n",
    "\n",
    "def update_team_evaluations_module2_results_in_db(team_evaluation_id: int, update_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    `team_evaluations` 테이블에 모듈 2 관련 AI 결과를 업데이트합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        set_clauses = [f\"`{k}` = :{k}\" for k in update_data.keys()]\n",
    "        query = text(f\"UPDATE `team_evaluations` SET {', '.join(set_clauses)} WHERE `team_evaluation_id` = :team_evaluation_id\")\n",
    "        \n",
    "        params = {**update_data, \"team_evaluation_id\": team_evaluation_id}\n",
    "        result = connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        return result.rowcount > 0\n",
    "\n",
    "def save_final_evaluation_report_module2_results_to_db(emp_no: str, team_evaluation_id: int, results: Dict) -> int:\n",
    "    \"\"\"\n",
    "    `final_evaluation_reports` 테이블에 모듈 2 관련 AI 결과를 삽입하거나 업데이트합니다.\n",
    "    `emp_no`와 `team_evaluation_id`가 중복되면 업데이트를 수행합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        # INSERT ... ON DUPLICATE KEY UPDATE 사용\n",
    "        # emp_no와 team_evaluation_id는 UNIQUE 키(또는 복합 PK)로 설정되어 있어야 합니다.\n",
    "        cols_for_insert = [\"emp_no\", \"team_evaluation_id\"] + list(results.keys())\n",
    "        values_placeholder = \", \".join([f\":{col}\" for col in cols_for_insert])\n",
    "        cols_str = \", \".join([f\"`{col}`\" for col in cols_for_insert])\n",
    "        \n",
    "        on_duplicate_set_clauses = [f\"`{k}` = VALUES(`{k}`)\" for k in results.keys()]\n",
    "        \n",
    "        query = text(f\"\"\"\n",
    "            INSERT INTO `final_evaluation_reports` ({cols_str}) VALUES ({values_placeholder})\n",
    "            ON DUPLICATE KEY UPDATE {\", \".join(on_duplicate_set_clauses)}\n",
    "        \"\"\")\n",
    "        \n",
    "        params = {\"emp_no\": emp_no, \"team_evaluation_id\": team_evaluation_id, **results}\n",
    "        \n",
    "        connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        \n",
    "        inserted_or_updated_id_query = text(\"\"\"\n",
    "            SELECT final_evaluation_report_id FROM `final_evaluation_reports`\n",
    "            WHERE `emp_no` = :emp_no AND `team_evaluation_id` = :team_evaluation_id\n",
    "        \"\"\")\n",
    "        ret_id = connection.execute(inserted_or_updated_id_query, {\"emp_no\": emp_no, \"team_evaluation_id\": team_evaluation_id}).scalar_one()\n",
    "        \n",
    "        print(f\"DB: final_evaluation_reports[{ret_id}] created/updated for emp_no={emp_no}.\")\n",
    "        return ret_id\n",
    "\n",
    "def update_temp_evaluations_module2_results_in_db(temp_evaluation_id: int, update_data: Dict) -> bool:\n",
    "    \"\"\"\n",
    "    `temp_evaluations` 테이블에 모듈 2 관련 AI 결과를 업데이트합니다.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        set_clauses = [f\"`{k}` = :{k}\" for k in update_data.keys()]\n",
    "        query = text(f\"UPDATE `temp_evaluations` SET {', '.join(set_clauses)} WHERE `TempEvaluation_id` = :temp_evaluation_id\")\n",
    "        \n",
    "        params = {**update_data, \"temp_evaluation_id\": temp_evaluation_id}\n",
    "        result = connection.execute(query, params)\n",
    "        connection.commit()\n",
    "        return result.rowcount > 0\n",
    "\n",
    "# --- LLM 호출 함수들 ---\n",
    "\n",
    "def call_llm_for_task_contribution(task_summary_text: str) -> Dict:\n",
    "    print(f\"LLM Call (Task Contribution): '{task_summary_text[:30]}...'\")\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 SK 조직의 성과 평가 전문가입니다.\n",
    "    아래 Task 요약 내용을 보고, 해당 Task가 전체 프로젝트/팀 목표에 얼마나 기여했는지, \n",
    "    그리고 업무의 난이도, 완성도, 중요도를 종합적으로 고려하여 100점 만점으로 기여도 점수를 산정하고, \n",
    "    간략한 분석 코멘트를 생성해주세요.\n",
    "\n",
    "    평가 시 다음을 고려합니다:\n",
    "    - Task의 복잡성과 달성 난이도\n",
    "    - Task 결과물의 품질과 완성도\n",
    "    - Task가 다음 단계 또는 다른 팀원에게 미친 긍정적 영향 (선행 조건 해결 등)\n",
    "    - Task가 팀 목표 달성에 기여한 정도\n",
    "\n",
    "    결과는 다음 JSON 형식으로만 응답해주세요. 불필요한 서문이나 추가 설명 없이 JSON만 반환해야 합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    human_prompt = f\"\"\"\n",
    "    <Task 요약>\n",
    "    {task_summary_text}\n",
    "    </Task 요약>\n",
    "\n",
    "    JSON 응답:\n",
    "    {{\n",
    "      \"기여도 점수\": [기여도 점수 (0-100점, 소수점 첫째 자리까지)],\n",
    "      \"분석 코멘트\": \"[Task에 대한 분석 코멘트]\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=human_prompt)\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response: AIMessage = chain.invoke({\"task_summary_text\": task_summary_text})\n",
    "        json_output_raw = response.content\n",
    "\n",
    "        json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "\n",
    "        llm_parsed_data = json.loads(json_output)\n",
    "\n",
    "        score = llm_parsed_data.get(\"기여도 점수\") \n",
    "        comment = llm_parsed_data.get(\"분석 코멘트\") \n",
    "\n",
    "\n",
    "        if not isinstance(score, (int, float)) or not (0 <= score <= 100):\n",
    "            raise ValueError(f\"LLM 반환 점수 {score}가 유효하지 않습니다.\")\n",
    "        if not isinstance(comment, str) or not comment:\n",
    "            raise ValueError(f\"LLM 반환 코멘트 {comment}가 유효하지 않습니다.\")\n",
    "\n",
    "        return {\"score\": round(float(score), 2), \"comment\": comment}\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\"score\": 0.0, \"comment\": f\"AI 분석 실패: JSON 파싱 오류 - {json_output_raw[:100]}...\"}\n",
    "    except ValueError as e:\n",
    "        print(f\"LLM 응답 데이터 유효성 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\"score\": 0.0, \"comment\": f\"AI 분석 실패: 유효성 오류 - {json_output_raw[:100]}...\"}\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 예기치 않은 오류 발생: {e}. 원본 응답: '{json_output_raw}'\")\n",
    "        return {\"score\": 0.0, \"comment\": f\"AI 분석 실패: 예기치 않은 오류 - {str(e)[:100]}...\"}\n",
    "\n",
    "\n",
    "def call_llm_for_task_achievement(target_level_text: str, task_performance_text: str, grade_definitions: Dict) -> Dict:\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    당신은 SK 조직의 성과 평가 전문가입니다.\n",
    "    아래 Task 목표와 실제 성과를 비교하여, Task의 달성률(0-100점 이상)과 적절한 등급(S, A, B, C, D)을 판단하고,\n",
    "    상세 분석 코멘트를 생성해주세요.\n",
    "\n",
    "    평가 기준은 다음과 같습니다:\n",
    "    - 달성률은 0점부터 시작하며, 100점을 초과하여 목표 초과 달성을 나타낼 수 있습니다. (예: 100.1% 이상)\n",
    "    - 등급은 S, A, B, C, D 중 하나여야 합니다.\n",
    "\n",
    "    <등급 정의 (LLM 참고용)>\n",
    "    \"\"\"\n",
    "    for grade, desc in grade_definitions.items():\n",
    "        system_prompt += f\"- {grade} 등급: {desc}\\n\"\n",
    "    system_prompt += \"</등급 정의>\\n\"\n",
    "    system_prompt += \"결과는 다음 JSON 형식으로만 응답해주세요. 불필요한 서문이나 추가 설명 없이 JSON만 반환해야 합니다.\"\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "    <Task 목표>\n",
    "    {target_level_text}\n",
    "    </Task 목표>\n",
    "\n",
    "    <실제 성과>\n",
    "    {task_performance_text}\n",
    "    </실제 성과>\n",
    "\n",
    "    JSON 응답:\n",
    "    {{\n",
    "      \"달성률\": [달성률 (0-100점 이상)],\n",
    "      \"등급\": \"[S, A, B, C, D 중 하나]\",\n",
    "      \"상세 분석 코멘트\": \"[Task에 대한 상세 분석 코멘트]\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=human_prompt)\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response: AIMessage = chain.invoke({\"target_level_text\": target_level_text, \"task_performance_text\": task_performance_text, \"grade_definitions\": grade_definitions})\n",
    "        json_output_raw = response.content\n",
    "        \n",
    "        json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "        \n",
    "        llm_parsed_data = json.loads(json_output)\n",
    "        \n",
    "        rate = llm_parsed_data.get(\"달성률\") \n",
    "        grade = llm_parsed_data.get(\"등급\") \n",
    "        analysis = llm_parsed_data.get(\"상세 분석 코멘트\") \n",
    "\n",
    "        # 수정된 부분: 달성률 유효성 검사 상한 제거\n",
    "        if not isinstance(rate, (int, float)) or not (0 <= rate): \n",
    "            raise ValueError(f\"LLM 반환 달성률 {rate}가 유효하지 않습니다 (0 이상이어야 합니다).\")\n",
    "        if grade not in [\"S\", \"A\", \"B\", \"C\", \"D\"]:\n",
    "            raise ValueError(f\"LLM 반환 등급 {grade}가 유효하지 않습니다.\")\n",
    "        if not isinstance(analysis, str) or not analysis:\n",
    "            raise ValueError(f\"LLM 반환 분석 코멘트 {analysis}가 유효하지 않습니다.\")\n",
    "\n",
    "        return {\"grade\": grade, \"rate\": round(float(rate), 2), \"analysis\": analysis}\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\"grade\": \"D\", \"rate\": 0.0, \"analysis\": f\"AI 분석 실패: JSON 파싱 오류 - {json_output_raw[:100]}...\"}\n",
    "    except ValueError as e:\n",
    "        print(f\"LLM 응답 데이터 유효성 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\"grade\": \"D\", \"rate\": 0.0, \"analysis\": f\"AI 분석 실패: 유효성 오류 - {json_output_raw[:100]}...\"}\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 예기치 않은 오류 발생: {e}. 원본 응답: '{json_output_raw}'\")\n",
    "        return {\"grade\": \"D\", \"rate\": 0.0, \"analysis\": f\"AI 분석 실패: 예기치 않은 오류 - {str(e)[:100]}...\"}\n",
    "\n",
    "\n",
    "def call_llm_for_overall_contribution_summary(all_individual_task_results: List[Dict], emp_name: str, emp_no: str) -> Dict: \n",
    "    print(f\"LLM Call (Overall Contribution Summary): '{emp_name} ({emp_no})' Task {len(all_individual_task_results)}개 기반 요약 요청.\") \n",
    "\n",
    "    task_details_str = \"\"\n",
    "    for task in all_individual_task_results:\n",
    "        task_details_str += f\"- Task: {task.get('task_name')} (ID: {task.get('task_id')})\\n\"\n",
    "        task_details_str += f\"  Summary: {task.get('task_summary', task.get('task_performance', ''))}\\n\"\n",
    "        if task.get('ai_contribution_score') is not None:\n",
    "            task_details_str += f\"  AI 기여도: {task.get('ai_contribution_score')}점\\n\"\n",
    "        if task.get('ai_achievement_rate') is not None:\n",
    "            task_details_str += f\"  AI 달성률: {task.get('ai_achievement_rate')}%\\n\"\n",
    "        if task.get('ai_assessed_grade'):\n",
    "            task_details_str += f\"  AI 등급: {task.get('ai_assessed_grade')}\\n\"\n",
    "        task_details_str += \"\\n\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 SK 조직의 HR 성과 전문가입니다.\n",
    "    아래 제공된 개인의 모든 Task 정보, Task Summary, 그리고 AI가 분석한 개별 Task 기여도/달성률 점수를 종합적으로 고려하여,\n",
    "    이 개인의 총체적인 기여도 점수 (팀 내 상대 비율, 0-100%)를 추정하고,\n",
    "    이름과 사번을 명시하며 개인의 전체적인 성과와 기여에 대한 간략한 종합 코멘트를 생성해주세요.\n",
    "\n",
    "    결과는 다음 JSON 형식으로만 응답해주세요. 불필요한 서문이나 추가 설명 없이 JSON만 반환해야 합니다.\n",
    "    직원 이름을 언급할 때는 반드시 \"이름(사번)님\" 형태로 작성해주세요.\n",
    "    \"\"\"\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "    <개인 Task 종합 정보>\n",
    "    {task_details_str}\n",
    "    </개인 Task 종합 정보>\n",
    "    <평가 대상 개인 정보>\n",
    "    이름: {emp_name}\n",
    "    사번: {emp_no}\n",
    "    </평가 대상 개인 정보>\n",
    "\n",
    "    JSON 응답:\n",
    "    {{\n",
    "      \"total_contribution\": [개인의 총체적인 기여도 점수 (0-100점)],\n",
    "      \"comment\": \"[{emp_name}({emp_no})님의 전체 성과와 기여에 대한 종합 코멘트]\",\n",
    "      \"average_rate\": [Task 달성률들의 평균 또는 종합적인 달성률 추정 (0-100점 이상)]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=human_prompt)\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response: AIMessage = chain.invoke({\"all_individual_task_results\": all_individual_task_results, \"emp_name\": emp_name, \"emp_no\": emp_no})\n",
    "        json_output_raw = response.content\n",
    "        \n",
    "        json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "        \n",
    "        llm_parsed_data = json.loads(json_output)\n",
    "        \n",
    "        total_contribution = llm_parsed_data.get(\"total_contribution\")\n",
    "        comment = llm_parsed_data.get(\"comment\")\n",
    "        average_rate = llm_parsed_data.get(\"average_rate\")\n",
    "\n",
    "        if not isinstance(total_contribution, (int, float)) or not (0 <= total_contribution <= 100):\n",
    "            raise ValueError(f\"LLM 반환 총 기여도 {total_contribution}가 유효하지 않습니다.\")\n",
    "        if not isinstance(comment, str) or not comment:\n",
    "            raise ValueError(f\"LLM 반환 코멘트 {comment}가 유효하지 않습니다.\")\n",
    "        if not isinstance(average_rate, (int, float)) or not (0 <= average_rate): # 0-120점 -> 0점 이상으로 수정\n",
    "            raise ValueError(f\"LLM 반환 평균 달성률 {average_rate}가 유효하지 않습니다 (0 이상이어야 합니다).\")\n",
    "\n",
    "        return {\"total_contribution\": round(float(total_contribution), 2), \"comment\": comment, \"average_rate\": round(float(average_rate), 2)}\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\"total_contribution\": 0.0, \"comment\": f\"AI 분석 실패: JSON 파싱 오류 - {json_output_raw[:100]}...\", \"average_rate\": 0.0}\n",
    "    except ValueError as e:\n",
    "        print(f\"LLM 응답 데이터 유효성 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\"total_contribution\": 0.0, \"comment\": f\"AI 분석 실패: 유효성 오류 - {json_output_raw[:100]}...\", \"average_rate\": 0.0}\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 예기치 않은 오류 발생: {e}. 원본 응답: '{json_output_raw}'\")\n",
    "        return {\"total_contribution\": 0.0, \"comment\": f\"AI 분석 실패: 예기치 않은 오류 - {str(e)[:100]}...\", \"average_rate\": 0.0}\n",
    "\n",
    "\n",
    "def call_llm_for_team_overall_analysis(all_team_kpis_results: List[Dict]) -> Dict:\n",
    "    print(f\"LLM Call (Team Overall Analysis): KPI {len(all_team_kpis_results)}개 기반 분석 요청.\")\n",
    "\n",
    "    kpi_details_str = \"\"\n",
    "    for kpi in all_team_kpis_results:\n",
    "        kpi_details_str += f\"- KPI: {kpi.get('kpi_name')} (ID: {kpi.get('team_kpi_id')})\\n\"\n",
    "        kpi_details_str += f\"  Description: {kpi.get('kpi_description')}\\n\"\n",
    "        if kpi.get('ai_kpi_overall_progress_rate') is not None:\n",
    "            kpi_details_str += f\"  AI 진행률: {kpi.get('ai_kpi_overall_progress_rate')}%\\n\"\n",
    "        if kpi.get('ai_kpi_analysis_comment'):\n",
    "            kpi_details_str += f\"  AI 코멘트: {kpi.get('ai_kpi_analysis_comment')}\\n\"\n",
    "        kpi_details_str += \"\\n\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 SK 조직의 고위 경영진을 위한 팀 성과 분석 전문가입니다.\n",
    "    아래 제공된 팀의 KPI 정보, 설명, 그리고 AI가 분석한 각 KPI의 진행률 및 코멘트를 종합적으로 검토하여,\n",
    "    이 팀의 전반적인 목표 달성률을 추정하고, 팀 성과의 주요 특징과 개선점에 대한 분석 코멘트를 생성해주세요.\n",
    "\n",
    "    결과는 다음 JSON 형식으로만 응답해주세요. 불필요한 서문이나 추가 설명 없이 JSON만 반환해야 합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "    <팀 KPI 종합 정보>\n",
    "    {kpi_details_str}\n",
    "    </팀 KPI 종합 정보>\n",
    "\n",
    "    JSON 응답:\n",
    "    {{\n",
    "      \"overall_rate\": [팀 전체의 목표 달성률 추정 (0-100점)],\n",
    "      \"comment\": \"[팀 성과에 대한 전반적인 분석 코멘트]\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=human_prompt)\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response: AIMessage = chain.invoke({\"all_team_kpis_results\": all_team_kpis_results})\n",
    "        json_output_raw = response.content\n",
    "        \n",
    "        json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "        \n",
    "        llm_parsed_data = json.loads(json_output)\n",
    "        \n",
    "        overall_rate = llm_parsed_data.get(\"overall_rate\")\n",
    "        comment = llm_parsed_data.get(\"comment\")\n",
    "\n",
    "        if not isinstance(overall_rate, (int, float)) or not (0 <= overall_rate <= 100):\n",
    "            raise ValueError(f\"LLM 반환 전체 달성률 {overall_rate}가 유효하지 않습니다.\")\n",
    "        if not isinstance(comment, str) or not comment:\n",
    "            raise ValueError(f\"LLM 반환 코멘트 {comment}가 유효하지 않습니다.\")\n",
    "\n",
    "        return {\"overall_rate\": round(float(overall_rate), 2), \"comment\": comment}\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\"overall_rate\": 0.0, \"comment\": f\"AI 분석 실패: JSON 파싱 오류 - {json_output_raw[:100]}...\"}\n",
    "    except ValueError as e:\n",
    "        print(f\"LLM 응답 데이터 유효성 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\"overall_rate\": 0.0, \"comment\": f\"AI 분석 실패: 유효성 오류 - {json_output_raw[:100]}...\"}\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 예기치 않은 오류 발생: {e}. 원본 응답: '{json_output_raw}'\")\n",
    "        return {\"overall_rate\": 0.0, \"comment\": f\"AI 분석 실패: 예기치 않은 오류 - {str(e)[:100]}...\"}\n",
    "\n",
    "\n",
    "def call_llm_for_kpi_relative_contribution(kpi_analysis_input: Dict) -> Dict:\n",
    "    kpi_goal = kpi_analysis_input.get(\"kpi_goal\", \"알 수 없는 목표\")\n",
    "    kpi_description = kpi_analysis_input.get(\"kpi_description\", \"\")\n",
    "    team_tasks = kpi_analysis_input.get(\"team_members_tasks\", [])\n",
    "    \n",
    "    print(f\"LLM Call (KPI Relative Contribution): '{kpi_goal[:30]}...' KPI 내 개인별 상대 기여도 분석 요청.\")\n",
    "    \n",
    "    actual_emp_nos_in_kpi = sorted(list(set(task.get('emp_no') for task in team_tasks if task.get('emp_no'))))\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 팀 KPI 성과에 대한 개인별 기여도를 평가하는 전문가입니다.\n",
    "    아래는 특정 팀 KPI의 목표, 설명, 그리고 이 KPI에 기여한 팀원들의 Task 상세 내용 및 AI가 분석한 개별 Task 기여도 점수입니다.\n",
    "    \n",
    "    이 정보를 종합적으로 검토하여 다음을 수행하세요:\n",
    "    1. 이 KPI에 대한 각 개인의 **상대적인 기여도 점수 (총합 100%)**를 판단하세요.\n",
    "       - 반환하는 JSON의 `individual_relative_contributions_in_kpi` 딕셔너리에는 아래 <실제 팀원 사번 목록>에 있는 모든 사번에 대해 기여도를 포함해야 합니다.\n",
    "       - 각 개인의 기여도 점수(0-100점)는 소수점 두 자리까지 허용합니다.\n",
    "       - 어떤 팀원의 기여도가 0%이더라도 해당 사번과 0점을 명시적으로 포함해야 합니다.\n",
    "       - 모든 팀원의 기여도 합계가 100%가 되도록 조정해야 합니다.\n",
    "    2. KPI 전체의 진행 상황에 대한 간략한 분석 코멘트를 생성하세요.\n",
    "\n",
    "    평가 시 다음을 고려해야 합니다:\n",
    "    - 각 Task의 내용이 KPI 목표 달성에 얼마나 중요한가?\n",
    "    - 각 Task의 AI 기여도 점수는 어떤 의미인가? (개별 Task의 품질 및 중요도)\n",
    "    - 팀원 간 Task의 상호 의존성, 선행/후행 관계, 협업 기여도\n",
    "    - 특정 팀원이 여러 Task를 수행했거나, 더 중요한 Task를 수행했는가?\n",
    "    - 결과물 JSON에 불필요한 텍스트를 포함하지 마세요.\n",
    "    - 직원 이름을 언급할 때는 반드시 \"이름(사번)님\" 형태로 작성해주세요.\n",
    "\n",
    "\n",
    "    결과는 다음 JSON 형식으로만 응답해주세요:\n",
    "    \"\"\"\n",
    "\n",
    "    team_tasks_str = \"\"\n",
    "    for task in team_tasks:\n",
    "        emp_name = task.get('emp_name', '이름없음') \n",
    "        emp_no = task.get('emp_no', '사번없음')\n",
    "        team_tasks_str += f\"- 팀원: {emp_name}({emp_no})님, Task: {task.get('task_name')}\\n\" \n",
    "        team_tasks_str += f\"  요약: {task.get('task_summary')}\\n\"\n",
    "        if task.get('ai_contribution_score_from_individual_analysis') is not None:\n",
    "            team_tasks_str += f\"  개별 AI 기여도 점수 (참고용): {task.get('ai_contribution_score_from_individual_analysis')}점\\n\"\n",
    "        team_tasks_str += \"\\n\"\n",
    "\n",
    "\n",
    "    individual_contributions_json_example = \",\\n\".join([f'\"{emp_no}\": [상대 기여도 (0-100점)]' for emp_no in actual_emp_nos_in_kpi])\n",
    "    if not individual_contributions_json_example:\n",
    "        individual_contributions_json_example = '\"EMP_NO_X\": [상대 기여도 (0-100점)]'\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "    <팀 KPI 목표>\n",
    "    {kpi_goal}\n",
    "    </팀 KPI 목표>\n",
    "    <팀 KPI 설명>\n",
    "    {kpi_description}\n",
    "    </팀 KPI 설명>\n",
    "    <팀원 Task 정보>\n",
    "    {team_tasks_str}\n",
    "    </팀원 Task 정보>\n",
    "    <실제 팀원 사번 목록>\n",
    "    {', '.join(actual_emp_nos_in_kpi) if actual_emp_nos_in_kpi else '없음'}\n",
    "    </실제 팀원 사번 목록>\n",
    "\n",
    "    JSON 응답:\n",
    "    {{\n",
    "      \"kpi_overall_rate\": [KPI 전체의 진행 상황에 대한 점수 (0-100점)],\n",
    "      \"kpi_analysis_comment\": \"[KPI 전체 진행 상황에 대한 분석 코멘트]\",\n",
    "      \"individual_relative_contributions_in_kpi\": {{\n",
    "        {individual_contributions_json_example}\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=human_prompt)\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response: AIMessage = chain.invoke({\"kpi_analysis_input\": kpi_analysis_input})\n",
    "        json_output_raw = response.content\n",
    "        json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "        \n",
    "        llm_parsed_data = json.loads(json_output)\n",
    "        \n",
    "        kpi_overall_rate = llm_parsed_data.get(\"kpi_overall_rate\")\n",
    "        kpi_analysis_comment = llm_parsed_data.get(\"kpi_analysis_comment\")\n",
    "        individual_relative_contributions_raw_from_llm = llm_parsed_data.get(\"individual_relative_contributions_in_kpi\")\n",
    "\n",
    "        if not isinstance(kpi_overall_rate, (int, float)) or not (0 <= kpi_overall_rate <= 100):\n",
    "            raise ValueError(f\"LLM 반환 KPI 전체 진행률 {kpi_overall_rate}가 유효하지 않습니다.\")\n",
    "        if not isinstance(kpi_analysis_comment, str) or not kpi_analysis_comment:\n",
    "            raise ValueError(f\"LLM 반환 KPI 분석 코멘트 {kpi_analysis_comment}가 유효하지 않습니다.\")\n",
    "        if not isinstance(individual_relative_contributions_raw_from_llm, dict):\n",
    "            raise ValueError(f\"LLM 반환 개인 상대 기여도 형식 {individual_relative_contributions_raw_from_llm}가 유효하지 않습니다.\")\n",
    "        \n",
    "        # --- 파싱 로직 보강: LLM이 반환한 사번 외의 사번 처리 및 합계 검증 ---\n",
    "        final_relative_contributions = {}\n",
    "        for emp_no in actual_emp_nos_in_kpi:\n",
    "            final_relative_contributions[emp_no] = 0.0\n",
    "        \n",
    "        for emp_no_from_llm, score in individual_relative_contributions_raw_from_llm.items():\n",
    "            if emp_no_from_llm in final_relative_contributions and isinstance(score, (int, float)):\n",
    "                final_relative_contributions[emp_no_from_llm] = round(float(score), 2)\n",
    "            else:\n",
    "                print(f\"Warning: LLM이 예상치 못한 사번 '{emp_no_from_llm}'를 반환했거나 점수가 유효하지 않아 무시됩니다. 점수: {score}\")\n",
    "\n",
    "        total_relative_sum = sum(final_relative_contributions.values())\n",
    "        if total_relative_sum > 0 and not (99.9 <= total_relative_sum <= 100.1):\n",
    "            print(f\"Warning: 개인 상대 기여도 합계가 100%와 다릅니다: {total_relative_sum}%. 재조정 시도.\")\n",
    "            adjustment_factor = 100.0 / total_relative_sum if total_relative_sum > 0 else 1.0\n",
    "            adjusted_contributions = {k: round(v * adjustment_factor, 2) for k, v in final_relative_contributions.items()}\n",
    "            final_relative_contributions = adjusted_contributions\n",
    "            print(f\"재조정된 기여도: {final_relative_contributions}\")\n",
    "            \n",
    "        return {\n",
    "            \"kpi_overall_rate\": round(float(kpi_overall_rate), 2),\n",
    "            \"kpi_analysis_comment\": kpi_analysis_comment,\n",
    "            \"individual_relative_contributions_in_kpi\": final_relative_contributions\n",
    "        }\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\n",
    "            \"kpi_overall_rate\": 0.0,\n",
    "            \"kpi_analysis_comment\": f\"AI 분석 실패: JSON 파싱 오류 - {json_output_raw[:100]}...\",\n",
    "            \"individual_relative_contributions_in_kpi\": {}\n",
    "        }\n",
    "    except ValueError as e:\n",
    "        print(f\"LLM 응답 데이터 유효성 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\n",
    "            \"kpi_overall_rate\": 0.0,\n",
    "            \"kpi_analysis_comment\": f\"AI 분석 실패: 유효성 오류 - {json_output_raw[:100]}...\",\n",
    "            \"individual_relative_contributions_in_kpi\": {}\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 예기치 않은 오류 발생: {e}. 원본 응답: '{json_output_raw}'\")\n",
    "        return {\n",
    "            \"kpi_overall_rate\": 0.0,\n",
    "            \"kpi_analysis_comment\": f\"AI 분석 실패: 예기치 않은 오류 - {str(e)[:100]}...\",\n",
    "            \"individual_relative_contributions_in_kpi\": {}\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "def call_llm_for_individual_contribution_reason_comment(\n",
    "    task_info: Dict, \n",
    "    adjusted_contribution_score: float, \n",
    "    kpi_goal: str, \n",
    "    kpi_overall_comment: str) -> Dict:\n",
    "    \"\"\"\n",
    "    개인의 Task 상세 내역, 조정된 기여도 점수, KPI 맥락을 종합하여\n",
    "    Task에 대한 기여도 근거 코멘트를 생성합니다.\n",
    "    \"\"\"\n",
    "    emp_name = task_info.get(\"emp_name\", \"이름 없음\") # Task info에 emp_name이 없다면 db에서 조회해야 함\n",
    "    emp_no = task_info.get(\"emp_no\", \"사번 없음\")\n",
    "    task_name = task_info.get(\"task_name\", \"알 수 없는 Task\")\n",
    "    task_summary_text = task_info.get(\"task_summary\", task_info.get(\"task_performance\", \"상세 내용 없음\"))\n",
    "\n",
    "    print(f\"LLM Call (Individual Contribution Reason): '{emp_name} ({emp_no})'의 '{task_name[:30]}...' Task 근거 요청.\")\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    당신은 SK 조직의 성과 평가 전문가이자 명확한 근거를 제시하는 분석가입니다.\n",
    "    아래 제공된 개인의 특정 Task 상세 내용, 이 Task가 속한 KPI의 목표, 그리고 팀 전체에 대한 KPI 분석 코멘트를 종합적으로 고려하여,\n",
    "    이 Task의 최종 조정된 기여도 점수(KPI 내 상대적 기여도)가 왜 그렇게 산정되었는지에 대한 구체적이고 복합적인 근거 코멘트를 작성해주세요.\n",
    "\n",
    "    코멘트는 다음 요소를 포함해야 합니다:\n",
    "    - Task 자체의 내용과 중요도 (Task Summary 기반)\n",
    "    - LLM이 판단한 KPI 내 상대적 기여도 점수 (제시된 점수 활용)\n",
    "    - 이 Task가 팀 KPI 목표 달성에 어떻게 기여했는지 (KPI 목표, 전체 KPI 코멘트 기반)\n",
    "    - Task 간의 상호 관계나 협업 등의 맥락이 기여도에 미친 영향 (제공된 정보 내에서 추론)\n",
    "    - 직원 이름을 언급할 때는 반드시 \"이름(사번)님\" 형태로 작성해주세요.\n",
    "\n",
    "    결과는 다음 JSON 형식으로만 응답해주세요. 불필요한 서문이나 추가 설명 없이 JSON만 반환해야 합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "    <Task 상세 정보>\n",
    "    이름: {emp_name}\n",
    "    사번: {emp_no}\n",
    "    Task 이름: {task_name}\n",
    "    Task 요약/성과: {task_summary_text}\n",
    "    조정된 기여도 점수: {adjusted_contribution_score}점\n",
    "    </Task 상세 정보>\n",
    "\n",
    "    <KPI 정보>\n",
    "    KPI 목표: {kpi_goal}\n",
    "    KPI 전체 분석 코멘트: {kpi_overall_comment}\n",
    "    </KPI 정보>\n",
    "\n",
    "    JSON 응답:\n",
    "    {{\n",
    "      \"comment_reason\": \"[{emp_name}({emp_no})님의 해당 Task에 대한 구체적 근거 코멘트]\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=human_prompt)\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response: AIMessage = chain.invoke({\n",
    "            \"task_info\": task_info, \n",
    "            \"adjusted_contribution_score\": adjusted_contribution_score, \n",
    "            \"kpi_goal\": kpi_goal, \n",
    "            \"kpi_overall_comment\": kpi_overall_comment\n",
    "        })\n",
    "        json_output_raw = response.content\n",
    "        json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "        llm_parsed_data = json.loads(json_output)\n",
    "        \n",
    "        comment_reason = llm_parsed_data.get(\"comment_reason\")\n",
    "\n",
    "        if not isinstance(comment_reason, str) or not comment_reason:\n",
    "            raise ValueError(f\"LLM 반환 근거 코멘트 {comment_reason}가 유효하지 않습니다.\")\n",
    "\n",
    "        return {\"comment\": comment_reason}\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}. 원본 응답: '{json_output_raw}'. 파싱 시도 텍스트: '{json_output[:100]}...'\")\n",
    "        return {\"comment\": f\"AI 근거 생성 실패: JSON 파싱 오류 - {json_output_raw[:100]}...\"}\n",
    "    except ValueError as e:\n",
    "        print(f\"LLM 응답 데이터 유효성 오류: {e}. 응답: {json_output}\")\n",
    "        return {\"comment\": f\"AI 근거 생성 실패: 유효성 오류 - {json_output[:100]}...\"}\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 예기치 않은 오류 발생: {e}. 원본 응답: '{json_output_raw}'\")\n",
    "        return {\"comment\": f\"AI 근거 생성 실패: 예기치 않은 오류 - {str(e)[:100]}...\"}\n",
    "\n",
    "# ... (나머지 기존 코드) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362dbbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc625255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb9f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 서브모듈 함수 정의 ---\n",
    "\n",
    "# 1. 데이터 수집 서브모듈\n",
    "def data_collection_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "    messages = state.get(\"messages\", []) + [HumanMessage(content=\"모듈 2: 데이터 수집 ID 초기화 완료\")] \n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "# 2. 개인 기여도 계산 서브모듈\n",
    "def calculate_individual_contribution_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "    report_type = state[\"report_type\"] \n",
    "    target_task_summary_ids = state[\"target_task_summary_ids\"] \n",
    "    \n",
    "    updated_task_ids_list = [] \n",
    "\n",
    "    for task_summary_id in target_task_summary_ids: \n",
    "        task_data = fetch_task_summary_by_id(task_summary_id) \n",
    "        if not task_data: \n",
    "            print(f\"Warning: Task data not found for task_summary_id {task_summary_id}.\") \n",
    "            continue \n",
    "        \n",
    "        task_id = task_data[\"task_id\"] \n",
    "        \n",
    "        llm_results = {} \n",
    "        update_data = {} \n",
    "\n",
    "        # --- 분기별 로직: 기여도만 계산 ---\n",
    "        if report_type == \"quarterly\": \n",
    "            task_summary_text = task_data.get(\"task_summary\", \"\") \n",
    "            if task_summary_text: \n",
    "                llm_results = call_llm_for_task_contribution(task_summary_text) \n",
    "                update_data = {\n",
    "                    \"ai_contribution_score\": llm_results.get(\"score\"), \n",
    "                    \"ai_analysis_comment_task\": llm_results.get(\"comment\") \n",
    "                }\n",
    "            else: \n",
    "                print(f\"Warning: No task_summary found for task_id {task_id} in {report_type} report.\") \n",
    "                continue \n",
    "        # --- 연말 로직: 달성률/등급 및 기여도 계산 ---\n",
    "        elif report_type == \"annual\": \n",
    "            target_level = task_data.get(\"target_level\", \"\") \n",
    "            task_performance = task_data.get(\"task_performance\", \"\") \n",
    "            task_summary_text_q4 = task_data.get(\"task_summary\", \"\") \n",
    "\n",
    "            grade_definitions = fetch_grade_definitions_from_db() \n",
    "            \n",
    "            if target_level and task_performance: \n",
    "                llm_achievement_results = call_llm_for_task_achievement(target_level, task_performance, grade_definitions) \n",
    "                \n",
    "                llm_contribution_results = call_llm_for_task_contribution(task_summary_text_q4) \n",
    "                \n",
    "                update_data = {\n",
    "                    \"ai_contribution_score\": llm_contribution_results.get(\"score\"), \n",
    "                    \"ai_achievement_rate\": llm_achievement_results.get(\"rate\"), \n",
    "                    \"ai_assessed_grade\": llm_achievement_results.get(\"grade\"), \n",
    "                    \"ai_analysis_comment_task\": llm_achievement_results.get(\"analysis\") \n",
    "                }\n",
    "            else: \n",
    "                print(f\"Warning: target_level or task_performance missing for task_id {task_id} in {report_type} report.\") \n",
    "                continue \n",
    "\n",
    "        if update_task_ai_results_in_db(task_id, update_data): \n",
    "            updated_task_ids_list.append(task_id) \n",
    "        else: \n",
    "            print(f\"Failed to update AI results for task_id: {task_id}\") \n",
    "\n",
    "    messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 개인 Task 기여도/달성률 계산 및 DB 업데이트 완료 ({len(updated_task_ids_list)}건)\")] \n",
    "    return {\"messages\": messages, \"updated_task_ids\": updated_task_ids_list}\n",
    "\n",
    "\n",
    "\n",
    "# 3. 팀 목표 분석 서브모듈 (수정: KPI 내 개인 상대 기여도 계산 및 LLM 요청 후 tasks 업데이트)\n",
    "def analyze_team_goals_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "    report_type = state[\"report_type\"] \n",
    "    target_team_kpi_ids = state[\"target_team_kpi_ids\"] \n",
    "    period_id = state[\"period_id\"] \n",
    "\n",
    "    updated_team_kpi_ids_list = [] \n",
    "    kpi_individual_relative_contributions_for_state = [] \n",
    "\n",
    "    for team_kpi_id in target_team_kpi_ids: \n",
    "        kpi_data = fetch_kpi_data_by_id(team_kpi_id) \n",
    "        if not kpi_data: \n",
    "            print(f\"Warning: Team KPI data not found for team_kpi_id {team_kpi_id}.\") \n",
    "            continue \n",
    "\n",
    "        tasks_in_this_kpi = fetch_tasks_for_kpi(team_kpi_id, period_id) \n",
    "        \n",
    "        llm_input_for_kpi_analysis = {\n",
    "            \"kpi_goal\": kpi_data.get(\"kpi_name\"), \n",
    "            \"kpi_description\": kpi_data.get(\"kpi_description\"), \n",
    "            \"team_members_tasks\": [\n",
    "                {\n",
    "                    \"emp_no\": task.get(\"emp_no\"), \n",
    "                    \"task_id\": task.get(\"task_id\"), \n",
    "                    \"task_name\": task.get(\"task_name\"), \n",
    "                    \"task_summary\": task.get(\"task_summary\"), \n",
    "                    \"ai_contribution_score_from_individual_analysis\": task.get(\"ai_contribution_score\") \n",
    "                } for task in tasks_in_this_kpi\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        llm_kpi_analysis_results = call_llm_for_kpi_relative_contribution(llm_input_for_kpi_analysis) \n",
    "\n",
    "        update_data_kpi = { \n",
    "            \"ai_kpi_overall_progress_rate\": llm_kpi_analysis_results.get(\"kpi_overall_rate\"), \n",
    "            \"ai_kpi_analysis_comment\": llm_kpi_analysis_results.get(\"kpi_analysis_comment\") \n",
    "        }\n",
    "\n",
    "        if update_team_kpi_ai_results_in_db(team_kpi_id, update_data_kpi): \n",
    "            updated_team_kpi_ids_list.append(team_kpi_id) \n",
    "            \n",
    "            if \"individual_relative_contributions_in_kpi\" in llm_kpi_analysis_results: \n",
    "                relative_contributions_by_emp = llm_kpi_analysis_results[\"individual_relative_contributions_in_kpi\"]\n",
    "                kpi_individual_relative_contributions_for_state.append({ \n",
    "                    \"team_kpi_id\": team_kpi_id,\n",
    "                    \"relative_contributions\": relative_contributions_by_emp\n",
    "                }) \n",
    "\n",
    "                # --- 수정된 부분: tasks 테이블 ai_contribution_score 및 ai_analysis_comment_task 업데이트 ---\n",
    "                for task in tasks_in_this_kpi: # 현재 KPI에 속한 Task들을 다시 순회\n",
    "                    emp_no_task = task.get(\"emp_no\")\n",
    "                    task_id_current = task.get(\"task_id\")\n",
    "                    \n",
    "                    if emp_no_task in relative_contributions_by_emp:\n",
    "                        new_contribution_score = relative_contributions_by_emp[emp_no_task]\n",
    "                        \n",
    "                        # LLM 호출을 위한 Task 상세 정보 준비\n",
    "                        # task_data에는 emp_name도 포함될 수 있도록 fetch_task_summary_by_id 쿼리 확인\n",
    "                        # (py의 fetch_employees_by_team_id도 emp_name을 가져옴)\n",
    "                        task_data_for_comment = fetch_task_summary_by_id(task.get(\"task_summary_Id\")) # task_summary_Id 필요\n",
    "                        if not task_data_for_comment:\n",
    "                            print(f\"Warning: Task data for comment generation not found for task_summary_Id {task.get('task_summary_Id')}.\")\n",
    "                            continue\n",
    "\n",
    "                        # 새로운 LLM 호출: Task별 상세 기여도 근거 코멘트 생성\n",
    "                        reason_llm_results = call_llm_for_individual_contribution_reason_comment(\n",
    "                            task_data_for_comment, # Task 상세 정보\n",
    "                            float(new_contribution_score), # 조정된 점수 (LLM에 전달 시 float으로 변환)\n",
    "                            kpi_data.get('kpi_name', ''), # KPI 목표\n",
    "                            llm_kpi_analysis_results.get('kpi_analysis_comment', '') # KPI 전체 분석 코멘트\n",
    "                        )\n",
    "                        adjusted_comment = reason_llm_results.get(\"comment\", f\"AI 근거 생성 실패: {emp_no_task}의 Task {task_id_current}에 대한 근거를 생성할 수 없습니다.\")\n",
    "                        \n",
    "                        update_data_task = {\n",
    "                            \"ai_contribution_score\": new_contribution_score,\n",
    "                            \"ai_analysis_comment_task\": adjusted_comment\n",
    "                        }\n",
    "                        \n",
    "                        if not update_task_ai_results_in_db(task_id_current, update_data_task):\n",
    "                            print(f\"Warning: Failed to update ai_contribution_score for task_id {task_id_current} (emp_no: {emp_no_task}) with new relative contribution.\")\n",
    "                    else:\n",
    "                        print(f\"Warning: Emp_no {emp_no_task} from task_id {task_id_current} not found in LLM's relative contributions for KPI {team_kpi_id}. ai_contribution_score not updated for this task.\")\n",
    "\n",
    "        else: \n",
    "            print(f\"Failed to update AI results for team_kpi_id: {team_kpi_id}\") \n",
    "\n",
    "    messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 팀 목표 분석 및 DB 업데이트 완료 ({len(updated_team_kpi_ids_list)}건)\")] \n",
    "    \n",
    "    return {\"messages\": messages, \"updated_team_kpi_ids\": updated_team_kpi_ids_list,\n",
    "            \"kpi_individual_relative_contributions\": kpi_individual_relative_contributions_for_state}\n",
    "\n",
    "\n",
    "\n",
    "# 4. 모듈 2 관련 레포트 테이블 데이터 생성/업데이트 서브모듈\n",
    "def generate_module2_report_data_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "    report_type = state[\"report_type\"] \n",
    "    team_id = state[\"team_id\"] \n",
    "    period_id = state[\"period_id\"] \n",
    "    \n",
    "    kpi_individual_relative_contributions = state.get(\"kpi_individual_relative_contributions\", []) \n",
    "    \n",
    "    updated_ids_for_state = {} \n",
    "\n",
    "    # 개인의 팀 전체 기여도 계산 (KPI별 상대 기여도 기반)\n",
    "    emp_overall_relative_contributions = {} \n",
    "    \n",
    "    for kpi_result in kpi_individual_relative_contributions: \n",
    "        for emp_no, relative_score in kpi_result[\"relative_contributions\"].items(): \n",
    "            if emp_no not in emp_overall_relative_contributions: \n",
    "                emp_overall_relative_contributions[emp_no] = 0 \n",
    "            emp_overall_relative_contributions[emp_no] += relative_score \n",
    "\n",
    "    # --- 팀 전체 기여도 합계 100%로 정규화 ---\n",
    "    total_sum_of_relative_contributions = sum(emp_overall_relative_contributions.values())\n",
    "    if total_sum_of_relative_contributions > 0:\n",
    "        adjustment_factor = 100.0 / total_sum_of_relative_contributions\n",
    "        for emp_no, score in emp_overall_relative_contributions.items():\n",
    "            emp_overall_relative_contributions[emp_no] = round(score * adjustment_factor, 2)\n",
    "    # ----------------------------------------\n",
    "\n",
    "    # 모든 개인 Task 결과는 여전히 필요 \n",
    "    all_individual_task_results_raw = [] \n",
    "    for task_summary_id in state[\"target_task_summary_ids\"]: \n",
    "        task_data = fetch_task_summary_by_id(task_summary_id) \n",
    "        if task_data: \n",
    "            all_individual_task_results_raw.append(task_data) \n",
    "\n",
    "\n",
    "    # 개인용 분기별 피드백 레포트 (feedback_reports)\n",
    "    if report_type == \"quarterly\": \n",
    "        # 1. 해당 팀의 모든 emp_no 조회 (피드백 레포트는 팀원용)\n",
    "        all_team_members_in_db = fetch_employees_by_team_id(team_id)\n",
    "\n",
    "        for member_info in all_team_members_in_db:\n",
    "            emp_no_current_member = member_info[\"emp_no\"]\n",
    "            emp_name_current_member = member_info[\"emp_name\"] # 직원 이름 추가\n",
    "\n",
    "            # 팀장(MANAGER) 역할은 피드백 레포트를 직접 생성하지 않으므로 건너뜁니다.\n",
    "            if member_info.get(\"role\") == \"MANAGER\": \n",
    "                print(f\"Info: Skipping feedback_reports for manager {emp_no_current_member}.\")\n",
    "                continue\n",
    "\n",
    "            # 해당 팀원에게 해당하는 Task Summaries 필터링\n",
    "            individual_tasks_for_report = [\n",
    "                task for task in all_individual_task_results_raw \n",
    "                if task.get(\"emp_no\") == emp_no_current_member and task.get(\"period_id\") <= period_id \n",
    "            ]\n",
    "\n",
    "            if not individual_tasks_for_report: \n",
    "                print(f\"Warning: No individual tasks found for emp_no {emp_no_current_member} in period {period_id}. Skipping feedback_reports save for this member.\") \n",
    "                continue \n",
    "\n",
    "            # LLM 호출 시 emp_name, emp_no 전달\n",
    "            individual_overall_results = call_llm_for_overall_contribution_summary(\n",
    "                individual_tasks_for_report, emp_name_current_member, emp_no_current_member\n",
    "            ) \n",
    "            calculated_individual_quarterly_contribution = emp_overall_relative_contributions.get(emp_no_current_member, 0) \n",
    "\n",
    "            team_evaluation_id_for_report = state.get(\"team_evaluation_id\") \n",
    "            if team_evaluation_id_for_report is None: \n",
    "                print(f\"Warning: team_evaluation_id for team_id={team_id}, period_id={period_id} is missing in state. Cannot save feedback_reports for {emp_no_current_member}. (앞단 Agent에서 생성 필요)\") \n",
    "            else: \n",
    "                actual_team_eval_id_in_db = fetch_team_evaluation_id_by_team_and_period(team_id, period_id) \n",
    "                if actual_team_eval_id_in_db != team_evaluation_id_for_report: \n",
    "                     print(f\"Warning: team_evaluation_id {team_evaluation_id_for_report} from state does not match existing ID in DB for team={team_id}, period={period_id}. Skipping feedback_reports save for {emp_no_current_member}.\") \n",
    "                else: \n",
    "                    # --- INSERT 또는 UPDATE 로직 (ON DUPLICATE KEY UPDATE 사용) ---\n",
    "                    feedback_report_id = save_feedback_report_module2_results_to_db(\n",
    "                        emp_no_current_member, team_evaluation_id_for_report, \n",
    "                        {\n",
    "                            \"ai_individual_total_contribution_quarterly\": calculated_individual_quarterly_contribution, \n",
    "                            \"ai_overall_contribution_summary_comment\": individual_overall_results.get(\"comment\") \n",
    "                        }\n",
    "                    )\n",
    "                    updated_ids_for_state[\"feedback_report_id\"] = feedback_report_id \n",
    "                    messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 개인 {emp_no_current_member} 분기별 레포트 내용 생성/업데이트 및 feedback_reports 저장 완료 (ID: {feedback_report_id})\")] \n",
    "\n",
    "    # 팀장용 분기별/연말 팀 전체 평가 레포트 (team_evaluations)\n",
    "    team_evaluation_id = state.get(\"team_evaluation_id\") \n",
    "    if team_evaluation_id is None: \n",
    "        print(f\"Warning: team_evaluation_id for team_id={team_id}, period_id={period_id} is missing in state. Cannot update team_evaluations. (앞단 Agent에서 생성 필요)\") \n",
    "    else: \n",
    "        actual_team_eval_id_in_db = fetch_team_evaluation_id_by_team_and_period(team_id, period_id) \n",
    "        if actual_team_eval_id_in_db != team_evaluation_id: \n",
    "             print(f\"Warning: team_evaluation_id {team_evaluation_id} from state does not match existing ID in DB for team={team_id}, period={period_id}. Skipping team_evaluations update.\") \n",
    "        else: \n",
    "            all_team_kpis_results = [fetch_kpi_data_by_id(kpi_id) for kpi_id in state[\"target_team_kpi_ids\"] if fetch_kpi_data_by_id(kpi_id)] \n",
    "            team_overall_results = call_llm_for_team_overall_analysis(all_team_kpis_results) \n",
    "            \n",
    "            update_data = {\n",
    "                \"ai_team_overall_achievement_rate\": team_overall_results.get(\"overall_rate\"), \n",
    "                \"ai_team_overall_analysis_comment\": team_overall_results.get(\"comment\") \n",
    "            }\n",
    "            update_team_evaluations_module2_results_in_db(team_evaluation_id, update_data) \n",
    "            updated_ids_for_state[\"team_evaluation_id\"] = team_evaluation_id \n",
    "            messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 팀 전체 분석 코멘트 생성 및 team_evaluations 업데이트 완료 (ID: {team_evaluation_id})\")] \n",
    "\n",
    "\n",
    "    # 개인용 연말 최종 평가 레포트 (final_evaluation_reports)\n",
    "    if report_type == \"annual\": \n",
    "        all_team_members_in_db = fetch_employees_by_team_id(team_id)\n",
    "\n",
    "        for member_info in all_team_members_in_db:\n",
    "            emp_no_current_member = member_info[\"emp_no\"]\n",
    "            emp_name_current_member = member_info[\"emp_name\"] # 직원 이름 추가\n",
    "\n",
    "            # 팀장(MANAGER) 역할은 최종 평가 레포트의 직접 대상이 아니므로 건너뜁니다.\n",
    "            if member_info.get(\"role\") == \"MANAGER\": \n",
    "                print(f\"Info: Skipping final_evaluation_reports for manager {emp_no_current_member}.\")\n",
    "                continue\n",
    "\n",
    "            # 해당 팀원에게 해당하는 Task Summaries 필터링\n",
    "            individual_tasks_for_annual_report = [\n",
    "                task for task in all_individual_task_results_raw \n",
    "                if task.get(\"emp_no\") == emp_no_current_member and task.get(\"period_id\") <= period_id\n",
    "            ]\n",
    "            if not individual_tasks_for_annual_report: \n",
    "                print(f\"Warning: No individual tasks found for emp_no {emp_no_current_member} in period {period_id}. Skipping final_evaluation_reports save for this member.\") \n",
    "                continue \n",
    "\n",
    "            # LLM 호출 시 emp_name, emp_no 전달\n",
    "            annual_individual_summary_results = call_llm_for_overall_contribution_summary(\n",
    "                individual_tasks_for_annual_report, emp_name_current_member, emp_no_current_member\n",
    "            ) \n",
    "            \n",
    "            calculated_annual_individual_total_contribution = emp_overall_relative_contributions.get(emp_no_current_member, 0) \n",
    "            \n",
    "            final_team_evaluation_id_example = state.get(\"team_evaluation_id\") \n",
    "            if final_team_evaluation_id_example is None: \n",
    "                print(f\"Warning: team_evaluation_id for team_id={team_id}, period_id={period_id} is missing in state. Cannot save final_evaluation_reports for {emp_no_current_member}. (앞단 Agent에서 생성 필요)\") \n",
    "            else: \n",
    "                actual_team_eval_id_in_db = fetch_team_evaluation_id_by_team_and_period(team_id, period_id) \n",
    "                if actual_team_eval_id_in_db != final_team_evaluation_id_example: \n",
    "                     print(f\"Warning: team_evaluation_id {final_team_evaluation_id_example} from state does not match existing ID in DB for team={team_id}, period={period_id}. Skipping final_evaluation_reports save for {emp_no_current_member}.\") \n",
    "                else: \n",
    "                    final_report_id = save_final_evaluation_report_module2_results_to_db(\n",
    "                        emp_no_current_member, final_team_evaluation_id_example, \n",
    "                        {\n",
    "                            \"ai_annual_individual_total_contribution\": calculated_annual_individual_total_contribution, \n",
    "                            \"ai_annual_achievement_rate\": annual_individual_summary_results.get(\"average_rate\"), \n",
    "                            \"ai_annual_performance_summary_comment\": annual_individual_summary_results.get(\"comment\") \n",
    "                        }\n",
    "                    )\n",
    "                    updated_ids_for_state[\"final_report_id\"] = final_report_id \n",
    "                    messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 개인 {emp_no_current_member} 연말 최종 평가 레포트 내용 생성 및 final_evaluation_reports 저장 완료 (ID: {final_report_id})\")] \n",
    "    \n",
    "    # 최종 전 중간 평가 자료 (temp_evaluations)\n",
    "    if report_type == \"annual\": \n",
    "        all_team_members = fetch_employees_by_team_id(team_id) \n",
    "\n",
    "        for member in all_team_members:\n",
    "            emp_no_current_member = member[\"emp_no\"]\n",
    "            emp_name_current_member = member[\"emp_name\"] # 직원 이름 추가\n",
    "\n",
    "            # 팀장(MANAGER) 역할도 temp_evaluations에는 포함될 수 있으므로 (참고 자료)\n",
    "            # 여기서는 MANAGER 역할도 포함하여 처리합니다.\n",
    "            \n",
    "            # 해당 팀원에게 해당하는 Task Summaries 필터링\n",
    "            individual_tasks_for_temp_eval = [\n",
    "                task for task in all_individual_task_results_raw\n",
    "                if task.get(\"emp_no\") == emp_no_current_member and task.get(\"period_id\") <= period_id\n",
    "            ]\n",
    "            \n",
    "            if not individual_tasks_for_temp_eval:\n",
    "                print(f\"Warning: No individual tasks found for emp_no {emp_no_current_member} in period {period_id}. Skipping temp_evaluations update for this member.\") \n",
    "                continue \n",
    "\n",
    "            # LLM 호출 시 emp_name, emp_no 전달\n",
    "            key_performance_summary_results = call_llm_for_overall_contribution_summary(\n",
    "                individual_tasks_for_temp_eval, emp_name_current_member, emp_no_current_member\n",
    "            )\n",
    "            \n",
    "            temp_eval_id_for_member = fetch_temp_evaluation_id_by_emp_and_period(emp_no_current_member, period_id) \n",
    "\n",
    "            if temp_eval_id_for_member is None: \n",
    "                print(f\"Warning: temp_evaluation_id for emp_no={emp_no_current_member}, period_id={period_id} is missing in DB. Cannot update temp_evaluations. (앞단 Agent에서 생성 필요)\") \n",
    "            else: \n",
    "                update_temp_evaluations_module2_results_in_db(\n",
    "                    temp_eval_id_for_member,\n",
    "                    {\n",
    "                        \"ai_annual_key_performance_contribution_summary\": key_performance_summary_results.get(\"comment\")\n",
    "                    }\n",
    "                )\n",
    "                if \"updated_temp_evaluation_ids_list\" not in updated_ids_for_state: \n",
    "                     updated_ids_for_state[\"updated_temp_evaluation_ids_list\"] = [] \n",
    "                updated_ids_for_state[\"updated_temp_evaluation_ids_list\"].append(temp_eval_id_for_member) \n",
    "                \n",
    "                messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 팀원 {emp_no_current_member} 연간 핵심 성과 기여도 요약 생성 및 temp_evaluations 업데이트 완료 (ID: {temp_eval_id_for_member})\")] \n",
    "\n",
    "    return {\"messages\": messages, **updated_ids_for_state}\n",
    "\n",
    "\n",
    "# 5. 포맷터 서브모듈\n",
    "def formatter_submodule(state: Module2AgentState) -> Module2AgentState:\n",
    "    messages = state.get(\"messages\", []) + [HumanMessage(content=\"모듈 2: 포맷팅 완료\")]\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e62f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai-performance-management-system/agents/evaluation/modules/module_02_goal_achievement/processor.py\n",
    "\n",
    "# ... (Module2AgentState 정의, 모든 서브모듈 함수 정의는 이 위에 위치한다고 가정) ...\n",
    "\n",
    "\n",
    "# --- LangGraph Workflow 구성 및 컴파일 ---\n",
    "# 모듈 2의 워크플로우 정의\n",
    "module2_workflow = StateGraph(Module2AgentState)\n",
    "\n",
    "# 노드 추가 (각 서브모듈 함수를 노드로 등록)\n",
    "module2_workflow.add_node(\"data_collection\", data_collection_submodule)\n",
    "module2_workflow.add_node(\"calculate_individual_contribution\", calculate_individual_contribution_submodule)\n",
    "module2_workflow.add_node(\"analyze_team_goals\", analyze_team_goals_submodule)\n",
    "module2_workflow.add_node(\"generate_module2_report_data\", generate_module2_report_data_submodule)\n",
    "module2_workflow.add_node(\"formatter\", formatter_submodule)\n",
    "\n",
    "\n",
    "# 엣지 (실행 순서) 정의\n",
    "# 시작 노드에서 'data_collection' 노드로 연결\n",
    "module2_workflow.add_edge(START, \"data_collection\")\n",
    "# 'data_collection' -> 'calculate_individual_contribution' 순서로 연결\n",
    "module2_workflow.add_edge(\"data_collection\", \"calculate_individual_contribution\")\n",
    "# 'calculate_individual_contribution' -> 'analyze_team_goals' 순서로 연결\n",
    "module2_workflow.add_edge(\"calculate_individual_contribution\", \"analyze_team_goals\")\n",
    "# 'analyze_team_goals' -> 'generate_module2_report_data' 순서로 연결\n",
    "module2_workflow.add_edge(\"analyze_team_goals\", \"generate_module2_report_data\")\n",
    "# 'generate_module2_report_data' -> 'formatter' 순서로 연결\n",
    "module2_workflow.add_edge(\"generate_module2_report_data\", \"formatter\")\n",
    "# 'formatter'에서 최종 종료 지점(END)으로 연결\n",
    "module2_workflow.add_edge(\"formatter\", END)\n",
    "\n",
    "# 모듈 2의 Graph 컴파일\n",
    "module2_graph = module2_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d159e1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모듈 2 실행 시작...\n",
      "LLM Call (Task Contribution): '김개발: 1분기 요구사항 분석 80% 진행. 핵심 기능...'\n",
      "LLM Call (Task Contribution): '이설계: 1분기 아키텍처 초안 수립 완료. 기술 스택 ...'\n",
      "LLM Call (Task Contribution): '박DB: 1분기 DB 스키마 초기 설계 진행. 아이디어...'\n",
      "LLM Call (Task Contribution): '김개발: 1분기 팀 가동률 80% 달성 지원. 보고 체...'\n",
      "LLM Call (Task Contribution): '이설계: 1분기 프로젝트 리스크 관리 프로세스 수립 시...'\n",
      "LLM Call (Task Contribution): '김개발: 1분기 신규 고객 발굴 시작. 시장 조사 진행...'\n",
      "LLM Call (Task Contribution): '이설계: 1분기 고객 VOC 수집 시스템 구축 검토 시...'\n",
      "LLM Call (Task Contribution): '박DB: 1분기 고객 만족도 설문 기획 및 피드백 분석...'\n",
      "LLM Call (Task Contribution): '김개발: 2분기 요구사항 분석 100% 완료. 사용자 ...'\n",
      "LLM Call (Task Contribution): '이설계: 2분기 아키텍처 상세 설계 완료. 성능 최적화...'\n",
      "LLM Call (Task Contribution): '박DB: 2분기 DB 스키마 90% 확정. 테이블 스크...'\n",
      "LLM Call (Task Contribution): '김개발: 2분기 팀 가동률 85% 달성 지원. 업무 프...'\n",
      "LLM Call (Task Contribution): '이설계: 2분기 프로젝트 리스크 분석 완료. 대응 방안...'\n",
      "LLM Call (Task Contribution): '김개발: 2분기 신규 계약 1건 체결. 추가 계약 협의...'\n",
      "LLM Call (Task Contribution): '이설계: 2분기 VOC 수집 및 분류 자동화 진행. 피...'\n",
      "LLM Call (Task Contribution): '박DB: 2분기 고객 만족도 개선 캠페인 데이터 분석 ...'\n",
      "Debug - employees 테이블 샘플: [{'emp_no': 'E001', 'emp_name': '팀장A'}, {'emp_no': 'E002', 'emp_name': '김개발'}, {'emp_no': 'E003', 'emp_name': '이설계'}, {'emp_no': 'E004', 'emp_name': '박DB'}]\n",
      "Debug - 실행할 쿼리: team_kpi_id=1, period_id=2\n",
      "Debug - 조회 결과 개수: 3\n",
      "Debug - 첫 번째 결과: {'task_id': 1, 'task_name': 'AI 시스템 요구사항 분석 및 정의', 'emp_no': 'E002', 'task_summary': '김개발: 2분기 요구사항 분석 100% 완료. 사용자 피드백 반영 완료.', 'task_summary_Id': 2, 'emp_name': '김개발', 'ai_contribution_score': Decimal('95.00'), 'ai_achievement_rate': None, 'ai_assessed_grade': None, 'ai_analysis_comment_task': '김개발의 요구사항 분석은 100% 완료되었으며, 사용자 피드백을 반영하여 품질이 높아졌습니다. 이로 인해 다음 단계의 개발 작업이 원활하게 진행될 수 있는 기반이 마련되었습니다. Task의 난이도는 중간 수준으로 평가되며, 팀 목표 달성에 크게 기여한 것으로 보입니다.'}\n",
      "LLM Call (KPI Relative Contribution): 'AI powered ITS 혁신...' KPI 내 개인별 상대 기여도 분석 요청.\n",
      "LLM Call (Individual Contribution Reason): '김개발 (E002)'의 'AI 시스템 요구사항 분석 및 정의...' Task 근거 요청.\n",
      "LLM Call (Individual Contribution Reason): '이설계 (E003)'의 'AI 시스템 아키텍처 설계...' Task 근거 요청.\n",
      "LLM Call (Individual Contribution Reason): '박DB (E004)'의 'AI 서비스 데이터베이스 설계...' Task 근거 요청.\n",
      "Debug - employees 테이블 샘플: [{'emp_no': 'E001', 'emp_name': '팀장A'}, {'emp_no': 'E002', 'emp_name': '김개발'}, {'emp_no': 'E003', 'emp_name': '이설계'}, {'emp_no': 'E004', 'emp_name': '박DB'}]\n",
      "Debug - 실행할 쿼리: team_kpi_id=2, period_id=2\n",
      "Debug - 조회 결과 개수: 2\n",
      "Debug - 첫 번째 결과: {'task_id': 4, 'task_name': '팀원별 가동률 관리 및 개선 방안 수립', 'emp_no': 'E002', 'task_summary': '김개발: 2분기 팀 가동률 85% 달성 지원. 업무 프로세스 개선.', 'task_summary_Id': 14, 'emp_name': '김개발', 'ai_contribution_score': Decimal('90.00'), 'ai_achievement_rate': None, 'ai_assessed_grade': None, 'ai_analysis_comment_task': '김개발은 2분기 팀 가동률 85% 달성을 지원하며, 업무 프로세스 개선을 통해 팀의 효율성을 높였습니다. 이 Task는 팀 목표 달성에 직접적으로 기여했으며, 프로세스 개선은 향후 업무 진행에 긍정적인 영향을 미칠 것으로 예상됩니다. Task의 난이도와 결과물의 품질이 높아 기여도 점수를 90점으로 평가합니다.'}\n",
      "LLM Call (KPI Relative Contribution): 'Bilable Rate (가동률)...' KPI 내 개인별 상대 기여도 분석 요청.\n",
      "LLM Call (Individual Contribution Reason): '김개발 (E002)'의 '팀원별 가동률 관리 및 개선 방안 수립...' Task 근거 요청.\n",
      "LLM Call (Individual Contribution Reason): '이설계 (E003)'의 '프로젝트 리스크 관리 및 대응...' Task 근거 요청.\n",
      "Debug - employees 테이블 샘플: [{'emp_no': 'E001', 'emp_name': '팀장A'}, {'emp_no': 'E002', 'emp_name': '김개발'}, {'emp_no': 'E003', 'emp_name': '이설계'}, {'emp_no': 'E004', 'emp_name': '박DB'}]\n",
      "Debug - 실행할 쿼리: team_kpi_id=3, period_id=2\n",
      "Debug - 조회 결과 개수: 3\n",
      "Debug - 첫 번째 결과: {'task_id': 6, 'task_name': '신규 고객 발굴 및 계약 추진', 'emp_no': 'E002', 'task_summary': '김개발: 2분기 신규 계약 1건 체결. 추가 계약 협의 중.', 'task_summary_Id': 22, 'emp_name': '김개발', 'ai_contribution_score': Decimal('75.00'), 'ai_achievement_rate': None, 'ai_assessed_grade': None, 'ai_analysis_comment_task': '김개발의 신규 계약 체결은 팀의 목표 달성에 중요한 기여를 하였으며, 추가 계약 협의 중인 점은 긍정적인 신호로 평가됩니다. 그러나 계약 건수가 1건에 그친 점과 추가 계약이 확정되지 않은 점은 다소 아쉬운 부분입니다. 전반적으로 업무의 난이도와 결과물의 품질은 높지만, 완성도 측면에서 추가적인 성과가 필요합니다.'}\n",
      "LLM Call (KPI Relative Contribution): '매출 및 고객 만족도 증대...' KPI 내 개인별 상대 기여도 분석 요청.\n",
      "LLM Call (Individual Contribution Reason): '김개발 (E002)'의 '신규 고객 발굴 및 계약 추진...' Task 근거 요청.\n",
      "LLM Call (Individual Contribution Reason): '이설계 (E003)'의 '고객 VOC 수집 및 개선 방안 수립...' Task 근거 요청.\n",
      "LLM Call (Individual Contribution Reason): '박DB (E004)'의 '고객 만족도 개선 캠페인 기획...' Task 근거 요청.\n",
      "Info: Skipping feedback_reports for manager E001.\n",
      "LLM Call (Overall Contribution Summary): '김개발 (E002)' Task 6개 기반 요약 요청.\n",
      "DB: feedback_reports[1001] for emp_no=E002, team_evaluation_id=101 inserted/updated.\n",
      "LLM Call (Overall Contribution Summary): '이설계 (E003)' Task 6개 기반 요약 요청.\n",
      "DB: feedback_reports[1002] for emp_no=E003, team_evaluation_id=101 inserted/updated.\n",
      "LLM Call (Overall Contribution Summary): '박DB (E004)' Task 4개 기반 요약 요청.\n",
      "DB: feedback_reports[1003] for emp_no=E004, team_evaluation_id=101 inserted/updated.\n",
      "LLM Call (Team Overall Analysis): KPI 3개 기반 분석 요청.\n",
      "모듈 2 실행 완료!\n",
      "최종 메시지: 모듈 2: 포맷팅 완료\n"
     ]
    }
   ],
   "source": [
    "# 간단한 랭그래프 실행\n",
    "print(\"모듈 2 실행 시작...\")\n",
    "\n",
    "# State 정의\n",
    "state = Module2AgentState(\n",
    "    messages=[HumanMessage(content=\"모듈 2 분기별 평가 시작\")],\n",
    "    report_type=\"quarterly\",\n",
    "    team_id=1,\n",
    "    period_id=2,  # 2025년 2분기 (Q2) 평가\n",
    "    \n",
    "    # Time Scope Adapter Agent에서 필터링해준다고 가정 (Q1, Q2 Task Summaries)\n",
    "    target_task_summary_ids=[1, 5, 9, 13, 17, 21, 25, 29, 2, 6, 10, 14, 18, 22, 26, 30],  # Q1(1,5,9,13,17,21,25,29), Q2(2,6,10,14,18,22,26,30)의 task_summary_Id\n",
    "    target_team_kpi_ids=[1, 2, 3],  # DML에 삽입된 team_kpi_id\n",
    "    \n",
    "    # team_evaluation_id는 상위 에이전트가 미리 생성/전달했다고 가정\n",
    "    team_evaluation_id=101,  # DML에 삽입된 Q2의 team_evaluation_id\n",
    "    \n",
    "    updated_task_ids=None,\n",
    "    updated_team_kpi_ids=None,\n",
    "    kpi_individual_relative_contributions=None\n",
    ")\n",
    "\n",
    "# 랭그래프 실행\n",
    "result = module2_graph.invoke(state)\n",
    "\n",
    "print(\"모듈 2 실행 완료!\")\n",
    "print(f\"최종 메시지: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a30e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc233b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- 서브모듈 함수 정의 ---\n",
    "\n",
    "# 1. 데이터 수집 서브모듈\n",
    "messages = state.get(\"messages\", []) + [HumanMessage(content=\"모듈 2: 데이터 수집 ID 초기화 완료\")] \n",
    "\n",
    "\n",
    "report_type = state[\"report_type\"] \n",
    "target_task_summary_ids = state[\"target_task_summary_ids\"] \n",
    "\n",
    "updated_task_ids_list = [] \n",
    "\n",
    "for task_summary_id in target_task_summary_ids: \n",
    "    task_data = fetch_task_summary_by_id(task_summary_id) \n",
    "    if not task_data: \n",
    "        print(f\"Warning: Task data not found for task_summary_id {task_summary_id}.\") \n",
    "        continue \n",
    "    \n",
    "    task_id = task_data[\"task_id\"] \n",
    "    \n",
    "    llm_results = {} \n",
    "    update_data = {} \n",
    "\n",
    "    # --- 분기별 로직: 기여도만 계산 ---\n",
    "    if report_type == \"quarterly\": \n",
    "        task_summary_text = task_data.get(\"task_summary\", \"\") \n",
    "        if task_summary_text: \n",
    "            llm_results = call_llm_for_task_contribution(task_summary_text) \n",
    "            update_data = {\n",
    "                \"ai_contribution_score\": llm_results.get(\"score\"), \n",
    "                \"ai_analysis_comment_task\": llm_results.get(\"comment\") \n",
    "            }\n",
    "        else: \n",
    "            print(f\"Warning: No task_summary found for task_id {task_id} in {report_type} report.\") \n",
    "            continue \n",
    "    # --- 연말 로직: 달성률/등급 및 기여도 계산 ---\n",
    "    elif report_type == \"annual\": \n",
    "        target_level = task_data.get(\"target_level\", \"\") \n",
    "        task_performance = task_data.get(\"task_performance\", \"\") \n",
    "        task_summary_text_q4 = task_data.get(\"task_summary\", \"\") \n",
    "\n",
    "        grade_definitions = fetch_grade_definitions_from_db() \n",
    "        \n",
    "        if target_level and task_performance: \n",
    "            llm_achievement_results = call_llm_for_task_achievement(target_level, task_performance, grade_definitions) \n",
    "            \n",
    "            llm_contribution_results = call_llm_for_task_contribution(task_summary_text_q4) \n",
    "            \n",
    "            update_data = {\n",
    "                \"ai_contribution_score\": llm_contribution_results.get(\"score\"), \n",
    "                \"ai_achievement_rate\": llm_achievement_results.get(\"rate\"), \n",
    "                \"ai_assessed_grade\": llm_achievement_results.get(\"grade\"), \n",
    "                \"ai_analysis_comment_task\": llm_achievement_results.get(\"analysis\") \n",
    "            }\n",
    "        else: \n",
    "            print(f\"Warning: target_level or task_performance missing for task_id {task_id} in {report_type} report.\") \n",
    "            continue \n",
    "\n",
    "    if update_task_ai_results_in_db(task_id, update_data): \n",
    "        updated_task_ids_list.append(task_id) \n",
    "    else: \n",
    "        print(f\"Failed to update AI results for task_id: {task_id}\") \n",
    "\n",
    "messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 개인 Task 기여도/달성률 계산 및 DB 업데이트 완료 ({len(updated_task_ids_list)}건)\")] \n",
    "\n",
    "\n",
    "\n",
    "# 3. 팀 목표 분석 서브모듈 (수정: KPI 내 개인 상대 기여도 계산 및 LLM 요청 후 tasks 업데이트)\n",
    "report_type = state[\"report_type\"] \n",
    "target_team_kpi_ids = state[\"target_team_kpi_ids\"] \n",
    "period_id = state[\"period_id\"] \n",
    "\n",
    "updated_team_kpi_ids_list = [] \n",
    "kpi_individual_relative_contributions_for_state = [] \n",
    "\n",
    "for team_kpi_id in target_team_kpi_ids: \n",
    "    kpi_data = fetch_kpi_data_by_id(team_kpi_id) \n",
    "    if not kpi_data: \n",
    "        print(f\"Warning: Team KPI data not found for team_kpi_id {team_kpi_id}.\") \n",
    "        continue \n",
    "\n",
    "    tasks_in_this_kpi = fetch_tasks_for_kpi(team_kpi_id, period_id) \n",
    "    \n",
    "    llm_input_for_kpi_analysis = {\n",
    "        \"kpi_goal\": kpi_data.get(\"kpi_name\"), \n",
    "        \"kpi_description\": kpi_data.get(\"kpi_description\"), \n",
    "        \"team_members_tasks\": [\n",
    "            {\n",
    "                \"emp_no\": task.get(\"emp_no\"), \n",
    "                \"task_id\": task.get(\"task_id\"), \n",
    "                \"task_name\": task.get(\"task_name\"), \n",
    "                \"task_summary\": task.get(\"task_summary\"), \n",
    "                \"ai_contribution_score_from_individual_analysis\": task.get(\"ai_contribution_score\") \n",
    "            } for task in tasks_in_this_kpi\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    llm_kpi_analysis_results = call_llm_for_kpi_relative_contribution(llm_input_for_kpi_analysis) \n",
    "\n",
    "    update_data_kpi = { \n",
    "        \"ai_kpi_overall_progress_rate\": llm_kpi_analysis_results.get(\"kpi_overall_rate\"), \n",
    "        \"ai_kpi_analysis_comment\": llm_kpi_analysis_results.get(\"kpi_analysis_comment\") \n",
    "    }\n",
    "\n",
    "    if update_team_kpi_ai_results_in_db(team_kpi_id, update_data_kpi): \n",
    "        updated_team_kpi_ids_list.append(team_kpi_id) \n",
    "        \n",
    "        if \"individual_relative_contributions_in_kpi\" in llm_kpi_analysis_results: \n",
    "            relative_contributions_by_emp = llm_kpi_analysis_results[\"individual_relative_contributions_in_kpi\"]\n",
    "            kpi_individual_relative_contributions_for_state.append({ \n",
    "                \"team_kpi_id\": team_kpi_id,\n",
    "                \"relative_contributions\": relative_contributions_by_emp\n",
    "            }) \n",
    "\n",
    "            # --- 수정된 부분: tasks 테이블 ai_contribution_score 및 ai_analysis_comment_task 업데이트 ---\n",
    "            for task in tasks_in_this_kpi: # 현재 KPI에 속한 Task들을 다시 순회\n",
    "                emp_no_task = task.get(\"emp_no\")\n",
    "                task_id_current = task.get(\"task_id\")\n",
    "                \n",
    "                if emp_no_task in relative_contributions_by_emp:\n",
    "                    new_contribution_score = relative_contributions_by_emp[emp_no_task]\n",
    "                    \n",
    "                    # LLM 호출을 위한 Task 상세 정보 준비\n",
    "                    # task_data에는 emp_name도 포함될 수 있도록 fetch_task_summary_by_id 쿼리 확인\n",
    "                    # (py의 fetch_employees_by_team_id도 emp_name을 가져옴)\n",
    "                    task_data_for_comment = fetch_task_summary_by_id(task.get(\"task_summary_Id\")) # task_summary_Id 필요\n",
    "                    if not task_data_for_comment:\n",
    "                        print(f\"Warning: Task data for comment generation not found for task_summary_Id {task.get('task_summary_Id')}.\")\n",
    "                        continue\n",
    "\n",
    "                    # 새로운 LLM 호출: Task별 상세 기여도 근거 코멘트 생성\n",
    "                    reason_llm_results = call_llm_for_individual_contribution_reason_comment(\n",
    "                        task_data_for_comment, # Task 상세 정보\n",
    "                        float(new_contribution_score), # 조정된 점수 (LLM에 전달 시 float으로 변환)\n",
    "                        kpi_data.get('kpi_name', ''), # KPI 목표\n",
    "                        llm_kpi_analysis_results.get('kpi_analysis_comment', '') # KPI 전체 분석 코멘트\n",
    "                    )\n",
    "                    adjusted_comment = reason_llm_results.get(\"comment\", f\"AI 근거 생성 실패: {emp_no_task}의 Task {task_id_current}에 대한 근거를 생성할 수 없습니다.\")\n",
    "                    \n",
    "                    update_data_task = {\n",
    "                        \"ai_contribution_score\": new_contribution_score,\n",
    "                        \"ai_analysis_comment_task\": adjusted_comment\n",
    "                    }\n",
    "                    \n",
    "                    if not update_task_ai_results_in_db(task_id_current, update_data_task):\n",
    "                        print(f\"Warning: Failed to update ai_contribution_score for task_id {task_id_current} (emp_no: {emp_no_task}) with new relative contribution.\")\n",
    "                else:\n",
    "                    print(f\"Warning: Emp_no {emp_no_task} from task_id {task_id_current} not found in LLM's relative contributions for KPI {team_kpi_id}. ai_contribution_score not updated for this task.\")\n",
    "\n",
    "    else: \n",
    "        print(f\"Failed to update AI results for team_kpi_id: {team_kpi_id}\") \n",
    "\n",
    "messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 팀 목표 분석 및 DB 업데이트 완료 ({len(updated_team_kpi_ids_list)}건)\")] \n",
    "\n",
    "state[\"kpi_individual_relative_contributions\"] = kpi_individual_relative_contributions_for_state\n",
    "\n",
    "# 4. 모듈 2 관련 레포트 테이블 데이터 생성/업데이트 서브모듈\n",
    "report_type = state[\"report_type\"] \n",
    "team_id = state[\"team_id\"] \n",
    "period_id = state[\"period_id\"] \n",
    "\n",
    "kpi_individual_relative_contributions = state.get(\"kpi_individual_relative_contributions\", []) \n",
    "\n",
    "updated_ids_for_state = {} \n",
    "\n",
    "# 개인의 팀 전체 기여도 계산 (KPI별 상대 기여도 기반)\n",
    "emp_overall_relative_contributions = {} \n",
    "\n",
    "for kpi_result in kpi_individual_relative_contributions: \n",
    "    for emp_no, relative_score in kpi_result[\"relative_contributions\"].items(): \n",
    "        if emp_no not in emp_overall_relative_contributions: \n",
    "            emp_overall_relative_contributions[emp_no] = 0 \n",
    "        emp_overall_relative_contributions[emp_no] += relative_score \n",
    "\n",
    "# --- 팀 전체 기여도 합계 100%로 정규화 ---\n",
    "total_sum_of_relative_contributions = sum(emp_overall_relative_contributions.values())\n",
    "if total_sum_of_relative_contributions > 0:\n",
    "    adjustment_factor = 100.0 / total_sum_of_relative_contributions\n",
    "    for emp_no, score in emp_overall_relative_contributions.items():\n",
    "        emp_overall_relative_contributions[emp_no] = round(score * adjustment_factor, 2)\n",
    "# ----------------------------------------\n",
    "\n",
    "# 모든 개인 Task 결과는 여전히 필요 \n",
    "all_individual_task_results_raw = [] \n",
    "for task_summary_id in state[\"target_task_summary_ids\"]: \n",
    "    task_data = fetch_task_summary_by_id(task_summary_id) \n",
    "    if task_data: \n",
    "        all_individual_task_results_raw.append(task_data) \n",
    "\n",
    "\n",
    "# 개인용 분기별 피드백 레포트 (feedback_reports)\n",
    "if report_type == \"quarterly\": \n",
    "    # 1. 해당 팀의 모든 emp_no 조회 (피드백 레포트는 팀원용)\n",
    "    all_team_members_in_db = fetch_employees_by_team_id(team_id)\n",
    "\n",
    "    for member_info in all_team_members_in_db:\n",
    "        emp_no_current_member = member_info[\"emp_no\"]\n",
    "        emp_name_current_member = member_info[\"emp_name\"] # 직원 이름 추가\n",
    "\n",
    "        # 팀장(MANAGER) 역할은 피드백 레포트를 직접 생성하지 않으므로 건너뜁니다.\n",
    "        if member_info.get(\"role\") == \"MANAGER\": \n",
    "            print(f\"Info: Skipping feedback_reports for manager {emp_no_current_member}.\")\n",
    "            continue\n",
    "\n",
    "        # 해당 팀원에게 해당하는 Task Summaries 필터링\n",
    "        individual_tasks_for_report = [\n",
    "            task for task in all_individual_task_results_raw \n",
    "            if task.get(\"emp_no\") == emp_no_current_member and task.get(\"period_id\") <= period_id \n",
    "        ]\n",
    "\n",
    "        if not individual_tasks_for_report: \n",
    "            print(f\"Warning: No individual tasks found for emp_no {emp_no_current_member} in period {period_id}. Skipping feedback_reports save for this member.\") \n",
    "            continue \n",
    "\n",
    "        # LLM 호출 시 emp_name, emp_no 전달\n",
    "        individual_overall_results = call_llm_for_overall_contribution_summary(\n",
    "            individual_tasks_for_report, emp_name_current_member, emp_no_current_member\n",
    "        ) \n",
    "        calculated_individual_quarterly_contribution = emp_overall_relative_contributions.get(emp_no_current_member, 0) \n",
    "\n",
    "        team_evaluation_id_for_report = state.get(\"team_evaluation_id\") \n",
    "        if team_evaluation_id_for_report is None: \n",
    "            print(f\"Warning: team_evaluation_id for team_id={team_id}, period_id={period_id} is missing in state. Cannot save feedback_reports for {emp_no_current_member}. (앞단 Agent에서 생성 필요)\") \n",
    "        else: \n",
    "            actual_team_eval_id_in_db = fetch_team_evaluation_id_by_team_and_period(team_id, period_id) \n",
    "            if actual_team_eval_id_in_db != team_evaluation_id_for_report: \n",
    "                    print(f\"Warning: team_evaluation_id {team_evaluation_id_for_report} from state does not match existing ID in DB for team={team_id}, period={period_id}. Skipping feedback_reports save for {emp_no_current_member}.\") \n",
    "            else: \n",
    "                # --- INSERT 또는 UPDATE 로직 (ON DUPLICATE KEY UPDATE 사용) ---\n",
    "                feedback_report_id = save_feedback_report_module2_results_to_db(\n",
    "                    emp_no_current_member, team_evaluation_id_for_report, \n",
    "                    {\n",
    "                        \"ai_individual_total_contribution_quarterly\": calculated_individual_quarterly_contribution, \n",
    "                        \"ai_overall_contribution_summary_comment\": individual_overall_results.get(\"comment\") \n",
    "                    }\n",
    "                )\n",
    "                updated_ids_for_state[\"feedback_report_id\"] = feedback_report_id \n",
    "                messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 개인 {emp_no_current_member} 분기별 레포트 내용 생성/업데이트 및 feedback_reports 저장 완료 (ID: {feedback_report_id})\")] \n",
    "\n",
    "# 팀장용 분기별/연말 팀 전체 평가 레포트 (team_evaluations)\n",
    "team_evaluation_id = state.get(\"team_evaluation_id\") \n",
    "if team_evaluation_id is None: \n",
    "    print(f\"Warning: team_evaluation_id for team_id={team_id}, period_id={period_id} is missing in state. Cannot update team_evaluations. (앞단 Agent에서 생성 필요)\") \n",
    "else: \n",
    "    actual_team_eval_id_in_db = fetch_team_evaluation_id_by_team_and_period(team_id, period_id) \n",
    "    if actual_team_eval_id_in_db != team_evaluation_id: \n",
    "            print(f\"Warning: team_evaluation_id {team_evaluation_id} from state does not match existing ID in DB for team={team_id}, period={period_id}. Skipping team_evaluations update.\") \n",
    "    else: \n",
    "        all_team_kpis_results = [fetch_kpi_data_by_id(kpi_id) for kpi_id in state[\"target_team_kpi_ids\"] if fetch_kpi_data_by_id(kpi_id)] \n",
    "        team_overall_results = call_llm_for_team_overall_analysis(all_team_kpis_results) \n",
    "        \n",
    "        update_data = {\n",
    "            \"ai_team_overall_achievement_rate\": team_overall_results.get(\"overall_rate\"), \n",
    "            \"ai_team_overall_analysis_comment\": team_overall_results.get(\"comment\") \n",
    "        }\n",
    "        update_team_evaluations_module2_results_in_db(team_evaluation_id, update_data) \n",
    "        updated_ids_for_state[\"team_evaluation_id\"] = team_evaluation_id \n",
    "        messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 팀 전체 분석 코멘트 생성 및 team_evaluations 업데이트 완료 (ID: {team_evaluation_id})\")] \n",
    "\n",
    "\n",
    "# 개인용 연말 최종 평가 레포트 (final_evaluation_reports)\n",
    "if report_type == \"annual\": \n",
    "    all_team_members_in_db = fetch_employees_by_team_id(team_id)\n",
    "\n",
    "    for member_info in all_team_members_in_db:\n",
    "        emp_no_current_member = member_info[\"emp_no\"]\n",
    "        emp_name_current_member = member_info[\"emp_name\"] # 직원 이름 추가\n",
    "\n",
    "        # 팀장(MANAGER) 역할은 최종 평가 레포트의 직접 대상이 아니므로 건너뜁니다.\n",
    "        if member_info.get(\"role\") == \"MANAGER\": \n",
    "            print(f\"Info: Skipping final_evaluation_reports for manager {emp_no_current_member}.\")\n",
    "            continue\n",
    "\n",
    "        # 해당 팀원에게 해당하는 Task Summaries 필터링\n",
    "        individual_tasks_for_annual_report = [\n",
    "            task for task in all_individual_task_results_raw \n",
    "            if task.get(\"emp_no\") == emp_no_current_member and task.get(\"period_id\") <= period_id\n",
    "        ]\n",
    "        if not individual_tasks_for_annual_report: \n",
    "            print(f\"Warning: No individual tasks found for emp_no {emp_no_current_member} in period {period_id}. Skipping final_evaluation_reports save for this member.\") \n",
    "            continue \n",
    "\n",
    "        # LLM 호출 시 emp_name, emp_no 전달\n",
    "        annual_individual_summary_results = call_llm_for_overall_contribution_summary(\n",
    "            individual_tasks_for_annual_report, emp_name_current_member, emp_no_current_member\n",
    "        ) \n",
    "        \n",
    "        calculated_annual_individual_total_contribution = emp_overall_relative_contributions.get(emp_no_current_member, 0) \n",
    "        \n",
    "        final_team_evaluation_id_example = state.get(\"team_evaluation_id\") \n",
    "        if final_team_evaluation_id_example is None: \n",
    "            print(f\"Warning: team_evaluation_id for team_id={team_id}, period_id={period_id} is missing in state. Cannot save final_evaluation_reports for {emp_no_current_member}. (앞단 Agent에서 생성 필요)\") \n",
    "        else: \n",
    "            actual_team_eval_id_in_db = fetch_team_evaluation_id_by_team_and_period(team_id, period_id) \n",
    "            if actual_team_eval_id_in_db != final_team_evaluation_id_example: \n",
    "                    print(f\"Warning: team_evaluation_id {final_team_evaluation_id_example} from state does not match existing ID in DB for team={team_id}, period={period_id}. Skipping final_evaluation_reports save for {emp_no_current_member}.\") \n",
    "            else: \n",
    "                final_report_id = save_final_evaluation_report_module2_results_to_db(\n",
    "                    emp_no_current_member, final_team_evaluation_id_example, \n",
    "                    {\n",
    "                        \"ai_annual_individual_total_contribution\": calculated_annual_individual_total_contribution, \n",
    "                        \"ai_annual_achievement_rate\": annual_individual_summary_results.get(\"average_rate\"), \n",
    "                        \"ai_annual_performance_summary_comment\": annual_individual_summary_results.get(\"comment\") \n",
    "                    }\n",
    "                )\n",
    "                updated_ids_for_state[\"final_report_id\"] = final_report_id \n",
    "                messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 개인 {emp_no_current_member} 연말 최종 평가 레포트 내용 생성 및 final_evaluation_reports 저장 완료 (ID: {final_report_id})\")] \n",
    "\n",
    "# 최종 전 중간 평가 자료 (temp_evaluations)\n",
    "if report_type == \"annual\": \n",
    "    all_team_members = fetch_employees_by_team_id(team_id) \n",
    "\n",
    "    for member in all_team_members:\n",
    "        emp_no_current_member = member[\"emp_no\"]\n",
    "        emp_name_current_member = member[\"emp_name\"] # 직원 이름 추가\n",
    "\n",
    "        # 팀장(MANAGER) 역할도 temp_evaluations에는 포함될 수 있으므로 (참고 자료)\n",
    "        # 여기서는 MANAGER 역할도 포함하여 처리합니다.\n",
    "        \n",
    "        # 해당 팀원에게 해당하는 Task Summaries 필터링\n",
    "        individual_tasks_for_temp_eval = [\n",
    "            task for task in all_individual_task_results_raw\n",
    "            if task.get(\"emp_no\") == emp_no_current_member and task.get(\"period_id\") <= period_id\n",
    "        ]\n",
    "        \n",
    "        if not individual_tasks_for_temp_eval:\n",
    "            print(f\"Warning: No individual tasks found for emp_no {emp_no_current_member} in period {period_id}. Skipping temp_evaluations update for this member.\") \n",
    "            continue \n",
    "\n",
    "        # LLM 호출 시 emp_name, emp_no 전달\n",
    "        key_performance_summary_results = call_llm_for_overall_contribution_summary(\n",
    "            individual_tasks_for_temp_eval, emp_name_current_member, emp_no_current_member\n",
    "        )\n",
    "        \n",
    "        temp_eval_id_for_member = fetch_temp_evaluation_id_by_emp_and_period(emp_no_current_member, period_id) \n",
    "\n",
    "        if temp_eval_id_for_member is None: \n",
    "            print(f\"Warning: temp_evaluation_id for emp_no={emp_no_current_member}, period_id={period_id} is missing in DB. Cannot update temp_evaluations. (앞단 Agent에서 생성 필요)\") \n",
    "        else: \n",
    "            update_temp_evaluations_module2_results_in_db(\n",
    "                temp_eval_id_for_member,\n",
    "                {\n",
    "                    \"ai_annual_key_performance_contribution_summary\": key_performance_summary_results.get(\"comment\")\n",
    "                }\n",
    "            )\n",
    "            if \"updated_temp_evaluation_ids_list\" not in updated_ids_for_state: \n",
    "                    updated_ids_for_state[\"updated_temp_evaluation_ids_list\"] = [] \n",
    "            updated_ids_for_state[\"updated_temp_evaluation_ids_list\"].append(temp_eval_id_for_member) \n",
    "            \n",
    "            messages = state.get(\"messages\", []) + [HumanMessage(content=f\"모듈 2: 팀원 {emp_no_current_member} 연간 핵심 성과 기여도 요약 생성 및 temp_evaluations 업데이트 완료 (ID: {temp_eval_id_for_member})\")] \n",
    "\n",
    "# 5. 포맷터 서브모듈\n",
    "messages = state.get(\"messages\", []) + [HumanMessage(content=\"모듈 2: 포맷팅 완료\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-WTM_qa1c-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
