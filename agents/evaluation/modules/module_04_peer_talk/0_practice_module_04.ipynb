{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ê±°ëŠ” ì£¼í”¼í„°ì— ì…ë ¥ \n",
    "from sqlalchemy import create_engine, Column, String, Integer, Enum\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "\n",
    "# --- 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • ---\n",
    "# ì‚¬ìš©ìê°€ ì œê³µí•œ DATABASE_URL\n",
    "DATABASE_URL = \"mysql+pymysql://root:thswldud12@localhost:3306/skoro_db\"\n",
    "\n",
    "# SQLAlchemy ì—”ì§„ ìƒì„±\n",
    "engine = create_engine(DATABASE_URL, echo=True) # echo=TrueëŠ” ì‹¤í–‰ë˜ëŠ” SQLì„ ì½˜ì†”ì— ì¶œë ¥í•˜ì—¬ ë””ë²„ê¹…ì— ìœ ìš©\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from typing import List, Dict, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ê´€ë ¨ ìœ í‹¸ë¦¬í‹° ë° í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "def get_predefined_keywords():\n",
    "    \"\"\"ë¯¸ë¦¬ ì •ì˜ëœ ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\"\"\"\n",
    "    positive_keywords = {\n",
    "        'ë¦¬ë”ì‹­', 'ì±…ì„ê°', 'ì°½ì˜ì ', 'ì ê·¹ì ', 'í˜‘ë ¥ì ', 'ì†Œí†µëŠ¥ë ¥', 'ë¬¸ì œí•´ê²°', \n",
    "        'ì„±ì‹¤í•¨', 'ì „ë¬¸ì„±', 'í˜ì‹ ì ', 'íŒ€ì›Œí¬', 'ê¸ì •ë§ˆì¸ë“œ', 'ë°°ë ¤ì‹¬', 'ì—´ì •ì ',\n",
    "        'ì‹ ë¢°ì„±', 'íš¨ìœ¨ì„±', 'ë¶„ì„ë ¥', 'ì¶”ì§„ë ¥', 'ìœ ì—°ì„±', 'ì„±ì¥ì§€í–¥', 'ë„ì „ì •ì‹ ',\n",
    "        'ì„¸ì‹¬í•¨', 'ë…¼ë¦¬ì ', 'ê°ê´€ì ', 'ì²´ê³„ì ', 'ê¼¼ê¼¼í•¨', 'ì¹œí™”ë ¥', 'ê²¸ì†í•¨',\n",
    "        'ë°°ë ¤', 'ì±…ì„ê° ìˆëŠ”', 'ë°ì€', 'ì„±ì‹¤í•œ', 'ë¬¸ì œí•´ê²°ë ¥', 'ê¸ì •ì ', 'ì—´ì •',\n",
    "        'ì¶”ì§„ë ¥ ìˆëŠ”', 'ì£¼ë„ì ì¸', 'ëª©í‘œì§€í–¥ì ', 'ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”', 'ëŠ¥ë™ì ì¸'\n",
    "    }\n",
    "    \n",
    "    negative_keywords = {\n",
    "        'ì†Œê·¹ì ', 'ë¬´ê´€ì‹¬', 'ë¹„í˜‘ì¡°ì ', 'ê³ ì§‘ìŠ¤ëŸ¬ìš´', 'ê²½ì§ëœ', 'íšŒí”¼í˜•', 'ë¬´ì˜ìš•',\n",
    "        'ì‚°ë§Œí•¨', 'ì§€ê°', 'ë¶ˆì„±ì‹¤', 'ê°ì •ì ', 'ì£¼ê´€ì ', 'ë…ë‹¨ì ', 'íì‡„ì ',\n",
    "        'ìˆ˜ë™ì ', 'ë¯¸ë£¨ê¸°', 'ì±…ì„íšŒí”¼', 'ì†Œí†µë¶€ì¡±', 'ë¶€ì •ì ', 'ì™„ê³ í•¨', 'ì˜ˆë¯¼í•¨',\n",
    "        'ì†Œê·¹ì ì¸', 'ì‹¤ìˆ˜ê°€ ì¦ì€', 'ë¬´ì˜ìš•ì', 'ê°œì¸ì£¼ì˜', 'ì†Œí†µë‹¨ì ˆ', 'ë¶€ì •ì ì¸',\n",
    "        'ìˆ˜ë™ì ì¸', 'ì±…ì„ê° ê²°ì—¬'\n",
    "    }\n",
    "    \n",
    "    return positive_keywords, negative_keywords\n",
    "\n",
    "def get_keyword_score(keyword: str, positive_keywords: set, negative_keywords: set, analyzed_keywords: Dict[str, float]) -> float:\n",
    "    \"\"\"í‚¤ì›Œë“œì˜ ê°ì • ì ìˆ˜ ë°˜í™˜\"\"\"\n",
    "    if keyword in positive_keywords:\n",
    "        return 1.0\n",
    "    elif keyword in negative_keywords:\n",
    "        return -1.0\n",
    "    elif keyword in analyzed_keywords:\n",
    "        return analyzed_keywords[keyword]\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_dict(row) -> Dict:\n",
    "    \"\"\"SQLAlchemy Row ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\"\"\"\n",
    "    return dict(row._mapping) if hasattr(row, '_mapping') else dict(row)\n",
    "\n",
    "def fetch_peer_evaluations_for_target(engine, period_id: int, target_emp_no: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ë¶„ê¸°/í‰ê°€ë°›ëŠ” ì‚¬ë²ˆì˜ ë™ë£Œ í‰ê°€ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ\n",
    "    \"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        query = text(\"\"\"\n",
    "            SELECT \n",
    "                pe.peer_evaluation_id,\n",
    "                te.period_id,\n",
    "                pe.target_emp_no AS target_emp_no,\n",
    "                pe.emp_no AS evaluator_emp_no,\n",
    "                pe.progress AS weight\n",
    "            FROM team_evaluations te\n",
    "            JOIN peer_evaluations pe ON te.team_evaluation_id = pe.team_evaluation_id\n",
    "            WHERE te.period_id = :period_id\n",
    "              AND pe.target_emp_no = :target_emp_no\n",
    "        \"\"\")\n",
    "        results = conn.execute(query, {\"period_id\": period_id, \"target_emp_no\": target_emp_no}).fetchall()\n",
    "        return [row_to_dict(row) for row in results]\n",
    "\n",
    "\n",
    "def fetch_keywords_for_peer_evaluations(engine, peer_evaluation_ids: List[int]) -> Dict[int, List[str]]:\n",
    "    \"\"\"\n",
    "    ë™ë£Œ í‰ê°€ ID ë¦¬ìŠ¤íŠ¸ë³„ í‚¤ì›Œë“œ(ì‹œìŠ¤í…œ/ì»¤ìŠ¤í…€) ëª¨ìŒ ì¡°íšŒ\n",
    "    \"\"\"\n",
    "    if not peer_evaluation_ids:\n",
    "        return {}\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        # IN ì ˆì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì²˜ë¦¬\n",
    "        placeholders = ','.join([f':id_{i}' for i in range(len(peer_evaluation_ids))])\n",
    "        params = {f'id_{i}': peer_id for i, peer_id in enumerate(peer_evaluation_ids)}\n",
    "        \n",
    "        query = text(f\"\"\"\n",
    "            SELECT \n",
    "                pek.peer_evaluation_id,\n",
    "                COALESCE(k.keyword_name, pek.custom_keyword) AS keyword\n",
    "            FROM peer_evaluation_keywords pek\n",
    "            LEFT JOIN keywords k ON pek.keyword_id = k.keyword_id\n",
    "            WHERE pek.peer_evaluation_id IN ({placeholders})\n",
    "        \"\"\")\n",
    "        \n",
    "        results = conn.execute(query, params).fetchall()\n",
    "        keyword_map = defaultdict(list)\n",
    "        for row in results:\n",
    "            row_dict = row_to_dict(row)\n",
    "            keyword_map[row_dict[\"peer_evaluation_id\"]].append(row_dict[\"keyword\"])\n",
    "        return dict(keyword_map)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tasks_for_peer_evaluations_fixed(engine, peer_evaluation_ids: List[int]) -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    ë™ë£Œ í‰ê°€ë³„ task_id ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ (ìˆ˜ì •ëœ ë²„ì „)\n",
    "    peer_evaluationsì˜ emp_no(í‰ê°€ì)ì™€ target_emp_no(í”¼í‰ê°€ì) ëª¨ë‘ ê³ ë ¤\n",
    "    \"\"\"\n",
    "    if not peer_evaluation_ids:\n",
    "        return {}\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        placeholders = ','.join([f':id_{i}' for i in range(len(peer_evaluation_ids))])\n",
    "        params = {f'id_{i}': peer_id for i, peer_id in enumerate(peer_evaluation_ids)}\n",
    "        \n",
    "        # ì‹¤ì œ tasks í…Œì´ë¸” êµ¬ì¡°ì— ë§ëŠ” ì¿¼ë¦¬\n",
    "        # emp_no ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ ì¡°ì¸\n",
    "        query = text(f\"\"\"\n",
    "            SELECT DISTINCT\n",
    "                pe.peer_evaluation_id,\n",
    "                t.task_id\n",
    "            FROM peer_evaluations pe\n",
    "            LEFT JOIN tasks t ON t.emp_no = pe.target_emp_no\n",
    "            WHERE pe.peer_evaluation_id IN ({placeholders})\n",
    "              AND t.task_id IS NOT NULL\n",
    "        \"\"\")\n",
    "        \n",
    "        results = conn.execute(query, params).fetchall()\n",
    "        task_map = defaultdict(list)\n",
    "        for row in results:\n",
    "            row_dict = row_to_dict(row)\n",
    "            task_map[row_dict[\"peer_evaluation_id\"]].append(row_dict[\"task_id\"])\n",
    "        return dict(task_map)\n",
    "\n",
    "def fetch_task_summaries_fixed(engine, period_id: int, task_ids: List[int]) -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    task_summariesì—ì„œ ì—…ë¬´ ìš”ì•½ ì¡°íšŒ (ìˆ˜ì •ëœ ë²„ì „)\n",
    "    task_performance ì»¬ëŸ¼ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    if not task_ids:\n",
    "        return {}\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        placeholders = ','.join([f':task_{i}' for i in range(len(task_ids))])\n",
    "        params = {f'task_{i}': task_id for i, task_id in enumerate(task_ids)}\n",
    "        \n",
    "        # tasks í…Œì´ë¸”ì—ì„œ ì§ì ‘ task_performance ì¡°íšŒ\n",
    "        # (task_summaries í…Œì´ë¸”ì´ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)\n",
    "        query = text(f\"\"\"\n",
    "            SELECT task_id, task_performance as summary\n",
    "            FROM tasks\n",
    "            WHERE task_id IN ({placeholders})\n",
    "        \"\"\")\n",
    "        \n",
    "        results = conn.execute(query, params).fetchall()\n",
    "        return {row_to_dict(row)[\"task_id\"]: row_to_dict(row)[\"summary\"] for row in results}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_employees_in_period(engine, period_id: int) -> List[str]:\n",
    "    \"\"\"íŠ¹ì • ë¶„ê¸°ì— ë™ë£Œí‰ê°€ë¥¼ ë°›ì€ ëª¨ë“  ì§ì› ì¡°íšŒ\"\"\"\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            query = text(\"\"\"\n",
    "                SELECT DISTINCT pe.target_emp_no\n",
    "                FROM team_evaluations te\n",
    "                JOIN peer_evaluations pe ON te.team_evaluation_id = pe.team_evaluation_id\n",
    "                WHERE te.period_id = :period_id\n",
    "                ORDER BY pe.target_emp_no\n",
    "            \"\"\")\n",
    "            \n",
    "            results = conn.execute(query, {\"period_id\": period_id}).fetchall()\n",
    "            employee_list = [row_to_dict(row)[\"target_emp_no\"] for row in results]\n",
    "            \n",
    "            print(f\"ğŸ“Š {period_id}ë¶„ê¸° ë™ë£Œí‰ê°€ ëŒ€ìƒì: {len(employee_list)}ëª…\")\n",
    "            for i, emp_no in enumerate(employee_list, 1):\n",
    "                print(f\"  {i}. {emp_no}\")\n",
    "                \n",
    "            return employee_list\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì§ì› ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ëŠ” ì™„ì „í•œ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ!\n",
      "ì£¼ìš” íŠ¹ì§•:\n",
      "- ê¸°ì¡´ ê²€ì¦ëœ ë¶„ì„ ë¡œì§ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
      "- DB ì €ì¥ ë¶€ë¶„ë§Œ ë¶„ê¸°ë³„ í…Œì´ë¸”ë¡œ ìˆ˜ì •\n",
      "- ë¶„ê¸° 4: final_evaluation_reports.ai_peer_talk_summary\n",
      "- ë¶„ê¸° 1,2,3: feedback_reports.ai_peer_talk_summary\n",
      "- ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ìë™ ìŠ¤í‚µ\n",
      "================================================================================\n",
      "ğŸš€ 3ë¶„ê¸° ì „ì²´ ì§ì› ë™ë£Œí‰ê°€ ë¶„ì„ ì‹œì‘ (ê²€ì¦ëœ í•¨ìˆ˜ë“¤ ì‚¬ìš©)\n",
      "================================================================================\n",
      "ğŸ’¾ ì €ì¥ í…Œì´ë¸”: feedback_reports.ai_peer_talk_summary\n",
      "2025-06-09 19:21:02,814 INFO sqlalchemy.engine.Engine SELECT DATABASE()\n",
      "2025-06-09 19:21:02,815 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-09 19:21:02,816 INFO sqlalchemy.engine.Engine SELECT @@sql_mode\n",
      "2025-06-09 19:21:02,816 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-09 19:21:02,820 INFO sqlalchemy.engine.Engine SELECT @@lower_case_table_names\n",
      "2025-06-09 19:21:02,820 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-06-09 19:21:02,827 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:02,828 INFO sqlalchemy.engine.Engine \n",
      "                SELECT DISTINCT pe.target_emp_no\n",
      "                FROM team_evaluations te\n",
      "                JOIN peer_evaluations pe ON te.team_evaluation_id = pe.team_evaluation_id\n",
      "                WHERE te.period_id = %(period_id)s\n",
      "                ORDER BY pe.target_emp_no\n",
      "            \n",
      "2025-06-09 19:21:02,828 INFO sqlalchemy.engine.Engine [generated in 0.00097s] {'period_id': 3}\n",
      "ğŸ“Š 3ë¶„ê¸° ë™ë£Œí‰ê°€ ëŒ€ìƒì: 3ëª…\n",
      "  1. E002\n",
      "  2. E003\n",
      "  3. E004\n",
      "2025-06-09 19:21:02,832 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "ğŸ¯ 3ëª… 3ë¶„ê¸° ì¼ê´„ ë¶„ì„ ì‹œì‘\n",
      "ğŸ’¾ ì €ì¥ í…Œì´ë¸”: feedback_reports.ai_peer_talk_summary\n",
      "\n",
      "[1/3] ğŸ“Š E002 ë¶„ì„ ì‹œì‘...\n",
      "------------------------------------------------------------\n",
      "2025-06-09 19:21:02,839 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:02,839 INFO sqlalchemy.engine.Engine \n",
      "                    SELECT fr.feedback_report_id\n",
      "                    FROM feedback_reports fr\n",
      "                    JOIN team_evaluations te ON fr.team_evaluation_id = te.team_evaluation_id\n",
      "                    WHERE te.period_id = %(period_id)s\n",
      "                      AND fr.emp_no = %(emp_no)s\n",
      "                      AND fr.ai_peer_talk_summary IS NOT NULL\n",
      "                      AND fr.ai_peer_talk_summary != ''\n",
      "                    LIMIT 1\n",
      "                \n",
      "2025-06-09 19:21:02,839 INFO sqlalchemy.engine.Engine [generated in 0.00062s] {'period_id': 3, 'emp_no': 'E002'}\n",
      "2025-06-09 19:21:02,841 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "ğŸ”„ [ì‘ë™] ë°ì´í„° ë§¤í•‘ ë…¸ë“œ ì‹œì‘...\n",
      "[CompleteDataMappingAgent] E002: ë°ì´í„° ë§¤í•‘ ì‹œì‘ (ë¶„ê¸°: 3)\n",
      "2025-06-09 19:21:02,844 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:02,844 INFO sqlalchemy.engine.Engine \n",
      "            SELECT \n",
      "                pe.peer_evaluation_id,\n",
      "                te.period_id,\n",
      "                pe.target_emp_no AS target_emp_no,\n",
      "                pe.emp_no AS evaluator_emp_no,\n",
      "                pe.progress AS weight\n",
      "            FROM team_evaluations te\n",
      "            JOIN peer_evaluations pe ON te.team_evaluation_id = pe.team_evaluation_id\n",
      "            WHERE te.period_id = %(period_id)s\n",
      "              AND pe.target_emp_no = %(target_emp_no)s\n",
      "        \n",
      "2025-06-09 19:21:02,844 INFO sqlalchemy.engine.Engine [generated in 0.00060s] {'period_id': 3, 'target_emp_no': 'E002'}\n",
      "2025-06-09 19:21:02,845 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "[CompleteDataMappingAgent] E002: 2ê°œ í‰ê°€ ë°œê²¬\n",
      "2025-06-09 19:21:02,846 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:02,847 INFO sqlalchemy.engine.Engine \n",
      "            SELECT \n",
      "                pek.peer_evaluation_id,\n",
      "                COALESCE(k.keyword_name, pek.custom_keyword) AS keyword\n",
      "            FROM peer_evaluation_keywords pek\n",
      "            LEFT JOIN keywords k ON pek.keyword_id = k.keyword_id\n",
      "            WHERE pek.peer_evaluation_id IN (%(id_0)s,%(id_1)s)\n",
      "        \n",
      "2025-06-09 19:21:02,847 INFO sqlalchemy.engine.Engine [generated in 0.00068s] {'id_0': 1, 'id_1': 2}\n",
      "2025-06-09 19:21:02,848 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-06-09 19:21:02,849 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:02,849 INFO sqlalchemy.engine.Engine \n",
      "            SELECT DISTINCT\n",
      "                pe.peer_evaluation_id,\n",
      "                t.task_id\n",
      "            FROM peer_evaluations pe\n",
      "            LEFT JOIN tasks t ON t.emp_no = pe.target_emp_no\n",
      "            WHERE pe.peer_evaluation_id IN (%(id_0)s,%(id_1)s)\n",
      "              AND t.task_id IS NOT NULL\n",
      "        \n",
      "2025-06-09 19:21:02,849 INFO sqlalchemy.engine.Engine [generated in 0.00052s] {'id_0': 1, 'id_1': 2}\n",
      "2025-06-09 19:21:02,851 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-06-09 19:21:02,851 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:02,852 INFO sqlalchemy.engine.Engine \n",
      "            SELECT task_id, task_performance as summary\n",
      "            FROM tasks\n",
      "            WHERE task_id IN (%(task_0)s,%(task_1)s,%(task_2)s,%(task_3)s,%(task_4)s,%(task_5)s,%(task_6)s,%(task_7)s,%(task_8)s,%(task_9)s,%(task_10)s,%(task_11)s)\n",
      "        \n",
      "2025-06-09 19:21:02,852 INFO sqlalchemy.engine.Engine [generated in 0.00118s] {'task_0': 1, 'task_1': 4, 'task_2': 5, 'task_3': 9, 'task_4': 14, 'task_5': 16, 'task_6': 1, 'task_7': 4, 'task_8': 5, 'task_9': 9, 'task_10': 14, 'task_11': 16}\n",
      "2025-06-09 19:21:02,854 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "[CompleteDataMappingAgent] E002: ë§¤í•‘ ì™„ë£Œ\n",
      "   ê²°ê³¼: í‰ê°€ì 2ëª…\n",
      "ğŸ”„ [ì‘ë™] ë§¥ë½ ìƒì„± ë…¸ë“œ ì‹œì‘...\n",
      "[SimpleContextAgent] E002: ë¬¸ì¥ ìƒì„± ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonjiyeong/Library/Caches/pypoetry/virtualenvs/langchain-kr-WTM_qa1c-py3.11/lib/python3.11/site-packages/langgraph/graph/state.py:95: UserWarning: Invalid state_schema: typing.Dict. Expected a type or Annotated[type, reducer]. Please provide a valid schema to ensure correct updates.\n",
      " See: https://langchain-ai.github.io/langgraph/reference/graphs/#stategraph\n",
      "  warnings.warn(\n",
      "/var/folders/x8/x9mhzs_j0yx8btgk3t9m0vvc0000gn/T/ipykernel_79280/1537465247.py:131: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(messages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleContextAgent] 1ë²ˆì§¸ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\n",
      "[SimpleContextAgent] 2ë²ˆì§¸ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\n",
      "[SimpleContextAgent] E002: ì´ 2ê°œ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\n",
      "   ê²°ê³¼: ë¬¸ì¥ 2ê°œ\n",
      "ğŸ”„ [ì‘ë™] ê°€ì¤‘ì¹˜ ë¶„ì„ ë…¸ë“œ ì‹œì‘...\n",
      "[WeightedAnalysisAgent] E002: ê°€ì¤‘ì¹˜ ë¶„ì„ ì‹œì‘\n",
      "[WeightedAnalysisAgent] E002: ë¶„ì„ ì™„ë£Œ\n",
      "   ê²°ê³¼: í‚¤ì›Œë“œ 11ê°œ\n",
      "ğŸ”„ [ì‘ë™] í”¼ë“œë°± ìƒì„± ë…¸ë“œ ì‹œì‘...\n",
      "[ImprovedFeedbackGenerationAgent] E002: í”¼ë“œë°± ìƒì„± ì‹œì‘\n",
      "[ImprovedFeedbackGenerationAgent] E002: í”¼ë“œë°± ìƒì„± ì„±ê³µ!\n",
      "   ê²°ê³¼: ê°•ì  1, ìš°ë ¤ 1, í˜‘ì—…ê´€ì°° 1\n",
      "ğŸ”„ [ì‘ë™] ë¶„ê¸°ë³„ DB ì €ì¥ ë…¸ë“œ ì‹œì‘...\n",
      "[DatabaseStorageAgent] E002: ë¶„ê¸°ë³„ DB ì €ì¥ ì‹œì‘ (ë¶„ê¸°: 3)\n",
      "[DatabaseStorageAgent] ì €ì¥ë  ë‚´ìš©:\n",
      "ê°•ì : í•´ë‹¹ ì§ì›ì€ ê³ ê° ì¸í„°ë·°ì™€ ê¸°ì¡´ ì‹œìŠ¤í…œ ë¶„ì„ì„ í†µí•´ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ë„ì¶œí•˜ëŠ” ë° ë›°ì–´ë‚œ ëŠ¥ë ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, ì°½ì˜ì ì´ê³  ë°ì€ íƒœë„ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ë©°, ê³ ê°ê³¼ì˜ ê¸ì •ì ì¸ ê´€ê³„ë¥¼ í˜•ì„±í•˜ëŠ” ë° ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°°ë ¤ì‹¬ê³¼ ì±…ì„ê° ìˆëŠ” íƒœë„ëŠ” íŒ€ì˜ ì‚¬ê¸°ë¥¼ ë†’ì´ëŠ” ë° í° ì—­í• ì„ í–ˆìŠµë‹ˆë‹¤.\n",
      "ìš°ë ¤: í•´ë‹¹ ì§ì›ì€ ê°€ë” íšŒí”¼í˜• íƒœë„ë¥¼ ë³´ì´ë©°, ì¦ì€ ì‹¤ìˆ˜ë¡œ ì¸í•´ ì—…ë¬´ì˜ ì™„ì„±ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¶€ë¶„ì€ íŒ€ì›Œí¬ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹¤ìˆ˜ë¥¼ ì¤„ì´ê³  ì ê·¹ì ì¸ ë¬¸ì œ í•´ê²° íƒœë„ë¥¼ ê¸°ë¥´ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "í˜‘ì—…ê´€ì°°: í•´ë‹¹ ì§ì›ì€ ê³ ê° ì¸í„°ë·°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì´ëŒë©° ê¸ì •ì ì¸ ë§ˆì¸ë“œë¡œ íŒ€ì›ë“¤ê³¼ í˜‘ë ¥í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ë¬´ì˜ìš•í•œ íƒœë„ì™€ ì‹¤ìˆ˜ë¡œ ì¸í•´ íŒ€ì˜ ëª©í‘œ ë‹¬ì„±ì— ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²½ìš°ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í–‰ë™ì€ íŒ€ì˜ íš¨ìœ¨ì„±ì„ ì €í•´í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë³´ë‹¤ ì ê·¹ì ì¸ ì°¸ì—¬ì™€ ì±…ì„ê°ì„ ê°–ê³  í˜‘ì—…ì— ì„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "--------------------------------------------------\n",
      "[DatabaseStorageAgent] ë¶„ê¸° 3 â†’ feedback_reports.ai_peer_talk_summaryì— ì €ì¥\n",
      "2025-06-09 19:21:10,670 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:10,670 INFO sqlalchemy.engine.Engine \n",
      "                SELECT te.team_evaluation_id\n",
      "                FROM team_evaluations te\n",
      "                JOIN teams t ON te.team_id = t.team_id\n",
      "                JOIN employees e ON e.team_id = t.team_id\n",
      "                WHERE te.period_id = %(period_id)s\n",
      "                  AND e.emp_no = %(emp_no)s\n",
      "                LIMIT 1\n",
      "            \n",
      "2025-06-09 19:21:10,670 INFO sqlalchemy.engine.Engine [generated in 0.00096s] {'period_id': 3, 'emp_no': 'E002'}\n",
      "2025-06-09 19:21:10,672 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-06-09 19:21:10,673 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:10,673 INFO sqlalchemy.engine.Engine \n",
      "                    SELECT feedback_report_id \n",
      "                    FROM feedback_reports \n",
      "                    WHERE team_evaluation_id = %(team_eval_id)s AND emp_no = %(emp_no)s\n",
      "                \n",
      "2025-06-09 19:21:10,674 INFO sqlalchemy.engine.Engine [generated in 0.00091s] {'team_eval_id': 1, 'emp_no': 'E002'}\n",
      "2025-06-09 19:21:10,675 INFO sqlalchemy.engine.Engine \n",
      "                        INSERT INTO feedback_reports (team_evaluation_id, emp_no, ai_peer_talk_summary, created_at, updated_at)\n",
      "                        VALUES (%(team_eval_id)s, %(emp_no)s, %(ai_peer_talk_summary)s, NOW(), NOW())\n",
      "                    \n",
      "2025-06-09 19:21:10,675 INFO sqlalchemy.engine.Engine [generated in 0.00029s] {'team_eval_id': 1, 'emp_no': 'E002', 'ai_peer_talk_summary': 'ê°•ì : í•´ë‹¹ ì§ì›ì€ ê³ ê° ì¸í„°ë·°ì™€ ê¸°ì¡´ ì‹œìŠ¤í…œ ë¶„ì„ì„ í†µí•´ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ë„ì¶œí•˜ëŠ” ë° ë›°ì–´ë‚œ ëŠ¥ë ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, ì°½ì˜ì ì´ê³  ë°ì€ íƒœë„ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ë©°, ê³ ê°ê³¼ì˜ ê¸ì •ì ì¸ ê´€ê³„ë¥¼ í˜•ì„±í•˜ëŠ” ë° ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°°ë ¤ì‹¬ê³¼ ì±…ì„ê° ìˆëŠ” íƒœë„ëŠ” íŒ€ì˜ ì‚¬ê¸°ë¥¼ ë†’ì´ ... (166 characters truncated) ...  ì„±ê³µì ìœ¼ë¡œ ì´ëŒë©° ê¸ì •ì ì¸ ë§ˆì¸ë“œë¡œ íŒ€ì›ë“¤ê³¼ í˜‘ë ¥í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ë¬´ì˜ìš•í•œ íƒœë„ì™€ ì‹¤ìˆ˜ë¡œ ì¸í•´ íŒ€ì˜ ëª©í‘œ ë‹¬ì„±ì— ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²½ìš°ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í–‰ë™ì€ íŒ€ì˜ íš¨ìœ¨ì„±ì„ ì €í•´í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë³´ë‹¤ ì ê·¹ì ì¸ ì°¸ì—¬ì™€ ì±…ì„ê°ì„ ê°–ê³  í˜‘ì—…ì— ì„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.'}\n",
      "2025-06-09 19:21:10,677 INFO sqlalchemy.engine.Engine COMMIT\n",
      "[DBì €ì¥] E002: feedback_reports.ai_peer_talk_summary ìƒˆ ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ\n",
      "[DatabaseStorageAgent] E002: DB ì €ì¥ ì„±ê³µ!\n",
      "   ê²°ê³¼: ë¶„ê¸°ë³„ DB ì €ì¥ ì™„ë£Œ\n",
      "âœ… E002 ë¶„ì„ ì™„ë£Œ!\n",
      "   ê°•ì : í•´ë‹¹ ì§ì›ì€ ê³ ê° ì¸í„°ë·°ì™€ ê¸°ì¡´ ì‹œìŠ¤í…œ ë¶„ì„ì„ í†µí•´ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ë„ì¶œí•˜ëŠ” ë° ë›°ì–´ë‚œ ëŠ¥...\n",
      "   ìš°ë ¤: í•´ë‹¹ ì§ì›ì€ ê°€ë” íšŒí”¼í˜• íƒœë„ë¥¼ ë³´ì´ë©°, ì¦ì€ ì‹¤ìˆ˜ë¡œ ì¸í•´ ì—…ë¬´ì˜ ì™„ì„±ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµ...\n",
      "   í˜‘ì—…ê´€ì°°: í•´ë‹¹ ì§ì›ì€ ê³ ê° ì¸í„°ë·°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì´ëŒë©° ê¸ì •ì ì¸ ë§ˆì¸ë“œë¡œ íŒ€ì›ë“¤ê³¼ í˜‘ë ¥í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬...\n",
      "\n",
      "[2/3] ğŸ“Š E003 ë¶„ì„ ì‹œì‘...\n",
      "------------------------------------------------------------\n",
      "2025-06-09 19:21:10,679 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:10,679 INFO sqlalchemy.engine.Engine \n",
      "                    SELECT fr.feedback_report_id\n",
      "                    FROM feedback_reports fr\n",
      "                    JOIN team_evaluations te ON fr.team_evaluation_id = te.team_evaluation_id\n",
      "                    WHERE te.period_id = %(period_id)s\n",
      "                      AND fr.emp_no = %(emp_no)s\n",
      "                      AND fr.ai_peer_talk_summary IS NOT NULL\n",
      "                      AND fr.ai_peer_talk_summary != ''\n",
      "                    LIMIT 1\n",
      "                \n",
      "2025-06-09 19:21:10,679 INFO sqlalchemy.engine.Engine [cached since 7.841s ago] {'period_id': 3, 'emp_no': 'E003'}\n",
      "2025-06-09 19:21:10,680 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "ğŸ”„ [ì‘ë™] ë°ì´í„° ë§¤í•‘ ë…¸ë“œ ì‹œì‘...\n",
      "[CompleteDataMappingAgent] E003: ë°ì´í„° ë§¤í•‘ ì‹œì‘ (ë¶„ê¸°: 3)\n",
      "2025-06-09 19:21:10,682 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:10,682 INFO sqlalchemy.engine.Engine \n",
      "            SELECT \n",
      "                pe.peer_evaluation_id,\n",
      "                te.period_id,\n",
      "                pe.target_emp_no AS target_emp_no,\n",
      "                pe.emp_no AS evaluator_emp_no,\n",
      "                pe.progress AS weight\n",
      "            FROM team_evaluations te\n",
      "            JOIN peer_evaluations pe ON te.team_evaluation_id = pe.team_evaluation_id\n",
      "            WHERE te.period_id = %(period_id)s\n",
      "              AND pe.target_emp_no = %(target_emp_no)s\n",
      "        \n",
      "2025-06-09 19:21:10,683 INFO sqlalchemy.engine.Engine [cached since 7.839s ago] {'period_id': 3, 'target_emp_no': 'E003'}\n",
      "2025-06-09 19:21:10,684 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "[CompleteDataMappingAgent] E003: 2ê°œ í‰ê°€ ë°œê²¬\n",
      "2025-06-09 19:21:10,684 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:10,685 INFO sqlalchemy.engine.Engine \n",
      "            SELECT \n",
      "                pek.peer_evaluation_id,\n",
      "                COALESCE(k.keyword_name, pek.custom_keyword) AS keyword\n",
      "            FROM peer_evaluation_keywords pek\n",
      "            LEFT JOIN keywords k ON pek.keyword_id = k.keyword_id\n",
      "            WHERE pek.peer_evaluation_id IN (%(id_0)s,%(id_1)s)\n",
      "        \n",
      "2025-06-09 19:21:10,685 INFO sqlalchemy.engine.Engine [cached since 7.839s ago] {'id_0': 3, 'id_1': 4}\n",
      "2025-06-09 19:21:10,686 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-06-09 19:21:10,687 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:10,687 INFO sqlalchemy.engine.Engine \n",
      "            SELECT DISTINCT\n",
      "                pe.peer_evaluation_id,\n",
      "                t.task_id\n",
      "            FROM peer_evaluations pe\n",
      "            LEFT JOIN tasks t ON t.emp_no = pe.target_emp_no\n",
      "            WHERE pe.peer_evaluation_id IN (%(id_0)s,%(id_1)s)\n",
      "              AND t.task_id IS NOT NULL\n",
      "        \n",
      "2025-06-09 19:21:10,688 INFO sqlalchemy.engine.Engine [cached since 7.839s ago] {'id_0': 3, 'id_1': 4}\n",
      "2025-06-09 19:21:10,689 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-06-09 19:21:10,689 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:10,690 INFO sqlalchemy.engine.Engine \n",
      "            SELECT task_id, task_performance as summary\n",
      "            FROM tasks\n",
      "            WHERE task_id IN (%(task_0)s,%(task_1)s,%(task_2)s,%(task_3)s,%(task_4)s,%(task_5)s,%(task_6)s,%(task_7)s,%(task_8)s,%(task_9)s)\n",
      "        \n",
      "2025-06-09 19:21:10,690 INFO sqlalchemy.engine.Engine [generated in 0.00070s] {'task_0': 2, 'task_1': 7, 'task_2': 10, 'task_3': 12, 'task_4': 13, 'task_5': 2, 'task_6': 7, 'task_7': 10, 'task_8': 12, 'task_9': 13}\n",
      "2025-06-09 19:21:10,691 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "[CompleteDataMappingAgent] E003: ë§¤í•‘ ì™„ë£Œ\n",
      "   ê²°ê³¼: í‰ê°€ì 2ëª…\n",
      "ğŸ”„ [ì‘ë™] ë§¥ë½ ìƒì„± ë…¸ë“œ ì‹œì‘...\n",
      "[SimpleContextAgent] E003: ë¬¸ì¥ ìƒì„± ì‹œì‘\n",
      "[SimpleContextAgent] 1ë²ˆì§¸ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\n",
      "[SimpleContextAgent] 2ë²ˆì§¸ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\n",
      "[SimpleContextAgent] E003: ì´ 2ê°œ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\n",
      "   ê²°ê³¼: ë¬¸ì¥ 2ê°œ\n",
      "ğŸ”„ [ì‘ë™] ê°€ì¤‘ì¹˜ ë¶„ì„ ë…¸ë“œ ì‹œì‘...\n",
      "[WeightedAnalysisAgent] E003: ê°€ì¤‘ì¹˜ ë¶„ì„ ì‹œì‘\n",
      "[WeightedAnalysisAgent] E003: ë¶„ì„ ì™„ë£Œ\n",
      "   ê²°ê³¼: í‚¤ì›Œë“œ 11ê°œ\n",
      "ğŸ”„ [ì‘ë™] í”¼ë“œë°± ìƒì„± ë…¸ë“œ ì‹œì‘...\n",
      "[ImprovedFeedbackGenerationAgent] E003: í”¼ë“œë°± ìƒì„± ì‹œì‘\n",
      "[ImprovedFeedbackGenerationAgent] E003: í”¼ë“œë°± ìƒì„± ì„±ê³µ!\n",
      "   ê²°ê³¼: ê°•ì  1, ìš°ë ¤ 1, í˜‘ì—…ê´€ì°° 1\n",
      "ğŸ”„ [ì‘ë™] ë¶„ê¸°ë³„ DB ì €ì¥ ë…¸ë“œ ì‹œì‘...\n",
      "[DatabaseStorageAgent] E003: ë¶„ê¸°ë³„ DB ì €ì¥ ì‹œì‘ (ë¶„ê¸°: 3)\n",
      "[DatabaseStorageAgent] ì €ì¥ë  ë‚´ìš©:\n",
      "ê°•ì : í•´ë‹¹ ì§ì›ì€ MSA ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ ì„±ì‹¤í•˜ê²Œ ì™„ë£Œí•˜ë©°, ë¬¸ì œ í•´ê²°ì— ìˆì–´ ê¸ì •ì ì¸ íƒœë„ë¥¼ ìœ ì§€í•˜ëŠ” ë™ì‹œì— ë›°ì–´ë‚œ ë¬¸ì œí•´ê²°ë ¥ì„ ë°œíœ˜í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì£¼ìš” ëª¨ë“ˆ ê°„ ì—°ë™ ë°©ì•ˆì„ í™•ì •í•˜ëŠ” ê³¼ì •ì—ì„œ ì—´ì •ê³¼ ì¶”ì§„ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.\n",
      "ìš°ë ¤: ì„¤ê³„ ë¬¸ì„œí™” ê³¼ì •ì—ì„œ ë‹¤ì†Œ ìˆ˜ë™ì ì¸ ë©´ì´ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ë¬¸ì„œí™”ì˜ ì™„ì„±ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë³´ë‹¤ ì ê·¹ì ì¸ ì ‘ê·¼ê³¼ ì£¼ë„ì ì¸ ì°¸ì—¬ê°€ í•„ìš”í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "í˜‘ì—…ê´€ì°°: í•´ë‹¹ ì§ì›ì€ ì£¼ë„ì ìœ¼ë¡œ ì—´ë¦° ì†Œí†µì„ í†µí•´ íŒ€ê³¼ì˜ í˜‘ì—…ì„ ì´ëŒì–´ë‚´ë©°, ê¸ì •ì ì¸ íƒœë„ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¬¸ì„œí™” ì‘ì—…ì—ì„œëŠ” ìˆ˜ë™ì ì¸ íƒœë„ê°€ ê´€ì°°ë˜ì–´, ì´ ë¶€ë¶„ì—ì„œì˜ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "--------------------------------------------------\n",
      "[DatabaseStorageAgent] ë¶„ê¸° 3 â†’ feedback_reports.ai_peer_talk_summaryì— ì €ì¥\n",
      "2025-06-09 19:21:19,990 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:19,991 INFO sqlalchemy.engine.Engine \n",
      "                SELECT te.team_evaluation_id\n",
      "                FROM team_evaluations te\n",
      "                JOIN teams t ON te.team_id = t.team_id\n",
      "                JOIN employees e ON e.team_id = t.team_id\n",
      "                WHERE te.period_id = %(period_id)s\n",
      "                  AND e.emp_no = %(emp_no)s\n",
      "                LIMIT 1\n",
      "            \n",
      "2025-06-09 19:21:19,991 INFO sqlalchemy.engine.Engine [cached since 9.322s ago] {'period_id': 3, 'emp_no': 'E003'}\n",
      "2025-06-09 19:21:19,993 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-06-09 19:21:19,994 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:19,995 INFO sqlalchemy.engine.Engine \n",
      "                    SELECT feedback_report_id \n",
      "                    FROM feedback_reports \n",
      "                    WHERE team_evaluation_id = %(team_eval_id)s AND emp_no = %(emp_no)s\n",
      "                \n",
      "2025-06-09 19:21:19,995 INFO sqlalchemy.engine.Engine [cached since 9.322s ago] {'team_eval_id': 1, 'emp_no': 'E003'}\n",
      "2025-06-09 19:21:19,998 INFO sqlalchemy.engine.Engine \n",
      "                        INSERT INTO feedback_reports (team_evaluation_id, emp_no, ai_peer_talk_summary, created_at, updated_at)\n",
      "                        VALUES (%(team_eval_id)s, %(emp_no)s, %(ai_peer_talk_summary)s, NOW(), NOW())\n",
      "                    \n",
      "2025-06-09 19:21:19,998 INFO sqlalchemy.engine.Engine [cached since 9.323s ago] {'team_eval_id': 1, 'emp_no': 'E003', 'ai_peer_talk_summary': 'ê°•ì : í•´ë‹¹ ì§ì›ì€ MSA ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ ì„±ì‹¤í•˜ê²Œ ì™„ë£Œí•˜ë©°, ë¬¸ì œ í•´ê²°ì— ìˆì–´ ê¸ì •ì ì¸ íƒœë„ë¥¼ ìœ ì§€í•˜ëŠ” ë™ì‹œì— ë›°ì–´ë‚œ ë¬¸ì œí•´ê²°ë ¥ì„ ë°œíœ˜í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì£¼ìš” ëª¨ë“ˆ ê°„ ì—°ë™ ë°©ì•ˆì„ í™•ì •í•˜ëŠ” ê³¼ì •ì—ì„œ ì—´ì •ê³¼ ì¶”ì§„ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.\\nìš°ë ¤: ì„¤ê³„ ë¬¸ì„œí™” ê³¼ì •ì—ì„œ  ... (44 characters truncated) ...  ì ‘ê·¼ê³¼ ì£¼ë„ì ì¸ ì°¸ì—¬ê°€ í•„ìš”í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\\ní˜‘ì—…ê´€ì°°: í•´ë‹¹ ì§ì›ì€ ì£¼ë„ì ìœ¼ë¡œ ì—´ë¦° ì†Œí†µì„ í†µí•´ íŒ€ê³¼ì˜ í˜‘ì—…ì„ ì´ëŒì–´ë‚´ë©°, ê¸ì •ì ì¸ íƒœë„ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¬¸ì„œí™” ì‘ì—…ì—ì„œëŠ” ìˆ˜ë™ì ì¸ íƒœë„ê°€ ê´€ì°°ë˜ì–´, ì´ ë¶€ë¶„ì—ì„œì˜ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.'}\n",
      "2025-06-09 19:21:19,999 INFO sqlalchemy.engine.Engine COMMIT\n",
      "[DBì €ì¥] E003: feedback_reports.ai_peer_talk_summary ìƒˆ ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ\n",
      "[DatabaseStorageAgent] E003: DB ì €ì¥ ì„±ê³µ!\n",
      "   ê²°ê³¼: ë¶„ê¸°ë³„ DB ì €ì¥ ì™„ë£Œ\n",
      "âœ… E003 ë¶„ì„ ì™„ë£Œ!\n",
      "   ê°•ì : í•´ë‹¹ ì§ì›ì€ MSA ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ ì„±ì‹¤í•˜ê²Œ ì™„ë£Œí•˜ë©°, ë¬¸ì œ í•´ê²°ì— ìˆì–´ ê¸ì •ì ì¸ íƒœ...\n",
      "   ìš°ë ¤: ì„¤ê³„ ë¬¸ì„œí™” ê³¼ì •ì—ì„œ ë‹¤ì†Œ ìˆ˜ë™ì ì¸ ë©´ì´ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ë¬¸ì„œí™”ì˜ ì™„ì„±ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë³´...\n",
      "   í˜‘ì—…ê´€ì°°: í•´ë‹¹ ì§ì›ì€ ì£¼ë„ì ìœ¼ë¡œ ì—´ë¦° ì†Œí†µì„ í†µí•´ íŒ€ê³¼ì˜ í˜‘ì—…ì„ ì´ëŒì–´ë‚´ë©°, ê¸ì •ì ì¸ íƒœë„ë¡œ ë¬¸ì œë¥¼...\n",
      "\n",
      "[3/3] ğŸ“Š E004 ë¶„ì„ ì‹œì‘...\n",
      "------------------------------------------------------------\n",
      "2025-06-09 19:21:20,001 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:20,001 INFO sqlalchemy.engine.Engine \n",
      "                    SELECT fr.feedback_report_id\n",
      "                    FROM feedback_reports fr\n",
      "                    JOIN team_evaluations te ON fr.team_evaluation_id = te.team_evaluation_id\n",
      "                    WHERE te.period_id = %(period_id)s\n",
      "                      AND fr.emp_no = %(emp_no)s\n",
      "                      AND fr.ai_peer_talk_summary IS NOT NULL\n",
      "                      AND fr.ai_peer_talk_summary != ''\n",
      "                    LIMIT 1\n",
      "                \n",
      "2025-06-09 19:21:20,001 INFO sqlalchemy.engine.Engine [cached since 17.16s ago] {'period_id': 3, 'emp_no': 'E004'}\n",
      "2025-06-09 19:21:20,002 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "ğŸ”„ [ì‘ë™] ë°ì´í„° ë§¤í•‘ ë…¸ë“œ ì‹œì‘...\n",
      "[CompleteDataMappingAgent] E004: ë°ì´í„° ë§¤í•‘ ì‹œì‘ (ë¶„ê¸°: 3)\n",
      "2025-06-09 19:21:20,003 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:20,004 INFO sqlalchemy.engine.Engine \n",
      "            SELECT \n",
      "                pe.peer_evaluation_id,\n",
      "                te.period_id,\n",
      "                pe.target_emp_no AS target_emp_no,\n",
      "                pe.emp_no AS evaluator_emp_no,\n",
      "                pe.progress AS weight\n",
      "            FROM team_evaluations te\n",
      "            JOIN peer_evaluations pe ON te.team_evaluation_id = pe.team_evaluation_id\n",
      "            WHERE te.period_id = %(period_id)s\n",
      "              AND pe.target_emp_no = %(target_emp_no)s\n",
      "        \n",
      "2025-06-09 19:21:20,004 INFO sqlalchemy.engine.Engine [cached since 17.16s ago] {'period_id': 3, 'target_emp_no': 'E004'}\n",
      "2025-06-09 19:21:20,005 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "[CompleteDataMappingAgent] E004: 2ê°œ í‰ê°€ ë°œê²¬\n",
      "2025-06-09 19:21:20,006 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:20,006 INFO sqlalchemy.engine.Engine \n",
      "            SELECT \n",
      "                pek.peer_evaluation_id,\n",
      "                COALESCE(k.keyword_name, pek.custom_keyword) AS keyword\n",
      "            FROM peer_evaluation_keywords pek\n",
      "            LEFT JOIN keywords k ON pek.keyword_id = k.keyword_id\n",
      "            WHERE pek.peer_evaluation_id IN (%(id_0)s,%(id_1)s)\n",
      "        \n",
      "2025-06-09 19:21:20,006 INFO sqlalchemy.engine.Engine [cached since 17.16s ago] {'id_0': 5, 'id_1': 6}\n",
      "2025-06-09 19:21:20,007 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-06-09 19:21:20,007 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:20,007 INFO sqlalchemy.engine.Engine \n",
      "            SELECT DISTINCT\n",
      "                pe.peer_evaluation_id,\n",
      "                t.task_id\n",
      "            FROM peer_evaluations pe\n",
      "            LEFT JOIN tasks t ON t.emp_no = pe.target_emp_no\n",
      "            WHERE pe.peer_evaluation_id IN (%(id_0)s,%(id_1)s)\n",
      "              AND t.task_id IS NOT NULL\n",
      "        \n",
      "2025-06-09 19:21:20,008 INFO sqlalchemy.engine.Engine [cached since 17.16s ago] {'id_0': 5, 'id_1': 6}\n",
      "2025-06-09 19:21:20,009 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-06-09 19:21:20,009 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:20,009 INFO sqlalchemy.engine.Engine \n",
      "            SELECT task_id, task_performance as summary\n",
      "            FROM tasks\n",
      "            WHERE task_id IN (%(task_0)s,%(task_1)s,%(task_2)s,%(task_3)s,%(task_4)s,%(task_5)s,%(task_6)s,%(task_7)s,%(task_8)s,%(task_9)s)\n",
      "        \n",
      "2025-06-09 19:21:20,010 INFO sqlalchemy.engine.Engine [cached since 9.32s ago] {'task_0': 3, 'task_1': 6, 'task_2': 8, 'task_3': 11, 'task_4': 15, 'task_5': 3, 'task_6': 6, 'task_7': 8, 'task_8': 11, 'task_9': 15}\n",
      "2025-06-09 19:21:20,011 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "[CompleteDataMappingAgent] E004: ë§¤í•‘ ì™„ë£Œ\n",
      "   ê²°ê³¼: í‰ê°€ì 2ëª…\n",
      "ğŸ”„ [ì‘ë™] ë§¥ë½ ìƒì„± ë…¸ë“œ ì‹œì‘...\n",
      "[SimpleContextAgent] E004: ë¬¸ì¥ ìƒì„± ì‹œì‘\n",
      "[SimpleContextAgent] 1ë²ˆì§¸ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\n",
      "[SimpleContextAgent] 2ë²ˆì§¸ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\n",
      "[SimpleContextAgent] E004: ì´ 2ê°œ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\n",
      "   ê²°ê³¼: ë¬¸ì¥ 2ê°œ\n",
      "ğŸ”„ [ì‘ë™] ê°€ì¤‘ì¹˜ ë¶„ì„ ë…¸ë“œ ì‹œì‘...\n",
      "[WeightedAnalysisAgent] E004: ê°€ì¤‘ì¹˜ ë¶„ì„ ì‹œì‘\n",
      "[WeightedAnalysisAgent] E004: ë¶„ì„ ì™„ë£Œ\n",
      "   ê²°ê³¼: í‚¤ì›Œë“œ 8ê°œ\n",
      "ğŸ”„ [ì‘ë™] í”¼ë“œë°± ìƒì„± ë…¸ë“œ ì‹œì‘...\n",
      "[ImprovedFeedbackGenerationAgent] E004: í”¼ë“œë°± ìƒì„± ì‹œì‘\n",
      "[ImprovedFeedbackGenerationAgent] E004: í”¼ë“œë°± ìƒì„± ì„±ê³µ!\n",
      "   ê²°ê³¼: ê°•ì  1, ìš°ë ¤ 1, í˜‘ì—…ê´€ì°° 1\n",
      "ğŸ”„ [ì‘ë™] ë¶„ê¸°ë³„ DB ì €ì¥ ë…¸ë“œ ì‹œì‘...\n",
      "[DatabaseStorageAgent] E004: ë¶„ê¸°ë³„ DB ì €ì¥ ì‹œì‘ (ë¶„ê¸°: 3)\n",
      "[DatabaseStorageAgent] ì €ì¥ë  ë‚´ìš©:\n",
      "ê°•ì : í•´ë‹¹ ì§ì›ì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒœë„ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ë©°, ëª©í‘œì§€í–¥ì ì´ê³  ëŠ¥ë™ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ í†µí•´ AI ëª¨ë¸ í•™ìŠµ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ìœ ë¨¸ê°ê°ì„ ë°œíœ˜í•˜ì—¬ ì†Œí†µì˜ ì¥ë²½ì„ ê·¹ë³µí•˜ëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.\n",
      "ìš°ë ¤: ê°œì¸ì£¼ì˜ì  ì„±í–¥ê³¼ ì±…ì„ê° ê²°ì—¬ê°€ ì‚¬ìš©ì ë°ì´í„° ì´ê´€ ì „ëµ ìˆ˜ë¦½ ê³¼ì •ì—ì„œ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¶€ë¶„ì€ íŒ€ì˜ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ê°œì„ ì´ í•„ìš”í•˜ë©°, í˜‘ì—…ê³¼ ì±…ì„ê°ì„ ê°•í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "í˜‘ì—…ê´€ì°°: í•´ë‹¹ ì§ì›ì€ ëª©í‘œì§€í–¥ì ì´ê³  ëŠ¥ë™ì ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì¶”ì§„í•˜ë©°, ìœ ë¨¸ë¥¼ í†µí•´ íŒ€ ë‚´ ì†Œí†µì„ ì›í™œí•˜ê²Œ í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ì¼ë¶€ ìƒí™©ì—ì„œëŠ” ê°œì¸ì£¼ì˜ì  íƒœë„ê°€ ë‚˜íƒ€ë‚˜ë©°, íŒ€ì˜ ê³µë™ ëª©í‘œì— ëŒ€í•œ ì±…ì„ê°ì´ ë¶€ì¡±í•œ ê²ƒìœ¼ë¡œ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "--------------------------------------------------\n",
      "[DatabaseStorageAgent] ë¶„ê¸° 3 â†’ feedback_reports.ai_peer_talk_summaryì— ì €ì¥\n",
      "2025-06-09 19:21:31,561 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:31,561 INFO sqlalchemy.engine.Engine \n",
      "                SELECT te.team_evaluation_id\n",
      "                FROM team_evaluations te\n",
      "                JOIN teams t ON te.team_id = t.team_id\n",
      "                JOIN employees e ON e.team_id = t.team_id\n",
      "                WHERE te.period_id = %(period_id)s\n",
      "                  AND e.emp_no = %(emp_no)s\n",
      "                LIMIT 1\n",
      "            \n",
      "2025-06-09 19:21:31,562 INFO sqlalchemy.engine.Engine [cached since 20.89s ago] {'period_id': 3, 'emp_no': 'E004'}\n",
      "2025-06-09 19:21:31,563 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "2025-06-09 19:21:31,564 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-06-09 19:21:31,564 INFO sqlalchemy.engine.Engine \n",
      "                    SELECT feedback_report_id \n",
      "                    FROM feedback_reports \n",
      "                    WHERE team_evaluation_id = %(team_eval_id)s AND emp_no = %(emp_no)s\n",
      "                \n",
      "2025-06-09 19:21:31,565 INFO sqlalchemy.engine.Engine [cached since 20.89s ago] {'team_eval_id': 1, 'emp_no': 'E004'}\n",
      "2025-06-09 19:21:31,565 INFO sqlalchemy.engine.Engine \n",
      "                        INSERT INTO feedback_reports (team_evaluation_id, emp_no, ai_peer_talk_summary, created_at, updated_at)\n",
      "                        VALUES (%(team_eval_id)s, %(emp_no)s, %(ai_peer_talk_summary)s, NOW(), NOW())\n",
      "                    \n",
      "2025-06-09 19:21:31,566 INFO sqlalchemy.engine.Engine [cached since 20.89s ago] {'team_eval_id': 1, 'emp_no': 'E004', 'ai_peer_talk_summary': 'ê°•ì : í•´ë‹¹ ì§ì›ì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒœë„ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ë©°, ëª©í‘œì§€í–¥ì ì´ê³  ëŠ¥ë™ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ í†µí•´ AI ëª¨ë¸ í•™ìŠµ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ìœ ë¨¸ê°ê°ì„ ë°œíœ˜í•˜ì—¬ ì†Œí†µì˜ ì¥ë²½ì„ ê·¹ë³µí•˜ëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.\\nìš°ë ¤: ê°œì¸ì£¼ì˜ì  ì„±í–¥ê³¼ ì±… ... (89 characters truncated) ... ì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\ní˜‘ì—…ê´€ì°°: í•´ë‹¹ ì§ì›ì€ ëª©í‘œì§€í–¥ì ì´ê³  ëŠ¥ë™ì ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì¶”ì§„í•˜ë©°, ìœ ë¨¸ë¥¼ í†µí•´ íŒ€ ë‚´ ì†Œí†µì„ ì›í™œí•˜ê²Œ í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ì¼ë¶€ ìƒí™©ì—ì„œëŠ” ê°œì¸ì£¼ì˜ì  íƒœë„ê°€ ë‚˜íƒ€ë‚˜ë©°, íŒ€ì˜ ê³µë™ ëª©í‘œì— ëŒ€í•œ ì±…ì„ê°ì´ ë¶€ì¡±í•œ ê²ƒìœ¼ë¡œ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤.'}\n",
      "2025-06-09 19:21:31,566 INFO sqlalchemy.engine.Engine COMMIT\n",
      "[DBì €ì¥] E004: feedback_reports.ai_peer_talk_summary ìƒˆ ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ\n",
      "[DatabaseStorageAgent] E004: DB ì €ì¥ ì„±ê³µ!\n",
      "   ê²°ê³¼: ë¶„ê¸°ë³„ DB ì €ì¥ ì™„ë£Œ\n",
      "âœ… E004 ë¶„ì„ ì™„ë£Œ!\n",
      "   ê°•ì : í•´ë‹¹ ì§ì›ì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒœë„ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ë©°, ëª©í‘œì§€í–¥ì ì´ê³  ëŠ¥ë™ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ ...\n",
      "   ìš°ë ¤: ê°œì¸ì£¼ì˜ì  ì„±í–¥ê³¼ ì±…ì„ê° ê²°ì—¬ê°€ ì‚¬ìš©ì ë°ì´í„° ì´ê´€ ì „ëµ ìˆ˜ë¦½ ê³¼ì •ì—ì„œ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´...\n",
      "   í˜‘ì—…ê´€ì°°: í•´ë‹¹ ì§ì›ì€ ëª©í‘œì§€í–¥ì ì´ê³  ëŠ¥ë™ì ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì¶”ì§„í•˜ë©°, ìœ ë¨¸ë¥¼ í†µí•´ íŒ€ ë‚´ ì†Œí†µì„ ì›í™œ...\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½ (feedback_reports í…Œì´ë¸”)\n",
      "================================================================================\n",
      "ì´ ëŒ€ìƒì: 3ëª…\n",
      "ì„±ê³µ: 3ëª…\n",
      "ìŠ¤í‚µ (ê¸°ì¡´ ì™„ë£Œ): 0ëª…\n",
      "ì‹¤íŒ¨: 0ëª…\n",
      "\n",
      "âœ… 3ë¶„ê¸° ì „ì²´ ë¶„ì„ ì™„ë£Œ!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'E002': {'ë¶„ê¸°': '3',\n",
       "  'í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ': 'E002',\n",
       "  'í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸': ['E003', 'E004'],\n",
       "  'ì„±ê³¼ì§€í‘œID_ë¦¬ìŠ¤íŠ¸': ['1', '1'],\n",
       "  'ë¹„ì¤‘': [3, 2],\n",
       "  'í‚¤ì›Œë“œëª¨ìŒ': ['ë°°ë ¤, ì±…ì„ê° ìˆëŠ”, ë°ì€, íšŒí”¼í˜•, ì°½ì˜ì ',\n",
       "   'ê¸ì •ë§ˆì¸ë“œ, ê¼¼ê¼¼í•œ, ì‹¤ìˆ˜ê°€ ì¦ì€, ë¬´ì˜ìš•ì, ì¹œì ˆí•œ, íŒ€ì›Œí¬ ì €í•˜'],\n",
       "  'êµ¬ì²´ì ì—…ë¬´ë‚´ìš©': ['ê³ ê° ì¸í„°ë·° ë° ê¸°ì¡´ ì‹œìŠ¤í…œ ë¶„ì„ì„ í†µí•´ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ë„ì¶œí•˜ê³ , ìƒì„¸ ê¸°ëŠ¥ ëª…ì„¸ì„œ 90% ì™„ì„±.',\n",
       "   'ê³ ê° ì¸í„°ë·° ë° ê¸°ì¡´ ì‹œìŠ¤í…œ ë¶„ì„ì„ í†µí•´ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ë„ì¶œí•˜ê³ , ìƒì„¸ ê¸°ëŠ¥ ëª…ì„¸ì„œ 90% ì™„ì„±.'],\n",
       "  'ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤': ['í•´ë‹¹ ì§ì›ì€ ê³ ê° ì¸í„°ë·°ì™€ ê¸°ì¡´ ì‹œìŠ¤í…œ ë¶„ì„ì„ í†µí•´ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ë„ì¶œí•˜ë©°, ì°½ì˜ì ì´ê³  ë°ì€ íƒœë„ë¡œ ìƒì„¸ ê¸°ëŠ¥ ëª…ì„¸ì„œë¥¼ 90% ì™„ì„±í–ˆìœ¼ë‚˜, ê°€ë” íšŒí”¼í˜• íƒœë„ê°€ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤.',\n",
       "   'í•´ë‹¹ ì§ì›ì€ ê¸ì •ì ì¸ ë§ˆì¸ë“œì™€ ì¹œì ˆí•¨ìœ¼ë¡œ ê³ ê° ì¸í„°ë·°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì´ëŒì—ˆìœ¼ë‚˜, ì¦ì€ ì‹¤ìˆ˜ì™€ ë¬´ì˜ìš•ìœ¼ë¡œ íŒ€ì›Œí¬ ì €í•˜ë¥¼ ì´ˆë˜í•˜ì—¬ ìƒì„¸ ê¸°ëŠ¥ ëª…ì„¸ì„œ ì™„ì„±ì— ì–´ë ¤ì›€ì„ ê²ªì—ˆìŠµë‹ˆë‹¤.'],\n",
       "  'ê°•ì ': ['í•´ë‹¹ ì§ì›ì€ ê³ ê° ì¸í„°ë·°ì™€ ê¸°ì¡´ ì‹œìŠ¤í…œ ë¶„ì„ì„ í†µí•´ í•µì‹¬ ìš”êµ¬ì‚¬í•­ì„ ë„ì¶œí•˜ëŠ” ë° ë›°ì–´ë‚œ ëŠ¥ë ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, ì°½ì˜ì ì´ê³  ë°ì€ íƒœë„ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ë©°, ê³ ê°ê³¼ì˜ ê¸ì •ì ì¸ ê´€ê³„ë¥¼ í˜•ì„±í•˜ëŠ” ë° ê¸°ì—¬í–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°°ë ¤ì‹¬ê³¼ ì±…ì„ê° ìˆëŠ” íƒœë„ëŠ” íŒ€ì˜ ì‚¬ê¸°ë¥¼ ë†’ì´ëŠ” ë° í° ì—­í• ì„ í–ˆìŠµë‹ˆë‹¤.'],\n",
       "  'ìš°ë ¤': ['í•´ë‹¹ ì§ì›ì€ ê°€ë” íšŒí”¼í˜• íƒœë„ë¥¼ ë³´ì´ë©°, ì¦ì€ ì‹¤ìˆ˜ë¡œ ì¸í•´ ì—…ë¬´ì˜ ì™„ì„±ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¶€ë¶„ì€ íŒ€ì›Œí¬ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹¤ìˆ˜ë¥¼ ì¤„ì´ê³  ì ê·¹ì ì¸ ë¬¸ì œ í•´ê²° íƒœë„ë¥¼ ê¸°ë¥´ëŠ” ê²ƒì´ í•„ìš”í•©ë‹ˆë‹¤.'],\n",
       "  'í˜‘ì—…ê´€ì°°': ['í•´ë‹¹ ì§ì›ì€ ê³ ê° ì¸í„°ë·°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì´ëŒë©° ê¸ì •ì ì¸ ë§ˆì¸ë“œë¡œ íŒ€ì›ë“¤ê³¼ í˜‘ë ¥í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ë¬´ì˜ìš•í•œ íƒœë„ì™€ ì‹¤ìˆ˜ë¡œ ì¸í•´ íŒ€ì˜ ëª©í‘œ ë‹¬ì„±ì— ì–´ë ¤ì›€ì„ ê²ªëŠ” ê²½ìš°ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í–‰ë™ì€ íŒ€ì˜ íš¨ìœ¨ì„±ì„ ì €í•´í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë³´ë‹¤ ì ê·¹ì ì¸ ì°¸ì—¬ì™€ ì±…ì„ê°ì„ ê°–ê³  í˜‘ì—…ì— ì„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.']},\n",
       " 'E003': {'ë¶„ê¸°': '3',\n",
       "  'í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ': 'E003',\n",
       "  'í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸': ['E002', 'E004'],\n",
       "  'ì„±ê³¼ì§€í‘œID_ë¦¬ìŠ¤íŠ¸': ['1', '1'],\n",
       "  'ë¹„ì¤‘': [4, 1],\n",
       "  'í‚¤ì›Œë“œëª¨ìŒ': ['ì„±ì‹¤í•œ, ë¬¸ì œí•´ê²°ë ¥, ìˆ˜ë™ì ì¸, ê¸ì •ì ',\n",
       "   'ì—´ì •, ì¶”ì§„ë ¥ ìˆëŠ”, ì£¼ë„ì ì¸, ì—´ë¦° ì†Œí†µ, í˜„ì‹¤ì ì¸, ë¶€ì •ì , ë¶„ì„ë ¥'],\n",
       "  'êµ¬ì²´ì ì—…ë¬´ë‚´ìš©': ['MSA ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì™„ë£Œ ë° ì£¼ìš” ëª¨ë“ˆ ê°„ ì—°ë™ ë°©ì•ˆ í™•ì •. 80% ì„¤ê³„ ë¬¸ì„œí™”.',\n",
       "   'MSA ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì™„ë£Œ ë° ì£¼ìš” ëª¨ë“ˆ ê°„ ì—°ë™ ë°©ì•ˆ í™•ì •. 80% ì„¤ê³„ ë¬¸ì„œí™”.'],\n",
       "  'ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤': ['í•´ë‹¹ ì§ì›ì€ MSA ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ ì„±ì‹¤í•˜ê²Œ ì™„ë£Œí•˜ê³  ì£¼ìš” ëª¨ë“ˆ ê°„ ì—°ë™ ë°©ì•ˆì„ í™•ì •í•˜ë©°, ê¸ì •ì ì¸ íƒœë„ë¡œ ë¬¸ì œë¥¼ í•´ê²°í–ˆìœ¼ë‚˜ ë‹¤ì†Œ ìˆ˜ë™ì ì¸ ë©´ì´ ìˆì–´ ì„¤ê³„ ë¬¸ì„œí™”ê°€ 80%ì— ê·¸ì³¤ìŠµë‹ˆë‹¤.',\n",
       "   'í•´ë‹¹ ì§ì›ì€ MSA ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ ì™„ë£Œí•˜ê³  ì£¼ìš” ëª¨ë“ˆ ê°„ ì—°ë™ ë°©ì•ˆì„ í™•ì •í•˜ëŠ” ê³¼ì •ì—ì„œ ì—´ì •ê³¼ ì¶”ì§„ë ¥ì„ ë°œíœ˜í•˜ë©°, ì£¼ë„ì ìœ¼ë¡œ ì—´ë¦° ì†Œí†µì„ í†µí•´ 80%ì˜ ì„¤ê³„ ë¬¸ì„œí™”ë¥¼ í˜„ì‹¤ì ìœ¼ë¡œ ì´ëŒì–´ëƒˆìŠµë‹ˆë‹¤.'],\n",
       "  'ê°•ì ': ['í•´ë‹¹ ì§ì›ì€ MSA ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ ì„±ì‹¤í•˜ê²Œ ì™„ë£Œí•˜ë©°, ë¬¸ì œ í•´ê²°ì— ìˆì–´ ê¸ì •ì ì¸ íƒœë„ë¥¼ ìœ ì§€í•˜ëŠ” ë™ì‹œì— ë›°ì–´ë‚œ ë¬¸ì œí•´ê²°ë ¥ì„ ë°œíœ˜í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ì£¼ìš” ëª¨ë“ˆ ê°„ ì—°ë™ ë°©ì•ˆì„ í™•ì •í•˜ëŠ” ê³¼ì •ì—ì„œ ì—´ì •ê³¼ ì¶”ì§„ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.'],\n",
       "  'ìš°ë ¤': ['ì„¤ê³„ ë¬¸ì„œí™” ê³¼ì •ì—ì„œ ë‹¤ì†Œ ìˆ˜ë™ì ì¸ ë©´ì´ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ë¬¸ì„œí™”ì˜ ì™„ì„±ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë³´ë‹¤ ì ê·¹ì ì¸ ì ‘ê·¼ê³¼ ì£¼ë„ì ì¸ ì°¸ì—¬ê°€ í•„ìš”í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.'],\n",
       "  'í˜‘ì—…ê´€ì°°': ['í•´ë‹¹ ì§ì›ì€ ì£¼ë„ì ìœ¼ë¡œ ì—´ë¦° ì†Œí†µì„ í†µí•´ íŒ€ê³¼ì˜ í˜‘ì—…ì„ ì´ëŒì–´ë‚´ë©°, ê¸ì •ì ì¸ íƒœë„ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¬¸ì„œí™” ì‘ì—…ì—ì„œëŠ” ìˆ˜ë™ì ì¸ íƒœë„ê°€ ê´€ì°°ë˜ì–´, ì´ ë¶€ë¶„ì—ì„œì˜ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.']},\n",
       " 'E004': {'ë¶„ê¸°': '3',\n",
       "  'í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ': 'E004',\n",
       "  'í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸': ['E002', 'E003'],\n",
       "  'ì„±ê³¼ì§€í‘œID_ë¦¬ìŠ¤íŠ¸': ['1', '1'],\n",
       "  'ë¹„ì¤‘': [2, 3],\n",
       "  'í‚¤ì›Œë“œëª¨ìŒ': ['ëª©í‘œì§€í–¥ì , ëŠ¥ë™ì ì¸, ë¹ ë¥¸ ì‹¤í–‰ë ¥, ì†Œí†µë‹¨ì ˆ, ìœ ë¨¸ê°ê°', 'ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”, ê°œì¸ì£¼ì˜, ì±…ì„ê° ê²°ì—¬'],\n",
       "  'êµ¬ì²´ì ì—…ë¬´ë‚´ìš©': ['ì‚¬ìš©ì ë°ì´í„°, AI ëª¨ë¸ í•™ìŠµ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„ ì™„ë£Œ. ë°ì´í„° ì´ê´€ ì „ëµ ìˆ˜ë¦½ ì‹œì‘.',\n",
       "   'ì‚¬ìš©ì ë°ì´í„°, AI ëª¨ë¸ í•™ìŠµ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„ ì™„ë£Œ. ë°ì´í„° ì´ê´€ ì „ëµ ìˆ˜ë¦½ ì‹œì‘.'],\n",
       "  'ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤': ['í•´ë‹¹ ì§ì›ì€ ëª©í‘œì§€í–¥ì ì´ê³  ëŠ¥ë™ì ìœ¼ë¡œ ì‚¬ìš©ì ë°ì´í„°ì™€ AI ëª¨ë¸ í•™ìŠµ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„ë¥¼ ë¹ ë¥´ê²Œ ì™„ë£Œí–ˆìœ¼ë©°, ìœ ë¨¸ê°ê°ì„ ë°œíœ˜í•´ ì†Œí†µë‹¨ì ˆì„ ê·¹ë³µí•˜ë©° ë°ì´í„° ì´ê´€ ì „ëµ ìˆ˜ë¦½ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.',\n",
       "   'í•´ë‹¹ ì§ì›ì€ AI ëª¨ë¸ í•™ìŠµ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìœ¼ë‚˜, ì‚¬ìš©ì ë°ì´í„° ì´ê´€ ì „ëµ ìˆ˜ë¦½ ê³¼ì •ì—ì„œ ê°œì¸ì£¼ì˜ì  ì„±í–¥ê³¼ ì±…ì„ê° ê²°ì—¬ê°€ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤.'],\n",
       "  'ê°•ì ': ['í•´ë‹¹ ì§ì›ì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” íƒœë„ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ë©°, ëª©í‘œì§€í–¥ì ì´ê³  ëŠ¥ë™ì ì¸ ì ‘ê·¼ ë°©ì‹ì„ í†µí•´ AI ëª¨ë¸ í•™ìŠµ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ìœ ë¨¸ê°ê°ì„ ë°œíœ˜í•˜ì—¬ ì†Œí†µì˜ ì¥ë²½ì„ ê·¹ë³µí•˜ëŠ” ëŠ¥ë ¥ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.'],\n",
       "  'ìš°ë ¤': ['ê°œì¸ì£¼ì˜ì  ì„±í–¥ê³¼ ì±…ì„ê° ê²°ì—¬ê°€ ì‚¬ìš©ì ë°ì´í„° ì´ê´€ ì „ëµ ìˆ˜ë¦½ ê³¼ì •ì—ì„œ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë¶€ë¶„ì€ íŒ€ì˜ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ê°œì„ ì´ í•„ìš”í•˜ë©°, í˜‘ì—…ê³¼ ì±…ì„ê°ì„ ê°•í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë°œì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'],\n",
       "  'í˜‘ì—…ê´€ì°°': ['í•´ë‹¹ ì§ì›ì€ ëª©í‘œì§€í–¥ì ì´ê³  ëŠ¥ë™ì ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì¶”ì§„í•˜ë©°, ìœ ë¨¸ë¥¼ í†µí•´ íŒ€ ë‚´ ì†Œí†µì„ ì›í™œí•˜ê²Œ í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ì¼ë¶€ ìƒí™©ì—ì„œëŠ” ê°œì¸ì£¼ì˜ì  íƒœë„ê°€ ë‚˜íƒ€ë‚˜ë©°, íŒ€ì˜ ê³µë™ ëª©í‘œì— ëŒ€í•œ ì±…ì„ê°ì´ ë¶€ì¡±í•œ ê²ƒìœ¼ë¡œ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤.']}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì™„ì „íˆ ì‘ë™í•˜ëŠ” ë¶„ê¸°ë³„ í…Œì´ë¸” ì €ì¥ ì‹œìŠ¤í…œ\n",
    "# ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ í•¨ìˆ˜ë“¤ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ì„œ DB ì €ì¥ ë¶€ë¶„ë§Œ ìˆ˜ì •\n",
    "\n",
    "from sqlalchemy import text\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict\n",
    "\n",
    "# =============================================================================\n",
    "# ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ í•¨ìˆ˜ë“¤ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def complete_data_mapping_agent_working(state: Dict, engine) -> Dict:\n",
    "    \"\"\"ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ ë°ì´í„° ë§¤í•‘ ì—ì´ì „íŠ¸ (ì´ë¦„ë§Œ ë³€ê²½)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        period_id = int(state[\"ë¶„ê¸°\"])\n",
    "        target_emp_no = state[\"í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ\"]\n",
    "        \n",
    "        if not target_emp_no:\n",
    "    \n",
    "            raise ValueError(\"í‰ê°€ë°›ëŠ”ì‚¬ë²ˆì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "        print(f\"[CompleteDataMappingAgent] {target_emp_no}: ë°ì´í„° ë§¤í•‘ ì‹œì‘ (ë¶„ê¸°: {period_id})\")\n",
    "\n",
    "        # 1. ë™ë£Œ í‰ê°€ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ\n",
    "        peer_evals = fetch_peer_evaluations_for_target(engine, period_id, target_emp_no)\n",
    "        \n",
    "        if not peer_evals:\n",
    "            print(f\"[CompleteDataMappingAgent] {target_emp_no}: í‰ê°€ ë°ì´í„° ì—†ìŒ\")\n",
    "            for field in [\"í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸\", \"ë¹„ì¤‘\", \"í‚¤ì›Œë“œëª¨ìŒ\", \"êµ¬ì²´ì ì—…ë¬´ë‚´ìš©\", \"ì„±ê³¼ì§€í‘œID_ë¦¬ìŠ¤íŠ¸\"]:\n",
    "                state[field] = []\n",
    "            for field in [\"ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤\", \"ê°•ì \", \"ìš°ë ¤\", \"í˜‘ì—…ê´€ì°°\"]:\n",
    "                state[field] = []\n",
    "            state[\"_weighted_analysis\"] = {}\n",
    "            return state\n",
    "\n",
    "        peer_eval_ids = [pe[\"peer_evaluation_id\"] for pe in peer_evals]\n",
    "        print(f\"[CompleteDataMappingAgent] {target_emp_no}: {len(peer_evals)}ê°œ í‰ê°€ ë°œê²¬\")\n",
    "\n",
    "        # 2. ê¸°ë³¸ í‰ê°€ ì •ë³´ ë§¤í•‘\n",
    "        state[\"í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸\"] = [pe[\"evaluator_emp_no\"] for pe in peer_evals]\n",
    "        state[\"ë¹„ì¤‘\"] = [pe[\"weight\"] for pe in peer_evals]\n",
    "\n",
    "        # 3. í‚¤ì›Œë“œ ëª¨ìŒ ì¡°íšŒ ë° ë§¤í•‘\n",
    "        keyword_map = fetch_keywords_for_peer_evaluations(engine, peer_eval_ids)\n",
    "        state[\"í‚¤ì›Œë“œëª¨ìŒ\"] = [\n",
    "            \", \".join(keyword_map.get(pid, [])) if keyword_map.get(pid) else \"\"\n",
    "            for pid in peer_eval_ids\n",
    "        ]\n",
    "\n",
    "        # 4. ì—…ë¬´ ë‚´ìš© ì¡°íšŒ ë° ë§¤í•‘\n",
    "        task_map = fetch_tasks_for_peer_evaluations_fixed(engine, peer_eval_ids)\n",
    "        all_task_ids = [tid for tids in task_map.values() for tid in tids]\n",
    "        summary_map = fetch_task_summaries_fixed(engine, period_id, all_task_ids) if all_task_ids else {}\n",
    "        \n",
    "        state[\"êµ¬ì²´ì ì—…ë¬´ë‚´ìš©\"] = []\n",
    "        for pid in peer_eval_ids:\n",
    "            if pid in task_map and task_map[pid]:\n",
    "                first_task_id = task_map[pid][0]\n",
    "                summary = summary_map.get(first_task_id, \"\")\n",
    "                state[\"êµ¬ì²´ì ì—…ë¬´ë‚´ìš©\"].append(summary)\n",
    "            else:\n",
    "                state[\"êµ¬ì²´ì ì—…ë¬´ë‚´ìš©\"].append(\"\")\n",
    "\n",
    "        # 5. ì„±ê³¼ì§€í‘œID_ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "        state[\"ì„±ê³¼ì§€í‘œID_ë¦¬ìŠ¤íŠ¸\"] = [\"1\"] * len(peer_evals)\n",
    "\n",
    "        # 6. ê¸°íƒ€ í•„ë“œë“¤ ì´ˆê¸°í™”\n",
    "        state[\"ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤\"] = []\n",
    "        state[\"ê°•ì \"] = []\n",
    "        state[\"ìš°ë ¤\"] = []\n",
    "        state[\"í˜‘ì—…ê´€ì°°\"] = []\n",
    "        state[\"_weighted_analysis\"] = {}\n",
    "        \n",
    "        print(f\"[CompleteDataMappingAgent] {target_emp_no}: ë§¤í•‘ ì™„ë£Œ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[CompleteDataMappingAgent] {target_emp_no}: ë§¤í•‘ ì‹¤íŒ¨ - {str(e)}\")\n",
    "        for field in [\"í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸\", \"ë¹„ì¤‘\", \"í‚¤ì›Œë“œëª¨ìŒ\", \"êµ¬ì²´ì ì—…ë¬´ë‚´ìš©\", \"ì„±ê³¼ì§€í‘œID_ë¦¬ìŠ¤íŠ¸\"]:\n",
    "            state[field] = []\n",
    "        for field in [\"ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤\", \"ê°•ì \", \"ìš°ë ¤\", \"í˜‘ì—…ê´€ì°°\"]:\n",
    "            state[field] = []\n",
    "        state[\"_weighted_analysis\"] = {}\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def simple_context_generation_agent_working(state: Dict, llm) -> Dict:\n",
    "    \"\"\"ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ ë§¥ë½ ìƒì„± ì—ì´ì „íŠ¸\"\"\"\n",
    "    \n",
    "    from langchain.prompts import ChatPromptTemplate\n",
    "    \n",
    "    employee_id = state[\"í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ\"]\n",
    "    print(f\"[SimpleContextAgent] {employee_id}: ë¬¸ì¥ ìƒì„± ì‹œì‘\")\n",
    "    \n",
    "    if not state.get(\"í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸\", []):\n",
    "        print(f\"[SimpleContextAgent] {employee_id}: í‰ê°€ ë°ì´í„° ì—†ìŒ\")\n",
    "        state[\"ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤\"] = []\n",
    "        return state\n",
    "    \n",
    "    detailed_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ë™ë£Œí‰ê°€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°œì¸ ì´ë¦„ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ê³  'ë™ë£Œ' ë˜ëŠ” 'í•´ë‹¹ ì§ì›'ì´ë¼ëŠ” í‘œí˜„ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\"),\n",
    "        (\"human\", \"\"\"ë‹¤ìŒ í‚¤ì›Œë“œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì—…ë¬´ ìƒí™©ì—ì„œì˜ í‰ê°€ ë¬¸ì¥ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "í‚¤ì›Œë“œ: {keywords}\n",
    "ì—…ë¬´ ìƒí™©: {work_situation}\n",
    "í‰ê°€ ë¹„ì¤‘: {weight}\n",
    "\n",
    "ì¤‘ìš”: ê°œì¸ ì´ë¦„, ì‚¬ë²ˆ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€. 'ë™ë£Œ', 'í•´ë‹¹ ì§ì›' ë“± ì¼ë°˜ì  í‘œí˜„ë§Œ ì‚¬ìš©.\n",
    "ì¶œë ¥: êµ¬ì²´ì ì¸ ì—…ë¬´ ìƒí™©ê³¼ ì—°ê²°ëœ í‰ê°€ ë¬¸ì¥ë§Œ ë°˜í™˜ (150ì ì´ë‚´)\n",
    "\"\"\")\n",
    "    ])\n",
    "    \n",
    "    ìš”ì•½ë¬¸ì¥ë“¤ = []\n",
    "    \n",
    "    for i in range(len(state[\"í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸\"])):\n",
    "        í‚¤ì›Œë“œ = state[\"í‚¤ì›Œë“œëª¨ìŒ\"][i] if i < len(state[\"í‚¤ì›Œë“œëª¨ìŒ\"]) else \"\"\n",
    "        ì—…ë¬´ë‚´ìš© = state[\"êµ¬ì²´ì ì—…ë¬´ë‚´ìš©\"][i] if i < len(state[\"êµ¬ì²´ì ì—…ë¬´ë‚´ìš©\"]) else \"\"\n",
    "        ë¹„ì¤‘ = state[\"ë¹„ì¤‘\"][i] if i < len(state[\"ë¹„ì¤‘\"]) else 1\n",
    "        \n",
    "        try:\n",
    "            work_situation = ì—…ë¬´ë‚´ìš©[:100] + \"...\" if len(ì—…ë¬´ë‚´ìš©) > 100 else ì—…ë¬´ë‚´ìš©\n",
    "            \n",
    "            messages = detailed_prompt.format_messages(\n",
    "                keywords=í‚¤ì›Œë“œ,\n",
    "                work_situation=work_situation,\n",
    "                weight=ë¹„ì¤‘\n",
    "            )\n",
    "            \n",
    "            response = llm(messages)\n",
    "            ìš”ì•½ë¬¸ì¥ = response.content.strip()\n",
    "            \n",
    "            ìš”ì•½ë¬¸ì¥ = ìš”ì•½ë¬¸ì¥.replace(\"{evaluated_name}\", \"ë™ë£Œ\")\n",
    "            ìš”ì•½ë¬¸ì¥ = ìš”ì•½ë¬¸ì¥.replace(\"{evaluator_name}\", \"ë™ë£Œ\")\n",
    "            \n",
    "            ìš”ì•½ë¬¸ì¥ë“¤.append(ìš”ì•½ë¬¸ì¥)\n",
    "            print(f\"[SimpleContextAgent] {i+1}ë²ˆì§¸ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            fallback = f\"ì—…ë¬´ ì§„í–‰ ê³¼ì •ì—ì„œ ë™ë£Œê°€ ë‹¤ì–‘í•œ íŠ¹ì„±ì„ ë³´ì„\"\n",
    "            ìš”ì•½ë¬¸ì¥ë“¤.append(fallback)\n",
    "            print(f\"[SimpleContextAgent] {i+1}ë²ˆì§¸ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ë¬¸ì¥ ì‚¬ìš©: {str(e)}\")\n",
    "    \n",
    "    state[\"ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤\"] = ìš”ì•½ë¬¸ì¥ë“¤\n",
    "    print(f\"[SimpleContextAgent] {employee_id}: ì´ {len(ìš”ì•½ë¬¸ì¥ë“¤)}ê°œ ë¬¸ì¥ ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def weighted_analysis_agent_working(state: Dict) -> Dict:\n",
    "    \"\"\"ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ ê°€ì¤‘ì¹˜ ë¶„ì„ ì—ì´ì „íŠ¸\"\"\"\n",
    "    \n",
    "    employee_id = state[\"í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ\"]\n",
    "    print(f\"[WeightedAnalysisAgent] {employee_id}: ê°€ì¤‘ì¹˜ ë¶„ì„ ì‹œì‘\")\n",
    "    \n",
    "    positive_keywords, negative_keywords = get_predefined_keywords()\n",
    "    \n",
    "    if not state.get(\"í‚¤ì›Œë“œëª¨ìŒ\", []):\n",
    "        print(f\"[WeightedAnalysisAgent] {employee_id}: í‚¤ì›Œë“œ ë°ì´í„° ì—†ìŒ, ìŠ¤í‚µ\")\n",
    "        state[\"_weighted_analysis\"] = _create_empty_analysis()\n",
    "        return state\n",
    "    \n",
    "    weighted_scores = defaultdict(float)\n",
    "    keyword_frequency = defaultdict(int)\n",
    "    total_weight = sum(state.get(\"ë¹„ì¤‘\", []))\n",
    "    \n",
    "    for i in range(len(state[\"í‚¤ì›Œë“œëª¨ìŒ\"])):\n",
    "        keywords = [k.strip() for k in state[\"í‚¤ì›Œë“œëª¨ìŒ\"][i].split(',') if k.strip()]\n",
    "        weight = state[\"ë¹„ì¤‘\"][i] if i < len(state[\"ë¹„ì¤‘\"]) else 1\n",
    "        \n",
    "        for keyword in keywords:\n",
    "            keyword_frequency[keyword] += 1\n",
    "            score = get_keyword_score(keyword, positive_keywords, negative_keywords, {})\n",
    "            weighted_scores[keyword] += score * weight\n",
    "    \n",
    "    if total_weight > 0:\n",
    "        for keyword in weighted_scores:\n",
    "            weighted_scores[keyword] = weighted_scores[keyword] / total_weight\n",
    "    \n",
    "    positive_keywords_result = {k: v for k, v in weighted_scores.items() if v > 0}\n",
    "    negative_keywords_result = {k: v for k, v in weighted_scores.items() if v < 0}\n",
    "    \n",
    "    top_positive = dict(sorted(positive_keywords_result.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "    top_negative = dict(sorted(negative_keywords_result.items(), key=lambda x: x[1])[:3])\n",
    "    \n",
    "    analysis_result = {\n",
    "        \"weighted_scores\": dict(weighted_scores),\n",
    "        \"keyword_frequency\": dict(keyword_frequency),\n",
    "        \"top_positive\": top_positive,\n",
    "        \"top_negative\": top_negative,\n",
    "        \"total_evaluations\": len(state.get(\"í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸\", [])),\n",
    "        \"average_weight\": total_weight / len(state[\"ë¹„ì¤‘\"]) if state.get(\"ë¹„ì¤‘\") else 0,\n",
    "        \"total_weight\": total_weight,\n",
    "        \"new_keywords_analyzed\": 0\n",
    "    }\n",
    "    \n",
    "    state[\"_weighted_analysis\"] = analysis_result\n",
    "    \n",
    "    print(f\"[WeightedAnalysisAgent] {employee_id}: ë¶„ì„ ì™„ë£Œ\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "def improved_feedback_generation_agent_working(state: Dict, llm) -> Dict:\n",
    "    \"\"\"ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ í”¼ë“œë°± ìƒì„± ì—ì´ì „íŠ¸\"\"\"\n",
    "    \n",
    "    employee_id = state[\"í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ\"]\n",
    "    print(f\"[ImprovedFeedbackGenerationAgent] {employee_id}: í”¼ë“œë°± ìƒì„± ì‹œì‘\")\n",
    "    \n",
    "    analysis = state.get(\"_weighted_analysis\", {})\n",
    "    \n",
    "    try:\n",
    "        top_sentences = _get_top_sentences_working(state)\n",
    "        feedback = generate_final_feedback_working(llm, analysis, top_sentences, employee_id)\n",
    "        \n",
    "        state[\"ê°•ì \"] = [feedback[\"ê°•ì \"]]\n",
    "        state[\"ìš°ë ¤\"] = [feedback[\"ìš°ë ¤\"]]\n",
    "        state[\"í˜‘ì—…ê´€ì°°\"] = [feedback[\"í˜‘ì—…ê´€ì°°\"]]\n",
    "        \n",
    "        print(f\"[ImprovedFeedbackGenerationAgent] {employee_id}: í”¼ë“œë°± ìƒì„± ì„±ê³µ!\")\n",
    "        \n",
    "        if \"_weighted_analysis\" in state:\n",
    "            del state[\"_weighted_analysis\"]\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ImprovedFeedbackGenerationAgent] {employee_id}: í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨ - {str(e)}\")\n",
    "        \n",
    "        keywords = \" \".join(state.get(\"í‚¤ì›Œë“œëª¨ìŒ\", []))\n",
    "        \n",
    "        state[\"ê°•ì \"] = [f\"ë™ë£Œ í‰ê°€ì—ì„œ ë‚˜íƒ€ë‚œ {keywords.split(',')[0] if keywords else 'í˜‘ì—…'} ë“±ì˜ ê¸ì •ì  íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ íŒ€ì— ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤\"]\n",
    "        state[\"ìš°ë ¤\"] = [\"ì§€ì†ì ì¸ ì„±ì¥ì„ ìœ„í•´ ì¼ë¶€ ì˜ì—­ì—ì„œ ì¶”ê°€ì ì¸ ê°œë°œê³¼ ê°œì„ ì´ í•„ìš”í•œ ìƒí™©ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤\"]\n",
    "        state[\"í˜‘ì—…ê´€ì°°\"] = [\"íŒ€ ë‚´ì—ì„œì˜ ì—­í•  ìˆ˜í–‰ê³¼ ë™ë£Œë“¤ê³¼ì˜ ê´€ê³„ì—ì„œ ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ëª¨ìŠµì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤\"]\n",
    "        \n",
    "        if \"_weighted_analysis\" in state:\n",
    "            del state[\"_weighted_analysis\"]\n",
    "        \n",
    "        return state\n",
    "\n",
    "# =============================================================================\n",
    "# í—¬í¼ í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def _get_top_sentences_working(state):\n",
    "    \"\"\"ë¹„ì¤‘ ë†’ì€ ìˆœìœ¼ë¡œ ìš”ì•½ ë¬¸ì¥ ì •ë ¬\"\"\"\n",
    "    if not state.get(\"ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤\", []) or not state.get(\"ë¹„ì¤‘\", []):\n",
    "        return []\n",
    "    \n",
    "    sentences_with_weights = list(zip(state[\"ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤\"], state[\"ë¹„ì¤‘\"]))\n",
    "    sorted_sentences = sorted(sentences_with_weights, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [s[0] for s in sorted_sentences[:3]]\n",
    "\n",
    "def _create_empty_analysis():\n",
    "    \"\"\"ë¹ˆ ë¶„ì„ ê²°ê³¼ ìƒì„±\"\"\"\n",
    "    return {\n",
    "        \"weighted_scores\": {},\n",
    "        \"keyword_frequency\": {},\n",
    "        \"top_positive\": {},\n",
    "        \"top_negative\": {},\n",
    "        \"total_evaluations\": 0,\n",
    "        \"average_weight\": 0,\n",
    "        \"total_weight\": 0,\n",
    "        \"new_keywords_analyzed\": 0\n",
    "    }\n",
    "\n",
    "def generate_final_feedback_working(llm, analysis: Dict, top_sentences: List[str], employee_id: str) -> Dict[str, str]:\n",
    "    \"\"\"ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ í”¼ë“œë°± ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "    from langchain.prompts import ChatPromptTemplate\n",
    "    \n",
    "    top_positive = analysis.get(\"top_positive\", {})\n",
    "    top_negative = analysis.get(\"top_negative\", {})\n",
    "    total_evals = analysis.get(\"total_evaluations\", 0)\n",
    "    avg_weight = analysis.get(\"average_weight\", 0)\n",
    "    \n",
    "    positive_text = \", \".join([f\"{k}({v:.2f})\" for k, v in list(top_positive.items())[:3]])\n",
    "    negative_text = \", \".join([f\"{k}({v:.2f})\" for k, v in list(top_negative.items())[:2]])\n",
    "    sentences_text = \"\\n\".join([f\"- {s}\" for s in top_sentences[:3]])\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ë™ë£Œí‰ê°€ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê°œì¸ ì´ë¦„ì´ë‚˜ ì‚¬ë²ˆì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\"),\n",
    "        (\"human\", \"\"\"ë‹¤ìŒ ë™ë£Œí‰ê°€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì¡°í™”ëœ í”¼ë“œë°±ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "=== ë¶„ì„ ë°ì´í„° ===\n",
    "ì´ í‰ê°€ ìˆ˜: {total_evals}ê°œ\n",
    "í‰ê·  ë¹„ì¤‘: {avg_weight:.1f}\n",
    "\n",
    "ì£¼ìš” ê¸ì • í‚¤ì›Œë“œ: {positive_keywords}\n",
    "ì£¼ìš” ë¶€ì • í‚¤ì›Œë“œ: {negative_keywords}\n",
    "\n",
    "í•µì‹¬ í‰ê°€ ë¬¸ì¥ë“¤:\n",
    "{key_sentences}\n",
    "\n",
    "=== ì¶œë ¥ í˜•ì‹ (JSON) ===\n",
    "{{\n",
    "  \"ê°•ì \": \"êµ¬ì²´ì ì´ê³  ê· í˜•ì¡íŒ ê°•ì  ì„œìˆ \",\n",
    "  \"ìš°ë ¤\": \"ê±´ì„¤ì ì´ê³  ê°œì„ ì§€í–¥ì ì¸ ìš°ë ¤ì‚¬í•­\",\n",
    "  \"í˜‘ì—…ê´€ì°°\": \"ê°ê´€ì ì´ê³  í–‰ë™ì¤‘ì‹¬ì˜ í˜‘ì—… ê´€ì°°\"\n",
    "}}\n",
    "\n",
    "ì¤‘ìš”: ê°œì¸ ì´ë¦„, ì‚¬ë²ˆ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€. 'ë™ë£Œ', 'í•´ë‹¹ ì§ì›' ë“± ì¼ë°˜ì  í‘œí˜„ë§Œ ì‚¬ìš©.\n",
    "\"\"\")\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        messages = prompt.format_messages(\n",
    "            total_evals=total_evals,\n",
    "            avg_weight=avg_weight,\n",
    "            positive_keywords=positive_text or \"ë°ì´í„° ë¶€ì¡±\",\n",
    "            negative_keywords=negative_text or \"íŠ¹ë³„í•œ ìš°ë ¤ì‚¬í•­ ì—†ìŒ\",\n",
    "            key_sentences=sentences_text or \"êµ¬ì²´ì  í‰ê°€ ë‚´ìš© ë¶€ì¡±\"\n",
    "        )\n",
    "        \n",
    "        response = llm(messages)\n",
    "        response_text = response.content.strip()\n",
    "        \n",
    "        import json\n",
    "        import re\n",
    "        \n",
    "        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_text = json_match.group()\n",
    "            feedback_dict = json.loads(json_text)\n",
    "            \n",
    "            result = {\n",
    "                \"ê°•ì \": feedback_dict.get(\"ê°•ì \", \"ë™ë£Œë“¤ë¡œë¶€í„° ê¸ì •ì ì¸ í‰ê°€ë¥¼ ë°›ê³  ìˆìŠµë‹ˆë‹¤\"),\n",
    "                \"ìš°ë ¤\": feedback_dict.get(\"ìš°ë ¤\", \"ì§€ì†ì ì¸ ì„±ì¥ì„ ìœ„í•œ ê°œì„  ì˜ì—­ì´ ìˆìŠµë‹ˆë‹¤\"),  \n",
    "                \"í˜‘ì—…ê´€ì°°\": feedback_dict.get(\"í˜‘ì—…ê´€ì°°\", \"íŒ€ ë‚´ì—ì„œ í˜‘ì—…ì— ì°¸ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤\")\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            raise ValueError(\"JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[FeedbackGeneration] LLM í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "        \n",
    "        if top_positive:\n",
    "            positive_keywords = list(top_positive.keys())[:2]\n",
    "            ê°•ì  = f\"ë™ë£Œ í‰ê°€ì—ì„œ {', '.join(positive_keywords)} ë“±ì˜ ê¸ì •ì  íŠ¹ì„±ì´ ë†’ê²Œ í‰ê°€ë˜ê³  ìˆìŠµë‹ˆë‹¤\"\n",
    "        else:\n",
    "            ê°•ì  = \"ë™ë£Œë“¤ê³¼ì˜ í˜‘ì—…ì—ì„œ ë‹¤ì–‘í•œ ê¸ì •ì  ì¸¡ë©´ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤\"\n",
    "        \n",
    "        if top_negative:\n",
    "            negative_keywords = list(top_negative.keys())[:1] \n",
    "            ìš°ë ¤ = f\"{negative_keywords[0]} ë“±ì˜ ì˜ì—­ì—ì„œ ì¶”ê°€ì ì¸ ê°œì„ ê³¼ ë°œì „ì´ í•„ìš”í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤\"\n",
    "        else:\n",
    "            ìš°ë ¤ = \"ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì´ë‚˜ ì§€ì†ì ì¸ ì„±ì¥ì„ ìœ„í•œ ë…¸ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤\"\n",
    "        \n",
    "        í˜‘ì—…ê´€ì°° = f\"ì´ {total_evals}ëª…ì˜ ë™ë£Œë¡œë¶€í„° í‰ê°€ë°›ì•˜ìœ¼ë©° íŒ€ ë‚´ì—ì„œì˜ ì—­í• ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤\"\n",
    "        \n",
    "        return {\n",
    "            \"ê°•ì \": ê°•ì ,\n",
    "            \"ìš°ë ¤\": ìš°ë ¤,\n",
    "            \"í˜‘ì—…ê´€ì°°\": í˜‘ì—…ê´€ì°°\n",
    "        }\n",
    "\n",
    "# =============================================================================\n",
    "# ë¶„ê¸°ë³„ DB ì €ì¥ ë¡œì§ë§Œ ìƒˆë¡œ ì¶”ê°€\n",
    "# =============================================================================\n",
    "\n",
    "def database_storage_agent_period_based(state: Dict, engine) -> Dict:\n",
    "    \"\"\"ë¶„ê¸°ë³„ë¡œ ë‹¤ë¥¸ í…Œì´ë¸”ì— ì €ì¥í•˜ëŠ” DB ì €ì¥ ì—ì´ì „íŠ¸\"\"\"\n",
    "    employee_id = state[\"í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ\"]\n",
    "    period_id = int(state[\"ë¶„ê¸°\"])\n",
    "    \n",
    "    print(f\"[DatabaseStorageAgent] {employee_id}: ë¶„ê¸°ë³„ DB ì €ì¥ ì‹œì‘ (ë¶„ê¸°: {period_id})\")\n",
    "    \n",
    "    try:\n",
    "        ai_peer_talk_summary = _format_peer_review_result(state)\n",
    "        \n",
    "        print(f\"[DatabaseStorageAgent] ì €ì¥ë  ë‚´ìš©:\")\n",
    "        print(ai_peer_talk_summary)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        if period_id == 4:\n",
    "            print(f\"[DatabaseStorageAgent] ë¶„ê¸° 4 â†’ final_evaluation_reports.ai_peer_talk_summaryì— ì €ì¥\")\n",
    "        else:\n",
    "            print(f\"[DatabaseStorageAgent] ë¶„ê¸° {period_id} â†’ feedback_reports.ai_peer_talk_summaryì— ì €ì¥\")\n",
    "        \n",
    "        success = save_feedback_to_db_by_period(engine, state)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"[DatabaseStorageAgent] {employee_id}: DB ì €ì¥ ì„±ê³µ!\")\n",
    "        else:\n",
    "            print(f\"[DatabaseStorageAgent] {employee_id}: DB ì €ì¥ ì‹¤íŒ¨\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[DatabaseStorageAgent] {employee_id}: DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ - {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    return state\n",
    "\n",
    "def _format_peer_review_result(state: Dict) -> str:\n",
    "    \"\"\"ê°•ì , ìš°ë ¤, í˜‘ì—…ê´€ì°°ì„ ì¤„ë°”ê¿ˆ í¬í•¨í•œ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…\"\"\"\n",
    "    ê°•ì  = state[\"ê°•ì \"][0] if state.get(\"ê°•ì \") and len(state[\"ê°•ì \"]) > 0 else \"ë™ë£Œë“¤ë¡œë¶€í„° ê¸ì •ì ì¸ í‰ê°€ë¥¼ ë°›ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "    ìš°ë ¤ = state[\"ìš°ë ¤\"][0] if state.get(\"ìš°ë ¤\") and len(state[\"ìš°ë ¤\"]) > 0 else \"ì§€ì†ì ì¸ ì„±ì¥ì„ ìœ„í•œ ê°œì„  ì˜ì—­ì´ ìˆìŠµë‹ˆë‹¤.\"\n",
    "    í˜‘ì—…ê´€ì°° = state[\"í˜‘ì—…ê´€ì°°\"][0] if state.get(\"í˜‘ì—…ê´€ì°°\") and len(state[\"í˜‘ì—…ê´€ì°°\"]) > 0 else \"íŒ€ ë‚´ì—ì„œ í˜‘ì—…ì— ì°¸ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    peer_review_result = f\"\"\"ê°•ì : {ê°•ì }\n",
    "ìš°ë ¤: {ìš°ë ¤}\n",
    "í˜‘ì—…ê´€ì°°: {í˜‘ì—…ê´€ì°°}\"\"\"\n",
    "    \n",
    "    return peer_review_result\n",
    "\n",
    "def _get_team_evaluation_id(engine, period_id: int, emp_no: str) -> int:\n",
    "    \"\"\"í•´ë‹¹ ë¶„ê¸°ì™€ ì§ì›ì— í•´ë‹¹í•˜ëŠ” team_evaluation_id ì¡°íšŒ\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            query = text(\"\"\"\n",
    "                SELECT te.team_evaluation_id\n",
    "                FROM team_evaluations te\n",
    "                JOIN teams t ON te.team_id = t.team_id\n",
    "                JOIN employees e ON e.team_id = t.team_id\n",
    "                WHERE te.period_id = :period_id\n",
    "                  AND e.emp_no = :emp_no\n",
    "                LIMIT 1\n",
    "            \"\"\")\n",
    "            \n",
    "            result = conn.execute(query, {\n",
    "                \"period_id\": period_id,\n",
    "                \"emp_no\": emp_no\n",
    "            }).fetchone()\n",
    "            \n",
    "            if result:\n",
    "                return dict(result._mapping)[\"team_evaluation_id\"]\n",
    "            else:\n",
    "                print(f\"[DatabaseStorageAgent] team_evaluation_id ì¡°íšŒ ì‹¤íŒ¨: period_id={period_id}, emp_no={emp_no}\")\n",
    "                return None\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"[DatabaseStorageAgent] team_evaluation_id ì¡°íšŒ ì˜¤ë¥˜: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def save_feedback_to_db_by_period(engine, state: Dict) -> bool:\n",
    "    \"\"\"ë¶„ê¸°ì— ë”°ë¼ ì ì ˆí•œ í…Œì´ë¸”ì— í”¼ë“œë°± ì €ì¥\"\"\"\n",
    "    period_id = int(state[\"ë¶„ê¸°\"])\n",
    "    emp_no = state[\"í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ\"]\n",
    "    \n",
    "    try:\n",
    "        team_eval_id = _get_team_evaluation_id(engine, period_id, emp_no)\n",
    "        if not team_eval_id:\n",
    "            print(f\"[DBì €ì¥] team_evaluation_id ì¡°íšŒ ì‹¤íŒ¨: {emp_no}\")\n",
    "            return False\n",
    "        \n",
    "        ai_peer_talk_summary = _format_peer_review_result(state)\n",
    "        \n",
    "        with engine.connect() as conn:\n",
    "            if period_id == 4:\n",
    "                # final_evaluation_reports í…Œì´ë¸”\n",
    "                check_query = text(\"\"\"\n",
    "                    SELECT final_evaluation_report_id \n",
    "                    FROM final_evaluation_reports \n",
    "                    WHERE team_evaluation_id = :team_eval_id AND emp_no = :emp_no\n",
    "                \"\"\")\n",
    "                \n",
    "                existing = conn.execute(check_query, {\n",
    "                    \"team_eval_id\": team_eval_id,\n",
    "                    \"emp_no\": emp_no\n",
    "                }).fetchone()\n",
    "                \n",
    "                if existing:\n",
    "                    update_query = text(\"\"\"\n",
    "                        UPDATE final_evaluation_reports \n",
    "                        SET ai_peer_talk_summary = :ai_peer_talk_summary,\n",
    "                            updated_at = NOW()\n",
    "                        WHERE final_evaluation_report_id = :final_evaluation_id\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    conn.execute(update_query, {\n",
    "                        \"ai_peer_talk_summary\": ai_peer_talk_summary,\n",
    "                        \"final_evaluation_id\": dict(existing._mapping)[\"final_evaluation_report_id\"]\n",
    "                    })\n",
    "                    conn.commit()\n",
    "                    print(f\"[DBì €ì¥] {emp_no}: final_evaluation_reports.ai_peer_talk_summary ì—…ë°ì´íŠ¸ ì™„ë£Œ\")\n",
    "                    \n",
    "                else:\n",
    "                    insert_query = text(\"\"\"\n",
    "                        INSERT INTO final_evaluation_reports (team_evaluation_id, emp_no, ai_peer_talk_summary, created_at, updated_at)\n",
    "                        VALUES (:team_eval_id, :emp_no, :ai_peer_talk_summary, NOW(), NOW())\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    conn.execute(insert_query, {\n",
    "                        \"team_eval_id\": team_eval_id,\n",
    "                        \"emp_no\": emp_no,\n",
    "                        \"ai_peer_talk_summary\": ai_peer_talk_summary\n",
    "                    })\n",
    "                    conn.commit()\n",
    "                    print(f\"[DBì €ì¥] {emp_no}: final_evaluation_reports.ai_peer_talk_summary ìƒˆ ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ\")\n",
    "            \n",
    "            else:\n",
    "                # feedback_reports í…Œì´ë¸”\n",
    "                check_query = text(\"\"\"\n",
    "                    SELECT feedback_report_id \n",
    "                    FROM feedback_reports \n",
    "                    WHERE team_evaluation_id = :team_eval_id AND emp_no = :emp_no\n",
    "                \"\"\")\n",
    "                \n",
    "                existing = conn.execute(check_query, {\n",
    "                    \"team_eval_id\": team_eval_id,\n",
    "                    \"emp_no\": emp_no\n",
    "                }).fetchone()\n",
    "                \n",
    "                if existing:\n",
    "                    update_query = text(\"\"\"\n",
    "                        UPDATE feedback_reports \n",
    "                        SET ai_peer_talk_summary = :ai_peer_talk_summary,\n",
    "                            updated_at = NOW()\n",
    "                        WHERE feedback_report_id = :feedback_id\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    conn.execute(update_query, {\n",
    "                        \"ai_peer_talk_summary\": ai_peer_talk_summary,\n",
    "                        \"feedback_id\": dict(existing._mapping)[\"feedback_report_id\"]\n",
    "                    })\n",
    "                    conn.commit()\n",
    "                    print(f\"[DBì €ì¥] {emp_no}: feedback_reports.ai_peer_talk_summary ì—…ë°ì´íŠ¸ ì™„ë£Œ\")\n",
    "                    \n",
    "                else:\n",
    "                    insert_query = text(\"\"\"\n",
    "                        INSERT INTO feedback_reports (team_evaluation_id, emp_no, ai_peer_talk_summary, created_at, updated_at)\n",
    "                        VALUES (:team_eval_id, :emp_no, :ai_peer_talk_summary, NOW(), NOW())\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    conn.execute(insert_query, {\n",
    "                        \"team_eval_id\": team_eval_id,\n",
    "                        \"emp_no\": emp_no,\n",
    "                        \"ai_peer_talk_summary\": ai_peer_talk_summary\n",
    "                    })\n",
    "                    conn.commit()\n",
    "                    print(f\"[DBì €ì¥] {emp_no}: feedback_reports.ai_peer_talk_summary ìƒˆ ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[DBì €ì¥] {emp_no}: ì €ì¥ ì‹¤íŒ¨ - {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# =============================================================================\n",
    "# ê¸°ì¡´ í•¨ìˆ˜ë“¤ê³¼ í˜¸í™˜ë˜ëŠ” ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš°\n",
    "# =============================================================================\n",
    "\n",
    "def create_working_langgraph_nodes(engine, llm):\n",
    "    \"\"\"ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ëŠ” ë…¸ë“œë“¤ (DB ì €ì¥ë§Œ ë¶„ê¸°ë³„ë¡œ)\"\"\"\n",
    "    \n",
    "    def safe_data_mapping_node(state: Dict) -> Dict:\n",
    "        print(\"ğŸ”„ [ì‘ë™] ë°ì´í„° ë§¤í•‘ ë…¸ë“œ ì‹œì‘...\")\n",
    "        try:\n",
    "            result = complete_data_mapping_agent_working(state, engine)\n",
    "            print(f\"   ê²°ê³¼: í‰ê°€ì {len(result.get('í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸', []))}ëª…\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ë°ì´í„° ë§¤í•‘ ì‹¤íŒ¨: {str(e)}\")\n",
    "            state[\"í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸\"] = []\n",
    "            state[\"ë¹„ì¤‘\"] = []\n",
    "            state[\"í‚¤ì›Œë“œëª¨ìŒ\"] = []\n",
    "            state[\"êµ¬ì²´ì ì—…ë¬´ë‚´ìš©\"] = []\n",
    "            return state\n",
    "    \n",
    "    def safe_context_generation_node(state: Dict) -> Dict:\n",
    "        print(\"ğŸ”„ [ì‘ë™] ë§¥ë½ ìƒì„± ë…¸ë“œ ì‹œì‘...\")\n",
    "        try:\n",
    "            result = simple_context_generation_agent_working(state, llm)\n",
    "            print(f\"   ê²°ê³¼: ë¬¸ì¥ {len(result.get('ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤', []))}ê°œ\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ë§¥ë½ ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "            state[\"ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤\"] = []\n",
    "            return state\n",
    "    \n",
    "    def safe_weighted_analysis_node(state: Dict) -> Dict:\n",
    "        print(\"ğŸ”„ [ì‘ë™] ê°€ì¤‘ì¹˜ ë¶„ì„ ë…¸ë“œ ì‹œì‘...\")\n",
    "        try:\n",
    "            result = weighted_analysis_agent_working(state)\n",
    "            analysis = result.get('_weighted_analysis', {})\n",
    "            print(f\"   ê²°ê³¼: í‚¤ì›Œë“œ {len(analysis.get('weighted_scores', {}))}ê°œ\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ê°€ì¤‘ì¹˜ ë¶„ì„ ì‹¤íŒ¨: {str(e)}\")\n",
    "            state[\"_weighted_analysis\"] = {}\n",
    "            return state\n",
    "    \n",
    "    def safe_feedback_generation_node(state: Dict) -> Dict:\n",
    "        print(\"ğŸ”„ [ì‘ë™] í”¼ë“œë°± ìƒì„± ë…¸ë“œ ì‹œì‘...\")\n",
    "        try:\n",
    "            result = improved_feedback_generation_agent_working(state, llm)\n",
    "            print(f\"   ê²°ê³¼: ê°•ì  {len(result.get('ê°•ì ', []))}, ìš°ë ¤ {len(result.get('ìš°ë ¤', []))}, í˜‘ì—…ê´€ì°° {len(result.get('í˜‘ì—…ê´€ì°°', []))}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "            state[\"ê°•ì \"] = [\"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤\"]\n",
    "            state[\"ìš°ë ¤\"] = [\"ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤\"]\n",
    "            state[\"í˜‘ì—…ê´€ì°°\"] = [\"ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„ì´ ì œí•œì ì…ë‹ˆë‹¤\"]\n",
    "            return state\n",
    "    \n",
    "    def safe_database_storage_node_period_based(state: Dict) -> Dict:\n",
    "        print(\"ğŸ”„ [ì‘ë™] ë¶„ê¸°ë³„ DB ì €ì¥ ë…¸ë“œ ì‹œì‘...\")\n",
    "        try:\n",
    "            result = database_storage_agent_period_based(state, engine)\n",
    "            print(\"   ê²°ê³¼: ë¶„ê¸°ë³„ DB ì €ì¥ ì™„ë£Œ\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ ë¶„ê¸°ë³„ DB ì €ì¥ ì‹¤íŒ¨: {str(e)}\")\n",
    "            return state\n",
    "    \n",
    "    return {\n",
    "        \"data_mapping\": safe_data_mapping_node,\n",
    "        \"context_generation\": safe_context_generation_node,\n",
    "        \"weighted_analysis\": safe_weighted_analysis_node,\n",
    "        \"feedback_generation\": safe_feedback_generation_node,\n",
    "        \"database_storage\": safe_database_storage_node_period_based\n",
    "    }\n",
    "\n",
    "def create_working_peer_evaluation_workflow(engine, llm):\n",
    "    \"\"\"ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ëŠ” ì›Œí¬í”Œë¡œìš° (ë¶„ê¸°ë³„ DB ì €ì¥ ì ìš©)\"\"\"\n",
    "    \n",
    "    from langgraph.graph import StateGraph, END\n",
    "    \n",
    "    # ë…¸ë“œ í•¨ìˆ˜ë“¤ ìƒì„±\n",
    "    nodes = create_working_langgraph_nodes(engine, llm)\n",
    "    \n",
    "    # StateGraph ìƒì„±\n",
    "    workflow = StateGraph(Dict)\n",
    "    \n",
    "    # ë…¸ë“œë“¤ ì¶”ê°€\n",
    "    workflow.add_node(\"data_mapping\", nodes[\"data_mapping\"])\n",
    "    workflow.add_node(\"context_generation\", nodes[\"context_generation\"])\n",
    "    workflow.add_node(\"weighted_analysis\", nodes[\"weighted_analysis\"])\n",
    "    workflow.add_node(\"feedback_generation\", nodes[\"feedback_generation\"])\n",
    "    workflow.add_node(\"database_storage\", nodes[\"database_storage\"])\n",
    "    \n",
    "    # ì—£ì§€ ì—°ê²° (ìˆœì°¨ ì‹¤í–‰)\n",
    "    workflow.set_entry_point(\"data_mapping\")\n",
    "    workflow.add_edge(\"data_mapping\", \"context_generation\")\n",
    "    workflow.add_edge(\"context_generation\", \"weighted_analysis\")\n",
    "    workflow.add_edge(\"weighted_analysis\", \"feedback_generation\")\n",
    "    workflow.add_edge(\"feedback_generation\", \"database_storage\")\n",
    "    workflow.add_edge(\"database_storage\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# =============================================================================\n",
    "# ì—…ë°ì´íŠ¸ëœ ì‹¤í–‰ í•¨ìˆ˜ë“¤\n",
    "# =============================================================================\n",
    "\n",
    "def create_initial_state_working(period_id: int, emp_no: str) -> Dict:\n",
    "    \"\"\"ê¸°ì¡´ ë°©ì‹ê³¼ í˜¸í™˜ë˜ëŠ” ì´ˆê¸° ìƒíƒœ ìƒì„±\"\"\"\n",
    "    return {\n",
    "        \"ë¶„ê¸°\": str(period_id),\n",
    "        \"í‰ê°€ë°›ëŠ”ì‚¬ë²ˆ\": emp_no,\n",
    "        \"í‰ê°€í•˜ëŠ”ì‚¬ë²ˆ_ë¦¬ìŠ¤íŠ¸\": [],\n",
    "        \"ì„±ê³¼ì§€í‘œID_ë¦¬ìŠ¤íŠ¸\": [],\n",
    "        \"ë¹„ì¤‘\": [],\n",
    "        \"í‚¤ì›Œë“œëª¨ìŒ\": [],\n",
    "        \"êµ¬ì²´ì ì—…ë¬´ë‚´ìš©\": [],\n",
    "        \"ë™ë£Œí‰ê°€ìš”ì•½ì¤„ê¸€ë“¤\": [],\n",
    "        \"ê°•ì \": [],\n",
    "        \"ìš°ë ¤\": [],\n",
    "        \"í˜‘ì—…ê´€ì°°\": [],\n",
    "        \"_weighted_analysis\": {}\n",
    "    }\n",
    "\n",
    "def check_feedback_reports_by_period_working(engine, period_id: int, emp_no: str) -> bool:\n",
    "    \"\"\"ë¶„ê¸°ë³„ë¡œ í•´ë‹¹ ì§ì›ì˜ í”¼ë“œë°± ë³´ê³ ì„œê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            if period_id == 4:\n",
    "                query = text(\"\"\"\n",
    "                    SELECT fer.final_evaluation_report_id\n",
    "                    FROM final_evaluation_reports fer\n",
    "                    JOIN team_evaluations te ON fer.team_evaluation_id = te.team_evaluation_id\n",
    "                    WHERE te.period_id = :period_id\n",
    "                      AND fer.emp_no = :emp_no\n",
    "                      AND fer.ai_peer_talk_summary IS NOT NULL\n",
    "                      AND fer.ai_peer_talk_summary != ''\n",
    "                    LIMIT 1\n",
    "                \"\"\")\n",
    "            else:\n",
    "                query = text(\"\"\"\n",
    "                    SELECT fr.feedback_report_id\n",
    "                    FROM feedback_reports fr\n",
    "                    JOIN team_evaluations te ON fr.team_evaluation_id = te.team_evaluation_id\n",
    "                    WHERE te.period_id = :period_id\n",
    "                      AND fr.emp_no = :emp_no\n",
    "                      AND fr.ai_peer_talk_summary IS NOT NULL\n",
    "                      AND fr.ai_peer_talk_summary != ''\n",
    "                    LIMIT 1\n",
    "                \"\"\")\n",
    "            \n",
    "            result = conn.execute(query, {\n",
    "                \"period_id\": period_id,\n",
    "                \"emp_no\": emp_no\n",
    "            }).fetchone()\n",
    "            \n",
    "            return result is not None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í”¼ë“œë°± ë³´ê³ ì„œ í™•ì¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def run_single_employee_analysis_working(engine, llm, period_id: int, emp_no: str) -> Dict:\n",
    "    \"\"\"ë‹¨ì¼ ì§ì› ë™ë£Œí‰ê°€ ë¶„ì„ ì‹¤í–‰ (ê¸°ì¡´ í•¨ìˆ˜ë“¤ ì‚¬ìš©)\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ¯ {emp_no} {period_id}ë¶„ê¸° ë™ë£Œí‰ê°€ ë¶„ì„ ì‹œì‘\")\n",
    "    \n",
    "    try:\n",
    "        # ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ ì›Œí¬í”Œë¡œìš° ì‚¬ìš©\n",
    "        workflow = create_working_peer_evaluation_workflow(engine, llm)\n",
    "        print(f\"ğŸ”„ ê¸°ì¡´ ê²€ì¦ëœ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰...\")\n",
    "        \n",
    "        # ì´ˆê¸° ìƒíƒœ ìƒì„±\n",
    "        initial_state = create_initial_state_working(period_id, emp_no)\n",
    "        \n",
    "        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "        result = workflow.invoke(initial_state)\n",
    "        \n",
    "        # ê²°ê³¼ ê²€ì¦\n",
    "        if (result and result.get('ê°•ì ') and result.get('ìš°ë ¤') and result.get('í˜‘ì—…ê´€ì°°')):\n",
    "            print(f\"âœ… {emp_no} ë¶„ì„ ì„±ê³µ!\")\n",
    "            print(f\"   ê°•ì : {result['ê°•ì '][0][:50]}...\")\n",
    "            print(f\"   ìš°ë ¤: {result['ìš°ë ¤'][0][:50]}...\")\n",
    "            print(f\"   í˜‘ì—…ê´€ì°°: {result['í˜‘ì—…ê´€ì°°'][0][:50]}...\")\n",
    "            \n",
    "            # ì €ì¥ í…Œì´ë¸” í™•ì¸\n",
    "            table_name = \"final_evaluation_reports\" if period_id == 4 else \"feedback_reports\"\n",
    "            print(f\"   ğŸ’¾ ì €ì¥ í…Œì´ë¸”: {table_name}.ai_peer_talk_summary\")\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            print(f\"âš ï¸ {emp_no} ë¶„ì„ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ê°€ ë¶ˆì™„ì „\")\n",
    "            return result\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {emp_no} ë¶„ì„ ì‹¤íŒ¨: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def run_multiple_employees_analysis_working(engine, llm, emp_list: List[str], period_id: int) -> Dict[str, Dict]:\n",
    "    \"\"\"ì—¬ëŸ¬ ì§ì› ì¼ê´„ ë¶„ì„ (ê¸°ì¡´ í•¨ìˆ˜ë“¤ ì‚¬ìš©)\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ¯ {len(emp_list)}ëª… {period_id}ë¶„ê¸° ì¼ê´„ ë¶„ì„ ì‹œì‘\")\n",
    "    \n",
    "    # ì €ì¥ë  í…Œì´ë¸” ì •ë³´ í‘œì‹œ\n",
    "    table_name = \"final_evaluation_reports\" if period_id == 4 else \"feedback_reports\"\n",
    "    print(f\"ğŸ’¾ ì €ì¥ í…Œì´ë¸”: {table_name}.ai_peer_talk_summary\")\n",
    "    \n",
    "    # ì›Œí¬í”Œë¡œìš° ìƒì„± (í•œ ë²ˆë§Œ)\n",
    "    workflow = create_working_peer_evaluation_workflow(engine, llm)\n",
    "    \n",
    "    results = {}\n",
    "    success_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for i, emp_no in enumerate(emp_list, 1):\n",
    "        print(f\"\\n[{i}/{len(emp_list)}] ğŸ“Š {emp_no} ë¶„ì„ ì‹œì‘...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸\n",
    "        if check_feedback_reports_by_period_working(engine, period_id, emp_no):\n",
    "            print(f\"â­ï¸ {emp_no}: ì´ë¯¸ ë¶„ì„ ì™„ë£Œ ({table_name}), ìŠ¤í‚µ\")\n",
    "            skipped_count += 1\n",
    "            results[emp_no] = \"already_completed\"\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # ê° ì§ì›ë³„ë¡œ ìƒˆë¡œìš´ ì´ˆê¸° ìƒíƒœ ìƒì„±\n",
    "            initial_state = create_initial_state_working(period_id, emp_no)\n",
    "            \n",
    "            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "            result = workflow.invoke(initial_state)\n",
    "            \n",
    "            # ê²°ê³¼ ê²€ì¦\n",
    "            if (result and result.get('ê°•ì ') and result.get('ìš°ë ¤') and result.get('í˜‘ì—…ê´€ì°°')):\n",
    "                print(f\"âœ… {emp_no} ë¶„ì„ ì™„ë£Œ!\")\n",
    "                if result.get('ê°•ì '):\n",
    "                    print(f\"   ê°•ì : {result['ê°•ì '][0][:50]}...\")\n",
    "                if result.get('ìš°ë ¤'):\n",
    "                    print(f\"   ìš°ë ¤: {result['ìš°ë ¤'][0][:50]}...\")\n",
    "                if result.get('í˜‘ì—…ê´€ì°°'):\n",
    "                    print(f\"   í˜‘ì—…ê´€ì°°: {result['í˜‘ì—…ê´€ì°°'][0][:50]}...\")\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"âš ï¸ {emp_no} ë¶„ì„ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ê°€ ë¶ˆì™„ì „\")\n",
    "            \n",
    "            results[emp_no] = result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {emp_no} ë¶„ì„ ì‹¤íŒ¨: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            results[emp_no] = None\n",
    "    \n",
    "    # ìš”ì•½ ì¶œë ¥\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½ ({table_name} í…Œì´ë¸”)\")\n",
    "    print(f\"=\"*80)\n",
    "    print(f\"ì´ ëŒ€ìƒì: {len(emp_list)}ëª…\")\n",
    "    print(f\"ì„±ê³µ: {success_count}ëª…\")\n",
    "    print(f\"ìŠ¤í‚µ (ê¸°ì¡´ ì™„ë£Œ): {skipped_count}ëª…\")\n",
    "    print(f\"ì‹¤íŒ¨: {len(emp_list) - success_count - skipped_count}ëª…\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def run_safe_period_analysis_working(engine, llm, period_id: int) -> Dict[str, Dict]:\n",
    "    \"\"\"ì•ˆì „í•œ ë¶„ê¸° ì „ì²´ ë¶„ì„ (ê¸°ì¡´ í•¨ìˆ˜ë“¤ ì‚¬ìš©, ë¶„ê¸°ë³„ í…Œì´ë¸” ì €ì¥)\"\"\"\n",
    "    \n",
    "    print(f\"=\"*80)\n",
    "    print(f\"ğŸš€ {period_id}ë¶„ê¸° ì „ì²´ ì§ì› ë™ë£Œí‰ê°€ ë¶„ì„ ì‹œì‘ (ê²€ì¦ëœ í•¨ìˆ˜ë“¤ ì‚¬ìš©)\")\n",
    "    print(f\"=\"*80)\n",
    "    \n",
    "    # ì €ì¥ë  í…Œì´ë¸” ì •ë³´ í‘œì‹œ\n",
    "    table_name = \"final_evaluation_reports\" if period_id == 4 else \"feedback_reports\"\n",
    "    print(f\"ğŸ’¾ ì €ì¥ í…Œì´ë¸”: {table_name}.ai_peer_talk_summary\")\n",
    "    \n",
    "    # í•´ë‹¹ ë¶„ê¸°ì˜ ëª¨ë“  í‰ê°€ ëŒ€ìƒì ì¡°íšŒ\n",
    "    emp_list = get_all_employees_in_period(engine, period_id)\n",
    "    \n",
    "    if not emp_list:\n",
    "        print(f\"âŒ {period_id}ë¶„ê¸°ì— ë¶„ì„í•  ì§ì›ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return {}\n",
    "    \n",
    "    # ì¼ê´„ ë¶„ì„ ì‹¤í–‰\n",
    "    results = run_multiple_employees_analysis_working(engine, llm, emp_list, period_id)\n",
    "    \n",
    "    print(f\"\\nâœ… {period_id}ë¶„ê¸° ì „ì²´ ë¶„ì„ ì™„ë£Œ!\")\n",
    "    return results\n",
    "\n",
    "# =============================================================================\n",
    "# ê°„í¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "# =============================================================================\n",
    "\n",
    "def quick_analysis_with_working_functions(engine, llm, emp_no: str, period_id: int):\n",
    "    \"\"\"ê¸°ì¡´ ê²€ì¦ëœ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•œ ë¹ ë¥¸ ë¶„ì„\"\"\"\n",
    "    print(f\"ğŸ¯ {emp_no} ë¹ ë¥¸ ë¶„ì„ ì‹œì‘ (ê²€ì¦ëœ í•¨ìˆ˜ë“¤ ì‚¬ìš©, ë¶„ê¸°: {period_id})...\")\n",
    "    \n",
    "    # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸\n",
    "    if check_feedback_reports_by_period_working(engine, period_id, emp_no):\n",
    "        table_name = \"final_evaluation_reports\" if period_id == 4 else \"feedback_reports\"\n",
    "        print(f\"â­ï¸ {emp_no}: ì´ë¯¸ ë¶„ì„ ì™„ë£Œ ({table_name}.ai_peer_talk_summary)\")\n",
    "        return \"already_completed\"\n",
    "    \n",
    "    result = run_single_employee_analysis_working(engine, llm, period_id, emp_no)\n",
    "    \n",
    "    if result and result.get('ê°•ì '):\n",
    "        print(\"\\nâœ… ë¶„ì„ ê²°ê³¼:\")\n",
    "        print(f\"ê°•ì : {result['ê°•ì '][0]}\")\n",
    "        print(f\"ìš°ë ¤: {result['ìš°ë ¤'][0]}\")  \n",
    "        print(f\"í˜‘ì—…ê´€ì°°: {result['í˜‘ì—…ê´€ì°°'][0]}\")\n",
    "    else:\n",
    "        print(\"âŒ ë¶„ì„ ì‹¤íŒ¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"âœ… ê¸°ì¡´ì— ì˜ ì‘ë™í•˜ë˜ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ëŠ” ì™„ì „í•œ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(\"ì£¼ìš” íŠ¹ì§•:\")\n",
    "print(\"- ê¸°ì¡´ ê²€ì¦ëœ ë¶„ì„ ë¡œì§ ê·¸ëŒ€ë¡œ ì‚¬ìš©\")\n",
    "print(\"- DB ì €ì¥ ë¶€ë¶„ë§Œ ë¶„ê¸°ë³„ í…Œì´ë¸”ë¡œ ìˆ˜ì •\")\n",
    "print(\"- ë¶„ê¸° 4: final_evaluation_reports.ai_peer_talk_summary\")\n",
    "print(\"- ë¶„ê¸° 1,2,3: feedback_reports.ai_peer_talk_summary\")\n",
    "print(\"- ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ìë™ ìŠ¤í‚µ\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ:\n",
    "run_safe_period_analysis_working(engine, llm, 3)\n",
    "# result = quick_analysis_with_working_functions(engine, llm, \"EMP001\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-WTM_qa1c-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
